{
  "generated_at": "2025-12-26T15:36:24.601670",
  "benchmark_dir": "C:\\Users\\k_nai\\nebulaMemBenchmark\\simple_test_set",
  "adapters": {
    "mem0": {
      "status": "success",
      "overall_accuracy": 0.5008488964346349,
      "total_probes": 589,
      "by_answer_type": {
        "short_answer": {
          "total": 180,
          "count": 450,
          "accuracy": 0.4
        },
        "boolean": {
          "total": 18,
          "count": 27,
          "accuracy": 0.6666666666666666
        },
        "verbatim": {
          "total": 16,
          "count": 21,
          "accuracy": 0.7619047619047619
        },
        "abstain": {
          "total": 80,
          "count": 83,
          "accuracy": 0.963855421686747
        },
        "generation": {
          "total": 1,
          "count": 8,
          "accuracy": 0.125
        }
      },
      "by_pillar": {
        "world_modeling": {
          "total": 45,
          "count": 99,
          "accuracy": 0.45454545454545453
        },
        "declarative_reasoning": {
          "total": 71,
          "count": 101,
          "accuracy": 0.7029702970297029
        },
        "temporal_episodic": {
          "total": 12,
          "count": 99,
          "accuracy": 0.12121212121212122
        },
        "preference_learning": {
          "total": 51,
          "count": 97,
          "accuracy": 0.5257731958762887
        },
        "knowledge_boundaries": {
          "total": 94,
          "count": 98,
          "accuracy": 0.9591836734693877
        },
        "procedural_knowledge": {
          "total": 22,
          "count": 95,
          "accuracy": 0.23157894736842105
        }
      }
    },
    "supermemory": {
      "status": "success",
      "overall_accuracy": 0.4838709677419355,
      "total_probes": 589,
      "by_answer_type": {
        "short_answer": {
          "total": 171,
          "count": 450,
          "accuracy": 0.38
        },
        "boolean": {
          "total": 20,
          "count": 27,
          "accuracy": 0.7407407407407407
        },
        "verbatim": {
          "total": 18,
          "count": 21,
          "accuracy": 0.8571428571428571
        },
        "abstain": {
          "total": 76,
          "count": 83,
          "accuracy": 0.9156626506024096
        },
        "generation": {
          "total": 0,
          "count": 8,
          "accuracy": 0.0
        }
      },
      "by_pillar": {
        "world_modeling": {
          "total": 24,
          "count": 99,
          "accuracy": 0.24242424242424243
        },
        "declarative_reasoning": {
          "total": 66,
          "count": 101,
          "accuracy": 0.6534653465346535
        },
        "temporal_episodic": {
          "total": 27,
          "count": 99,
          "accuracy": 0.2727272727272727
        },
        "preference_learning": {
          "total": 43,
          "count": 97,
          "accuracy": 0.44329896907216493
        },
        "knowledge_boundaries": {
          "total": 88,
          "count": 98,
          "accuracy": 0.8979591836734694
        },
        "procedural_knowledge": {
          "total": 37,
          "count": 95,
          "accuracy": 0.3894736842105263
        }
      }
    },
    "naive_rag": {
      "status": "success",
      "overall_accuracy": 0.5534804753820034,
      "total_probes": 589,
      "by_answer_type": {
        "short_answer": {
          "total": 200,
          "count": 450,
          "accuracy": 0.4444444444444444
        },
        "boolean": {
          "total": 23,
          "count": 27,
          "accuracy": 0.8518518518518519
        },
        "verbatim": {
          "total": 16,
          "count": 21,
          "accuracy": 0.7619047619047619
        },
        "abstain": {
          "total": 81,
          "count": 83,
          "accuracy": 0.9759036144578314
        },
        "generation": {
          "total": 6,
          "count": 8,
          "accuracy": 0.75
        }
      },
      "by_pillar": {
        "world_modeling": {
          "total": 42,
          "count": 99,
          "accuracy": 0.42424242424242425
        },
        "declarative_reasoning": {
          "total": 61,
          "count": 101,
          "accuracy": 0.6039603960396039
        },
        "temporal_episodic": {
          "total": 28,
          "count": 99,
          "accuracy": 0.2828282828282828
        },
        "preference_learning": {
          "total": 58,
          "count": 97,
          "accuracy": 0.5979381443298969
        },
        "knowledge_boundaries": {
          "total": 96,
          "count": 98,
          "accuracy": 0.9795918367346939
        },
        "procedural_knowledge": {
          "total": 41,
          "count": 95,
          "accuracy": 0.43157894736842106
        }
      }
    },
    "no_rag": {
      "status": "success",
      "overall_accuracy": 0.7096774193548387,
      "total_probes": 589,
      "by_answer_type": {
        "short_answer": {
          "total": 291,
          "count": 450,
          "accuracy": 0.6466666666666666
        },
        "boolean": {
          "total": 26,
          "count": 27,
          "accuracy": 0.9629629629629629
        },
        "verbatim": {
          "total": 19,
          "count": 21,
          "accuracy": 0.9047619047619048
        },
        "abstain": {
          "total": 80,
          "count": 83,
          "accuracy": 0.963855421686747
        },
        "generation": {
          "total": 2,
          "count": 8,
          "accuracy": 0.25
        }
      },
      "by_pillar": {
        "world_modeling": {
          "total": 67,
          "count": 99,
          "accuracy": 0.6767676767676768
        },
        "declarative_reasoning": {
          "total": 91,
          "count": 101,
          "accuracy": 0.900990099009901
        },
        "temporal_episodic": {
          "total": 49,
          "count": 99,
          "accuracy": 0.494949494949495
        },
        "preference_learning": {
          "total": 70,
          "count": 97,
          "accuracy": 0.7216494845360825
        },
        "knowledge_boundaries": {
          "total": 96,
          "count": 98,
          "accuracy": 0.9795918367346939
        },
        "procedural_knowledge": {
          "total": 45,
          "count": 95,
          "accuracy": 0.47368421052631576
        }
      }
    }
  }
}