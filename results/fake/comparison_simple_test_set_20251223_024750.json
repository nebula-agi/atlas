{
  "generated_at": "2025-12-23T02:47:50.689956",
  "benchmark_dir": "C:\\Users\\k_nai\\nebulaMemBenchmark\\simple_test_set",
  "adapters": {
    "mem0": {
      "status": "success",
      "overall_accuracy": 0.20203735144312393,
      "total_probes": 589,
      "by_answer_type": {
        "short_answer": {
          "total": 33,
          "count": 450,
          "accuracy": 0.07333333333333333
        },
        "boolean": {
          "total": 0,
          "count": 27,
          "accuracy": 0.0
        },
        "verbatim": {
          "total": 2,
          "count": 21,
          "accuracy": 0.09523809523809523
        },
        "abstain": {
          "total": 83,
          "count": 83,
          "accuracy": 1.0
        },
        "generation": {
          "total": 1,
          "count": 8,
          "accuracy": 0.125
        }
      },
      "by_pillar": {
        "world_modeling": {
          "total": 1,
          "count": 99,
          "accuracy": 0.010101010101010102
        },
        "declarative_reasoning": {
          "total": 9,
          "count": 101,
          "accuracy": 0.0891089108910891
        },
        "temporal_episodic": {
          "total": 2,
          "count": 99,
          "accuracy": 0.020202020202020204
        },
        "preference_learning": {
          "total": 8,
          "count": 97,
          "accuracy": 0.08247422680412371
        },
        "knowledge_boundaries": {
          "total": 88,
          "count": 98,
          "accuracy": 0.8979591836734694
        },
        "procedural_knowledge": {
          "total": 11,
          "count": 95,
          "accuracy": 0.11578947368421053
        }
      }
    },
    "supermemory": {
      "status": "success",
      "overall_accuracy": 0.5195246179966044,
      "total_probes": 589,
      "by_answer_type": {
        "short_answer": {
          "total": 209,
          "count": 450,
          "accuracy": 0.46444444444444444
        },
        "boolean": {
          "total": 13,
          "count": 27,
          "accuracy": 0.48148148148148145
        },
        "verbatim": {
          "total": 16,
          "count": 21,
          "accuracy": 0.7619047619047619
        },
        "abstain": {
          "total": 64,
          "count": 83,
          "accuracy": 0.7710843373493976
        },
        "generation": {
          "total": 4,
          "count": 8,
          "accuracy": 0.5
        }
      },
      "by_pillar": {
        "world_modeling": {
          "total": 30,
          "count": 99,
          "accuracy": 0.30303030303030304
        },
        "declarative_reasoning": {
          "total": 62,
          "count": 101,
          "accuracy": 0.6138613861386139
        },
        "temporal_episodic": {
          "total": 37,
          "count": 99,
          "accuracy": 0.37373737373737376
        },
        "preference_learning": {
          "total": 44,
          "count": 97,
          "accuracy": 0.4536082474226804
        },
        "knowledge_boundaries": {
          "total": 76,
          "count": 98,
          "accuracy": 0.7755102040816326
        },
        "procedural_knowledge": {
          "total": 57,
          "count": 95,
          "accuracy": 0.6
        }
      }
    },
    "naive_rag": {
      "status": "success",
      "overall_accuracy": 0.0,
      "total_probes": 589,
      "by_answer_type": {
        "short_answer": {
          "total": 0,
          "count": 450,
          "accuracy": 0.0
        },
        "boolean": {
          "total": 0,
          "count": 27,
          "accuracy": 0.0
        },
        "verbatim": {
          "total": 0,
          "count": 21,
          "accuracy": 0.0
        },
        "abstain": {
          "total": 0,
          "count": 83,
          "accuracy": 0.0
        },
        "generation": {
          "total": 0,
          "count": 8,
          "accuracy": 0.0
        }
      },
      "by_pillar": {
        "world_modeling": {
          "total": 0,
          "count": 99,
          "accuracy": 0.0
        },
        "declarative_reasoning": {
          "total": 0,
          "count": 101,
          "accuracy": 0.0
        },
        "temporal_episodic": {
          "total": 0,
          "count": 99,
          "accuracy": 0.0
        },
        "preference_learning": {
          "total": 0,
          "count": 97,
          "accuracy": 0.0
        },
        "knowledge_boundaries": {
          "total": 0,
          "count": 98,
          "accuracy": 0.0
        },
        "procedural_knowledge": {
          "total": 0,
          "count": 95,
          "accuracy": 0.0
        }
      }
    },
    "no_rag": {
      "status": "success",
      "overall_accuracy": 0.0,
      "total_probes": 589,
      "by_answer_type": {
        "short_answer": {
          "total": 0,
          "count": 450,
          "accuracy": 0.0
        },
        "boolean": {
          "total": 0,
          "count": 27,
          "accuracy": 0.0
        },
        "verbatim": {
          "total": 0,
          "count": 21,
          "accuracy": 0.0
        },
        "abstain": {
          "total": 0,
          "count": 83,
          "accuracy": 0.0
        },
        "generation": {
          "total": 0,
          "count": 8,
          "accuracy": 0.0
        }
      },
      "by_pillar": {
        "world_modeling": {
          "total": 0,
          "count": 99,
          "accuracy": 0.0
        },
        "declarative_reasoning": {
          "total": 0,
          "count": 101,
          "accuracy": 0.0
        },
        "temporal_episodic": {
          "total": 0,
          "count": 99,
          "accuracy": 0.0
        },
        "preference_learning": {
          "total": 0,
          "count": 97,
          "accuracy": 0.0
        },
        "knowledge_boundaries": {
          "total": 0,
          "count": 98,
          "accuracy": 0.0
        },
        "procedural_knowledge": {
          "total": 0,
          "count": 95,
          "accuracy": 0.0
        }
      }
    }
  }
}