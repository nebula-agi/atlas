{
  "generated_at": "2026-01-07T13:08:16.706148",
  "adapter_type": "NebulaAdapter",
  "num_benchmarks": 50,
  "total_probes": 503,
  "overall_summary": {
    "overall_accuracy": 0.709741550695825,
    "total_score": 357,
    "count": 503,
    "by_answer_type": {
      "short_answer": {
        "total": 274,
        "count": 408,
        "accuracy": 0.6715686274509803
      },
      "boolean": {
        "total": 12,
        "count": 18,
        "accuracy": 0.6666666666666666
      },
      "abstain": {
        "total": 70,
        "count": 73,
        "accuracy": 0.958904109589041
      },
      "verbatim": {
        "total": 1,
        "count": 2,
        "accuracy": 0.5
      },
      "generation": {
        "total": 0,
        "count": 2,
        "accuracy": 0.0
      }
    },
    "by_pillar": {
      "world_modeling": {
        "total": 77,
        "count": 85,
        "accuracy": 0.9058823529411765
      },
      "declarative_reasoning": {
        "total": 86,
        "count": 95,
        "accuracy": 0.9052631578947369
      },
      "temporal_episodic": {
        "total": 30,
        "count": 83,
        "accuracy": 0.3614457831325301
      },
      "preference_learning": {
        "total": 40,
        "count": 75,
        "accuracy": 0.5333333333333333
      },
      "knowledge_boundaries": {
        "total": 81,
        "count": 90,
        "accuracy": 0.9
      },
      "procedural_knowledge": {
        "total": 43,
        "count": 75,
        "accuracy": 0.5733333333333334
      }
    }
  },
  "stored_memories": [],
  "benchmark_summaries": [
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_001.json",
      "accuracy": 0.6666666666666666,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 162.53168749809265
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_002.json",
      "accuracy": 0.75,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 163.05644011497498
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_003.json",
      "accuracy": 0.8333333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 192.1492142677307
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_004.json",
      "accuracy": 0.5833333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 180.4115309715271
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_005.json",
      "accuracy": 0.5833333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 178.15170812606812
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_006.json",
      "accuracy": 0.8181818181818182,
      "num_probes": 11,
      "ingestion_time_s": 0.0,
      "eval_time_s": 151.79101634025574
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_007.json",
      "accuracy": 0.5833333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 166.56251049041748
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_008.json",
      "accuracy": 0.6666666666666666,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 158.96275877952576
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_009.json",
      "accuracy": 0.9166666666666666,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 175.65321373939514
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_010.json",
      "accuracy": 0.8333333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 156.22318077087402
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_011.json",
      "accuracy": 0.7142857142857143,
      "num_probes": 7,
      "ingestion_time_s": 0.0,
      "eval_time_s": 86.55206155776978
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_012.json",
      "accuracy": 1.0,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 24.441195726394653
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_013.json",
      "accuracy": 1.0,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 29.345185041427612
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_014.json",
      "accuracy": 1.0,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 26.741690635681152
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_015.json",
      "accuracy": 0.5454545454545454,
      "num_probes": 11,
      "ingestion_time_s": 0.0,
      "eval_time_s": 141.14706087112427
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_016.json",
      "accuracy": 0.46153846153846156,
      "num_probes": 13,
      "ingestion_time_s": 0.0,
      "eval_time_s": 181.1806080341339
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_017.json",
      "accuracy": 0.9166666666666666,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 140.71079802513123
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_018.json",
      "accuracy": 0.75,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 154.59266352653503
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_019.json",
      "accuracy": 0.5833333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 151.66193675994873
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_020.json",
      "accuracy": 0.8333333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 227.64129972457886
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_021.json",
      "accuracy": 0.8333333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 203.76925015449524
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_022.json",
      "accuracy": 0.6666666666666666,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 154.53285241127014
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_023.json",
      "accuracy": 0.875,
      "num_probes": 8,
      "ingestion_time_s": 0.0,
      "eval_time_s": 104.50233435630798
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_024.json",
      "accuracy": 0.8,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "eval_time_s": 120.39625549316406
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_025.json",
      "accuracy": 1.0,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "eval_time_s": 123.84278583526611
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_026.json",
      "accuracy": 0.75,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 156.24845957756042
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_027.json",
      "accuracy": 0.5,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 22.082979917526245
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_028.json",
      "accuracy": 0.5833333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 146.12000703811646
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_029.json",
      "accuracy": 0.9166666666666666,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 145.51042485237122
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_030.json",
      "accuracy": 1.0,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 23.25640559196472
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_031.json",
      "accuracy": 0.5,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 23.902372121810913
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_032.json",
      "accuracy": 0.8,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "eval_time_s": 126.41883111000061
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_033.json",
      "accuracy": 0.5833333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 326.5929355621338
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_034.json",
      "accuracy": 0.75,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 177.73558020591736
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_035.json",
      "accuracy": 0.7,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "eval_time_s": 128.75734686851501
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_036.json",
      "accuracy": 0.6363636363636364,
      "num_probes": 11,
      "ingestion_time_s": 0.0,
      "eval_time_s": 154.7967345714569
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_037.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 198.24540853500366
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_038.json",
      "accuracy": 0.6666666666666666,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 164.02462434768677
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_039.json",
      "accuracy": 1.0,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 28.170116424560547
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_040.json",
      "accuracy": 0.6666666666666666,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 180.86324667930603
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_041.json",
      "accuracy": 0.75,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 173.83610773086548
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_042.json",
      "accuracy": 0.5555555555555556,
      "num_probes": 9,
      "ingestion_time_s": 0.0,
      "eval_time_s": 135.8281171321869
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_043.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 153.14634466171265
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_044.json",
      "accuracy": 0.5833333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 155.99928784370422
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_045.json",
      "accuracy": 0.8,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "eval_time_s": 125.05501866340637
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_046.json",
      "accuracy": 0.75,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 145.56045603752136
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_047.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 165.67154145240784
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_048.json",
      "accuracy": 0.9166666666666666,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 171.8122022151947
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_049.json",
      "accuracy": 0.8333333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 175.52690076828003
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_050.json",
      "accuracy": 0.4444444444444444,
      "num_probes": 9,
      "ingestion_time_s": 0.0,
      "eval_time_s": 109.09515070915222
    }
  ],
  "detailed_results": [
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_001.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 162.53168749809265,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who deployed the analytics engine situated on Google Cloud Platform?",
          "answer_type": "short_answer",
          "gold_answer": "Lucas",
          "predicted_answer": "Lucas",
          "retrieved_context": [
            "Lucas deployed AnalyticsEngine2",
            "AnalyticsEngine9 located in AWS environment",
            "AnalyticsEngine5 located in AWS environment"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4828.1190395355225,
          "generation_latency_ms": 3942.2531127929688,
          "scoring_latency_ms": 2878.019094467163,
          "total_latency_ms": 11648.391246795654
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the job title of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Data Scientist",
          "predicted_answer": "Data Scientist",
          "retrieved_context": [
            "Will owner of Luna",
            "Will has pet Luna",
            "Will owns or associated with Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5104.130029678345,
          "generation_latency_ms": 3208.7960243225098,
          "scoring_latency_ms": 2785.4690551757812,
          "total_latency_ms": 11098.395109176636
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which cloud provider hosts the service that is currently reporting conflicting version numbers?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "80f14bf5-c465-429a-8c75-e5dcaf2e2f8f reports version version v1.2.0",
            "PrimaryDB7 reports version conflict between v1.2.0 and v2.0.0-beta",
            "Analytics Engine 9 hosted on Amazon Web Services"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6644.061803817749,
          "generation_latency_ms": 4643.6707973480225,
          "scoring_latency_ms": 2851.254463195801,
          "total_latency_ms": 14138.987064361572
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What specific versions are currently being flagged by the primary database according to the latest logs and config?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "version 1.2.0 running on PrimaryDB7",
            "version mismatch on PrimaryDB7 involves PrimaryDB7",
            "2d361912-05b4-40f8-af8e-98b879486bc1 flags version version v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6160.385608673096,
          "generation_latency_ms": 4009.6545219421387,
          "scoring_latency_ms": 2732.942819595337,
          "total_latency_ms": 12902.982950210571
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-0",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "During the conversation about consolidating analytics services, what personal appointment was the user reminded of?",
          "answer_type": "short_answer",
          "gold_answer": "Dentist appointment",
          "predicted_answer": "Dentist appointment",
          "retrieved_context": [
            "Alex needs to consolidate billing for analytics stack",
            "user has scheduled budget meeting with Charlotte",
            "2234b1a8-a2a4-4189-b555-312b072cb7d9 scheduled for user"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6685.515642166138,
          "generation_latency_ms": 5364.382982254028,
          "scoring_latency_ms": 2820.4426765441895,
          "total_latency_ms": 14870.341300964355
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Was the reminder to call mom set for 5 PM before or after the user discussed the CEO's memo?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user reminder to call mom at 6 PM, January 7, 2026",
            "call to mom scheduled for 12:30 PM",
            "user reminded to pick up 5 PM"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5210.764169692993,
          "generation_latency_ms": 3889.237403869629,
          "scoring_latency_ms": 2900.9909629821777,
          "total_latency_ms": 12000.9925365448
        },
        {
          "probe_id": "preference_learning-preference_drift-0",
          "pillar": "preference_learning",
          "subpillar": "preference_drift",
          "question": "What is the most recently requested time for the user's reminder to call their mom?",
          "answer_type": "short_answer",
          "gold_answer": "6 PM",
          "predicted_answer": "12:30 PM",
          "retrieved_context": [
            "user reminder to call mom at 6 PM, January 7, 2026",
            "user wants to call mom",
            "call to mom scheduled for 12:30 PM"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5498.851537704468,
          "generation_latency_ms": 4826.346635818481,
          "scoring_latency_ms": 2882.596731185913,
          "total_latency_ms": 13207.794904708862
        },
        {
          "probe_id": "preference_learning-explicit_preferences-1",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Did the user specify a particular topic to discuss during the call with their mom?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user wants to call mom",
            "User plans to call mom",
            "call to mom scheduled for 12:30 PM"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5310.377359390259,
          "generation_latency_ms": 3160.473346710205,
          "scoring_latency_ms": 3607.0096492767334,
          "total_latency_ms": 12077.860355377197
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What version is the AnalyticsEngine2 currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Will running models on AnalyticsEngine2",
            "7812d899-35c3-4cef-8c1d-367350cd658c hosted on Google Cloud Platform",
            "9178b08c-2b8a-4a05-9516-35de3cde6bd9 hosted on GCP"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8535.725593566895,
          "generation_latency_ms": 5906.256198883057,
          "scoring_latency_ms": 2962.8403186798096,
          "total_latency_ms": 17404.82211112976
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Product Designer's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Noah leading product design overhaul",
            "email cofounder reminder concerns Noah's product designs",
            "Noah member of design team"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5767.778635025024,
          "generation_latency_ms": 5478.709936141968,
          "scoring_latency_ms": 3106.9579124450684,
          "total_latency_ms": 14353.44648361206
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "How did the assistant determine the version conflict on the Azure-hosted database?",
          "answer_type": "short_answer",
          "gold_answer": "Comparing logs and config",
          "predicted_answer": "Conflicting telemetry, heartbeats, diagnostics flags, headers, internal status, logs, and configuration",
          "retrieved_context": [
            "Lucas notified about database version conflict",
            "PrimaryDB7 version 1.2.0 hosted on Azure",
            "PrimaryDB7 hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8790.855169296265,
          "generation_latency_ms": 4618.452787399292,
          "scoring_latency_ms": 2731.830596923828,
          "total_latency_ms": 16141.138553619385
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-1",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What technical task is the DevOps lead currently struggling with?",
          "answer_type": "short_answer",
          "gold_answer": "Azure deployment",
          "predicted_answer": "PrimaryDB7 version conflict",
          "retrieved_context": [
            "DevOps lead coordinates networking with CacheLayer9",
            "DevOps lead assigned to migration ticket for AnalyticsEngine2",
            "Lucas has role DevOps lead"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4966.432094573975,
          "generation_latency_ms": 4875.8111000061035,
          "scoring_latency_ms": 2786.731958389282,
          "total_latency_ms": 12628.97515296936
        }
      ],
      "summary": {
        "overall_accuracy": 0.6666666666666666,
        "total_score": 8,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 9,
            "accuracy": 0.6666666666666666
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_002.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 163.05644011497498,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the person referred to as the user's 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Charlotte",
          "predicted_answer": "Charlotte",
          "retrieved_context": [
            "cofounder participates in strategy sync",
            "cofounder advocates for platform stabilization",
            "Charlotte cofounder of user"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5405.799627304077,
          "generation_latency_ms": 4995.612859725952,
          "scoring_latency_ms": 3130.361318588257,
          "total_latency_ms": 13531.773805618286
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which DevOps team member is associated with a cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Noah",
          "predicted_answer": "Noah",
          "retrieved_context": [
            "DevOps crew led by Ava",
            "Ava member of DevOps",
            "DevOps crew led by Noah"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4968.662738800049,
          "generation_latency_ms": 2903.6858081817627,
          "scoring_latency_ms": 2830.310106277466,
          "total_latency_ms": 10702.658653259277
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service currently reporting a conflict between v1.2.0 and v2.0.0-beta hosted?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google Cloud Platform",
          "retrieved_context": [
            "Charlotte concerned about GCP auth service version v2.0.0-beta",
            "Charlotte concerned about GCP auth service version v1.2.0",
            "AuthService7 reports version v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5072.070837020874,
          "generation_latency_ms": 4857.27071762085,
          "scoring_latency_ms": 2606.1275005340576,
          "total_latency_ms": 12535.469055175781
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-1",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "What two specific versions are simultaneously reported as active on AuthService7?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "version 1.2.0 current version of AuthService7",
            "Ava alerted about version conflict on AuthService7",
            "v2.0.0-beta alias of AuthService7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7584.62929725647,
          "generation_latency_ms": 4572.335243225098,
          "scoring_latency_ms": 2675.0388145446777,
          "total_latency_ms": 14832.003355026245
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-0",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific event involving a pet did the user speculate might have caused the canary deployment issues?",
          "answer_type": "short_answer",
          "gold_answer": "Luna walking on keyboard",
          "predicted_answer": "Noah pushed wrong config to AuthService7",
          "retrieved_context": [
            "canary deployment started January 6, 2026 occurred on January 6, 2026",
            "canary deployment issue affects AuthService7",
            "AuthService7 deployed in canary deployment started January 6, 2026"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8913.14673423767,
          "generation_latency_ms": 2799.494981765747,
          "scoring_latency_ms": 2732.0215702056885,
          "total_latency_ms": 14444.663286209106
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-1",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "Immediately after mentioning the strategy session with Charlotte, what personal task did the user request a reminder for?",
          "answer_type": "short_answer",
          "gold_answer": "Pick up dry cleaning",
          "predicted_answer": "dry cleaning",
          "retrieved_context": [
            "user has strategy meeting with Charlotte",
            "60e503a6-3c02-4f31-bd47-4d526aa9a5e7 involved user",
            "user has set reminder to call dentist at 2 PM"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5128.187656402588,
          "generation_latency_ms": 3858.380079269409,
          "scoring_latency_ms": 2686.607837677002,
          "total_latency_ms": 11673.175573348999
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of Emma's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Charlotte will follow up with Emma",
            "user meeting with Emma",
            "20529c9b-d28f-4ff1-82d6-87f1170a109d participates in executive sync"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6221.451759338379,
          "generation_latency_ms": 5151.767015457153,
          "scoring_latency_ms": 2791.0258769989014,
          "total_latency_ms": 14164.244651794434
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "On which cloud platform is the 'PaymentGateway' service hosted?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "AuthService7 hosted on Google's cloud",
            "authentication service hosted on Google Cloud Platform",
            "multi-cloud strategy includes Google Cloud Platform"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5142.302513122559,
          "generation_latency_ms": 4413.796901702881,
          "scoring_latency_ms": 3140.9220695495605,
          "total_latency_ms": 12697.021484375
        },
        {
          "probe_id": "preference_learning-explicit_preferences-0",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "At what time does the user repeatedly request to be reminded to pick up dry cleaning?",
          "answer_type": "short_answer",
          "gold_answer": "5 PM",
          "predicted_answer": "5 PM",
          "retrieved_context": [
            "user has reminder for dry cleaning reminder at 5 PM",
            "user set reminder for dry cleaning reminder at 5 PM",
            "user reminded to dry cleaning pickup"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5294.448375701904,
          "generation_latency_ms": 3452.1172046661377,
          "scoring_latency_ms": 2927.499294281006,
          "total_latency_ms": 11674.064874649048
        },
        {
          "probe_id": "preference_learning-preference_scope-1",
          "pillar": "preference_learning",
          "subpillar": "preference_scope",
          "question": "Has the user expressed a preference for which cloud provider to use for new services?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "AuthService7 hosted on Google Cloud",
            "AuthService7 hosted on Google Cloud Platform",
            "AuthService7 deployed on Google Cloud Platform"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 7592.419147491455,
          "generation_latency_ms": 5552.927732467651,
          "scoring_latency_ms": 2769.7579860687256,
          "total_latency_ms": 15915.104866027832
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What administrative action did the assistant take to ensure the version discrepancy was addressed during the user's sync with Charlotte?",
          "answer_type": "short_answer",
          "gold_answer": "Added a note",
          "predicted_answer": "Added a note",
          "retrieved_context": [
            "Charlotte participates in sync meeting with Charlotte",
            "Alex has sync meeting with Charlotte",
            "9e9ba8a0-b521-4079-85bc-e580a3a55c95 involves Emma"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 9004.11581993103,
          "generation_latency_ms": 3318.3891773223877,
          "scoring_latency_ms": 2760.357618331909,
          "total_latency_ms": 15082.862615585327
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "Which two team members did the assistant suggest contacting to handle an infrastructure rollback?",
          "answer_type": "short_answer",
          "gold_answer": "Ava or Noah",
          "predicted_answer": "Ava and Noah",
          "retrieved_context": [
            "Ava can handle infrastructure rollback",
            "user preparing for infrastructure review",
            "user considering check in with infrastructure team"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6877.901554107666,
          "generation_latency_ms": 5353.308916091919,
          "scoring_latency_ms": 3403.3851623535156,
          "total_latency_ms": 15634.5956325531
        }
      ],
      "summary": {
        "overall_accuracy": 0.75,
        "total_score": 9,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 7,
            "count": 9,
            "accuracy": 0.7777777777777778
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_003.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 27,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 192.1492142677307,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual identified as the user's cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "Liam",
          "retrieved_context": [
            "cofounder mentioned in context of cloud budget meeting",
            "beta rollout possibly authorized by cofounder",
            "User's cofounder concerned about Azure bill"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5830.5840492248535,
          "generation_latency_ms": 6556.697368621826,
          "scoring_latency_ms": 2963.1099700927734,
          "total_latency_ms": 15350.391387939453
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which employee is associated with the pet named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Ava",
          "predicted_answer": "Ava",
          "retrieved_context": [
            "Luna subject of vet visit",
            "Luna office mascot office",
            "Ava brought pet to call Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4763.668775558472,
          "generation_latency_ms": 4616.232633590698,
          "scoring_latency_ms": 3239.875078201294,
          "total_latency_ms": 12619.776487350464
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Is the service currently running the v2.0.0-beta version hosted on the same cloud provider as LoadBalancer2?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "LoadBalancer2 hosted on Google Cloud Platform",
            "LoadBalancer2 hosted on GCP",
            "LoadBalancer2 hosted on GCP"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5171.067714691162,
          "generation_latency_ms": 5115.941286087036,
          "scoring_latency_ms": 4682.622194290161,
          "total_latency_ms": 14969.63119506836
        },
        {
          "probe_id": "declarative_reasoning-verbatim_recall-3",
          "pillar": "declarative_reasoning",
          "subpillar": "verbatim_recall",
          "question": "What exact phrase did the user use to describe their low energy level in Session 23?",
          "answer_type": "verbatim",
          "gold_answer": "I am dragging today",
          "predicted_answer": "I am dragging today.",
          "retrieved_context": [
            "2f0bfa1d-0f36-45fd-a933-01320a71e355 spoken by document",
            "Luna mentioned during standup meeting",
            "User uses Slack"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4430.397748947144,
          "generation_latency_ms": 4088.3655548095703,
          "scoring_latency_ms": 3328.02414894104,
          "total_latency_ms": 11846.787452697754
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-4",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the request to text Ava occur before or after the discussion about the Azure bill?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "After",
          "retrieved_context": [
            "3460bacd-5f57-4179-927a-70363f7973f1 plans to text Ava",
            "Alex promised to text Ava",
            "3460bacd-5f57-4179-927a-70363f7973f1 plans to ask about Ava"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5593.6338901519775,
          "generation_latency_ms": 5775.822162628174,
          "scoring_latency_ms": 3245.6095218658447,
          "total_latency_ms": 14615.065574645996
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What specific time slot was secured for the meeting with the CEO regarding the data team?",
          "answer_type": "short_answer",
          "gold_answer": "2 PM",
          "predicted_answer": "",
          "retrieved_context": [
            "Data team standup meeting scheduled for January 7, 2026",
            "Will discussed in context of data team discussion meeting",
            "Alex needs to talk about data team discussion meeting"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6860.484600067139,
          "generation_latency_ms": 23088.027000427246,
          "scoring_latency_ms": 4120.736360549927,
          "total_latency_ms": 34069.24796104431
        },
        {
          "probe_id": "preference_learning-explicit_preferences-6",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Which specific service did the user explicitly instruct to exclude from the Azure cost report?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer2",
          "predicted_answer": "LoadBalancer2",
          "retrieved_context": [
            "8956d7d4-af12-41a4-ad70-040ef14c6038 includes AnalyticsEngine2",
            "8956d7d4-af12-41a4-ad70-040ef14c6038 includes AnalyticsEngine1",
            "ea10a485-9c76-4514-9910-b7ec3d3873f6 generated for Liam"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5546.824216842651,
          "generation_latency_ms": 4482.799768447876,
          "scoring_latency_ms": 3875.3647804260254,
          "total_latency_ms": 13904.988765716553
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "When asking for system status for the investor call, what level of detail did the user prefer?",
          "answer_type": "short_answer",
          "gold_answer": "High level",
          "predicted_answer": "High level",
          "retrieved_context": [
            "Liam requesting stability report for investor call",
            "3460bacd-5f57-4179-927a-70363f7973f1 requested status report for infrastructure meeting",
            "Warriors game result inquired by user"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5396.2953090667725,
          "generation_latency_ms": 4587.465524673462,
          "scoring_latency_ms": 4339.494466781616,
          "total_latency_ms": 14323.25530052185
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the specific version number currently running on AuthService4?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex feels acting up AuthService4",
            "d5af207f-0d13-4836-a3b7-2b8f1ec44acd hosted on Azure",
            "AnalyticsEngine2 reports conflicting version reports"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6813.962697982788,
          "generation_latency_ms": 7139.000177383423,
          "scoring_latency_ms": 2952.3115158081055,
          "total_latency_ms": 16905.274391174316
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who is the current Product Manager at Nebula?",
          "answer_type": "abstain",
          "gold_answer": "Not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Ava manages UX stuff",
            "Sophia member of data team",
            "Alex plans to ping data scientists about AnalyticsEngine2"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5390.188455581665,
          "generation_latency_ms": 4761.642932891846,
          "scoring_latency_ms": 3455.256700515747,
          "total_latency_ms": 13607.088088989258
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What habit of Will's is believed to be the cause of the version conflicts on the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "Testing in prod",
          "predicted_answer": "testing new models in prod",
          "retrieved_context": [
            "31912d2a-7be6-42e1-8133-f056f8623d1b frequently uses AnalyticsEngine2",
            "0d6bcec1-ac83-4bf9-896c-ea4e1d10eeaa likely cause of version conflict",
            "31912d2a-7be6-42e1-8133-f056f8623d1b frequently uses AnalyticsEngine9"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5442.365407943726,
          "generation_latency_ms": 5420.361757278442,
          "scoring_latency_ms": 2992.8107261657715,
          "total_latency_ms": 13855.53789138794
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-11",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What logic was applied to exclude LoadBalancer2 from the Azure spend report?",
          "answer_type": "short_answer",
          "gold_answer": "Hosted on GCP",
          "predicted_answer": "LoadBalancer2 is hosted on GCP.",
          "retrieved_context": [
            "44a56448-b4b1-406e-b782-39d66efe1966 inquiring about LoadBalancer2",
            "LoadBalancer2 routes to Azure",
            "Azure bill includes AnalyticsEngine2"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8387.09306716919,
          "generation_latency_ms": 4618.5009479522705,
          "scoring_latency_ms": 3032.987356185913,
          "total_latency_ms": 16038.581371307373
        }
      ],
      "summary": {
        "overall_accuracy": 0.8333333333333334,
        "total_score": 10,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 8,
            "accuracy": 0.75
          },
          "boolean": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "verbatim": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_004.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 180.4115309715271,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user planning to discuss quarterly goals with?",
          "answer_type": "short_answer",
          "gold_answer": "Mia",
          "predicted_answer": "Mia",
          "retrieved_context": [
            "coffee meeting with cofounder discusses quarterly goals",
            "b5a8c32c-5d2f-4fff-9fd8-ef699bc5298d plans to ask about sales meeting Sophia",
            "b5a8c32c-5d2f-4fff-9fd8-ef699bc5298d plans to grill backend team"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7727.882623672485,
          "generation_latency_ms": 3803.2963275909424,
          "scoring_latency_ms": 3004.31227684021,
          "total_latency_ms": 14535.491228103638
        },
        {
          "probe_id": "world_modeling-relationship_mapping-0",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which member of the sales team is the owner of Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Lucas",
          "predicted_answer": "Lucas",
          "retrieved_context": [
            "Lucas owner of Luna",
            "Lucas owns Luna",
            "Lucas member of Sales"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5543.723821640015,
          "generation_latency_ms": 4206.216096878052,
          "scoring_latency_ms": 2896.78692817688,
          "total_latency_ms": 12646.726846694946
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What cloud provider hosts the load balancer that the DevOps lead was worried about?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "GCP",
          "retrieved_context": [
            "DevOps guy responsible for LoadBalancer8",
            "DevOps guy investigating latency on LoadBalancer8",
            "7ae60ee2-5c22-404f-8604-ecfed414a4ea possibly hosted on Google"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6234.703302383423,
          "generation_latency_ms": 3759.6490383148193,
          "scoring_latency_ms": 5407.737493515015,
          "total_latency_ms": 15402.089834213257
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-0",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "According to the conflicting system logs, which two cloud providers are reportedly hosting CacheLayer3?",
          "answer_type": "short_answer",
          "gold_answer": "GCP and Azure",
          "predicted_answer": "GCP, Azure",
          "retrieved_context": [
            "CacheLayer3 hosted on according to monitoring tool GCP",
            "CacheLayer3 possibly hosted on Google Cloud Platform",
            "929c6d92-7d33-48bb-97ab-0acf013d04a4 indicated hosting on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5872.164011001587,
          "generation_latency_ms": 2712.9783630371094,
          "scoring_latency_ms": 3157.9620838165283,
          "total_latency_ms": 11743.104457855225
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-0",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What ongoing activity explains why CacheLayer3 is reporting two different software versions simultaneously?",
          "answer_type": "short_answer",
          "gold_answer": "Update migration",
          "predicted_answer": "simultaneously spinning up instances of v2.0.0-beta",
          "retrieved_context": [
            "CacheLayer3 exhibits version mismatch",
            "CacheLayer3 reporting version v1.2.0",
            "CacheLayer6 possibly shares version issue with CacheLayer3"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 14032.164573669434,
          "generation_latency_ms": 5137.784242630005,
          "scoring_latency_ms": 3381.192207336426,
          "total_latency_ms": 22551.141023635864
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-0",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "During the strategy meeting, what specific event interrupted the Sales Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Luna jumped on keyboard",
          "predicted_answer": "Lucas derailed end of strategy session",
          "retrieved_context": [
            "Lucas derailed end of strategy session",
            "sales meeting led by Lucas",
            "user participated in strategy session"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6331.94375038147,
          "generation_latency_ms": 4835.581064224243,
          "scoring_latency_ms": 3305.002450942993,
          "total_latency_ms": 14472.527265548706
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What beverage does the user frequently consume to cope with work exhaustion?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Double espresso",
          "retrieved_context": [
            "Alex needs before double espresso",
            "user wants to be reminded to grab coffee beans",
            "user set reminder for double espresso reminder"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5005.254030227661,
          "generation_latency_ms": 3002.2099018096924,
          "scoring_latency_ms": 3276.8867015838623,
          "total_latency_ms": 11284.350633621216
        },
        {
          "probe_id": "preference_learning-explicit_preferences-0",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What item did the user explicitly ask to be added to their shopping list?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee beans",
          "predicted_answer": "coffee beans",
          "retrieved_context": [
            "Alex added reminder to buy shopping list",
            "buy espresso beans added to personal to do list user",
            "user wants to be reminded to grab coffee beans"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5118.268251419067,
          "generation_latency_ms": 6566.784143447876,
          "scoring_latency_ms": 3283.6709022521973,
          "total_latency_ms": 14968.72329711914
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Backend Lead's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "29a40d23-b322-41b3-8dcc-c9393539f9c4 led by Charlotte",
            "Charlotte holds role Backend Lead",
            "user needs to inform backend lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6682.437419891357,
          "generation_latency_ms": 9473.422288894653,
          "scoring_latency_ms": 3280.1151275634766,
          "total_latency_ms": 19435.974836349487
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the 'auth_service'?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "CacheLayer3 possibly hosted on Google Cloud Platform",
            "6ee1fa78-9ebd-4723-9ed6-d963116f6c50 includes Google Cloud Platform",
            "CacheLayer3 hosted on according to billing invoice Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5314.17989730835,
          "generation_latency_ms": 2874.600648880005,
          "scoring_latency_ms": 2905.505657196045,
          "total_latency_ms": 11094.2862033844
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What two specific data sources does the assistant cite when analyzing the version conflict on CacheLayer3?",
          "answer_type": "short_answer",
          "gold_answer": "Response headers and heartbeats",
          "predicted_answer": "Headers and logs",
          "retrieved_context": [
            "CacheLayer3 exhibits version mismatch",
            "b5a8c32c-5d2f-4fff-9fd8-ef699bc5298d concerned about routing and version conflict on CacheLayer3",
            "DevOps team responsible for reconciling versions on CacheLayer3"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 10642.024517059326,
          "generation_latency_ms": 5172.8644371032715,
          "scoring_latency_ms": 2885.194778442383,
          "total_latency_ms": 18700.08373260498
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-0",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "Based on previous checks, what is the expected stability status of CacheLayer3?",
          "answer_type": "short_answer",
          "gold_answer": "Unstable",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "b5a8c32c-5d2f-4fff-9fd8-ef699bc5298d investigating CacheLayer3",
            "CacheLayer3 hosted on according to monitoring tool GCP",
            "CacheLayer3 has active instances on Azure"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5827.6567459106445,
          "generation_latency_ms": 4935.606241226196,
          "scoring_latency_ms": 2796.751022338867,
          "total_latency_ms": 13560.014009475708
        }
      ],
      "summary": {
        "overall_accuracy": 0.5833333333333334,
        "total_score": 7,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 10,
            "accuracy": 0.5
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_005.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 178.15170812606812,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which executive is repeatedly referred to as the user's 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Mia",
          "predicted_answer": "Mia",
          "retrieved_context": [
            "user has cofounder cofounder",
            "user has meeting with cofounder",
            "user cofounder of Mia"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6201.617956161499,
          "generation_latency_ms": 7286.767482757568,
          "scoring_latency_ms": 3104.274272918701,
          "total_latency_ms": 16592.65971183777
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which specific service is co-located on the Google Cloud Platform alongside the main database?",
          "answer_type": "short_answer",
          "gold_answer": "CacheLayer4",
          "predicted_answer": "CacheLayer4",
          "retrieved_context": [
            "PrimaryDB3 hosted on Google Cloud Platform",
            "PrimaryDB3 hosted on Google Cloud Platform",
            "PrimaryDB3 hosted on GCP"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5727.360725402832,
          "generation_latency_ms": 5363.686323165894,
          "scoring_latency_ms": 2942.798376083374,
          "total_latency_ms": 14033.8454246521
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "The Backend Lead set up a specific caching layer. Which cloud platform is that layer hosted on?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "AWS",
          "retrieved_context": [
            "a3321243-5000-47c6-8d19-ec7cdd3aeb0c hosted on Google Cloud Platform",
            "e824f0fe-8fc5-409d-af5a-47902421015d hosted on Google Cloud Platform",
            "8d81dd72-ee94-4670-b3a9-6cf683a9f41f deployed CacheLayer2"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4698.7714767456055,
          "generation_latency_ms": 10011.228084564209,
          "scoring_latency_ms": 2986.569404602051,
          "total_latency_ms": 17696.568965911865
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What two software versions is AuthService7 currently reporting in the logs?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "Will deployed AuthService7",
            "Alex manages AuthService7",
            "AuthService7 has instances running version v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6436.429738998413,
          "generation_latency_ms": 3488.1157875061035,
          "scoring_latency_ms": 2973.007917404175,
          "total_latency_ms": 12897.553443908691
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-1",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "In the most recent interaction, what reason was given for the Sales Lead being inactive or late?",
          "answer_type": "short_answer",
          "gold_answer": "Luna was sick",
          "predicted_answer": "Luna knocked over his webcam",
          "retrieved_context": [
            "Sales Lead fond of Luna",
            "James has reason for being late vet appointment for Luna",
            "James holds role Sales Lead"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6007.907152175903,
          "generation_latency_ms": 7954.680919647217,
          "scoring_latency_ms": 3390.4356956481934,
          "total_latency_ms": 17353.023767471313
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user request a reminder for concert tickets before or after the reminder for the team lunch pizza?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "concert tickets reminder set for 12:00 PM",
            "user requested reminder at 4 PM on January 7, 2026",
            "user set reminder for noon"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4937.828063964844,
          "generation_latency_ms": 5280.430316925049,
          "scoring_latency_ms": 3049.000024795532,
          "total_latency_ms": 13267.258405685425
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "When offered the option to filter the Sales Lead's distracting messages, what was the user's decision?",
          "answer_type": "short_answer",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user plans to message James",
            "3bcd041f-6ae6-48da-9767-a686eee70c9c fond of Luna",
            "James holds role Sales Lead"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5659.452199935913,
          "generation_latency_ms": 6492.311477661133,
          "scoring_latency_ms": 3454.273462295532,
          "total_latency_ms": 15606.037139892578
        },
        {
          "probe_id": "preference_learning-constraint_hierarchy-1",
          "pillar": "preference_learning",
          "subpillar": "constraint_hierarchy",
          "question": "Why did the user choose not to filter James's messages despite the distractions?",
          "answer_type": "short_answer",
          "gold_answer": "To stay in the loop",
          "predicted_answer": "To stay in the loop in case he actually closes a deal.",
          "retrieved_context": [
            "user plans to message James",
            "f049d2b7-d739-4af9-ba5f-28357b634056 distracted during standup meeting",
            "d7229d8b-da4c-4030-a08c-8d28c4b36da8 distracts Alex"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5799.102544784546,
          "generation_latency_ms": 4184.4282150268555,
          "scoring_latency_ms": 3462.148427963257,
          "total_latency_ms": 13445.679187774658
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the 'PaymentGateway' service?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB3 hosted on Google Cloud Platform",
            "PrimaryDB3 hosted on Google Cloud Platform",
            "AuthService7 hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5796.7729568481445,
          "generation_latency_ms": 5430.867910385132,
          "scoring_latency_ms": 3445.878028869629,
          "total_latency_ms": 14673.518896102905
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "What is the name of the Backend Lead's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Will has role Backend Lead",
            "Will holds role Backend Lead",
            "8028e88e-0bf9-4896-a3f1-53e623774cf5 led by Will"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5020.710706710815,
          "generation_latency_ms": 5348.126411437988,
          "scoring_latency_ms": 3026.498556137085,
          "total_latency_ms": 13395.335674285889
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What recurring weekly event does the user repeatedly ask the assistant to help prepare for?",
          "answer_type": "short_answer",
          "gold_answer": "Sync with Mia",
          "predicted_answer": "Meeting with cofounder",
          "retrieved_context": [
            "e4cb38fe-4e00-491e-9847-8fab5d43bc5a involves cofounder",
            "user has scheduled dentist appointment",
            "quarterly review noted as not scheduled yet user calendar"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5783.244848251343,
          "generation_latency_ms": 6467.120885848999,
          "scoring_latency_ms": 3746.056318283081,
          "total_latency_ms": 15996.422052383423
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-1",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "Is the service managed by the Backend Lead hosted on the same platform as the Analytics Engine?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Yes",
          "retrieved_context": [
            "766e77bf-7b77-4c6a-a25d-cb821c92bfb6 hosted on Azure",
            "analytics engine hosted on Azure",
            "c2af27cc-d2b8-4d09-a76f-e9dbf77a7a67 hosted on Azure"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5532.46545791626,
          "generation_latency_ms": 4667.094707489014,
          "scoring_latency_ms": 2976.9604206085205,
          "total_latency_ms": 13176.520586013794
        }
      ],
      "summary": {
        "overall_accuracy": 0.5833333333333334,
        "total_score": 7,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 9,
            "accuracy": 0.5555555555555556
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 3,
            "accuracy": 0.6666666666666666
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_006.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 11,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 151.79101634025574,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the 'Backend Lead' investigating the database discrepancies?",
          "answer_type": "short_answer",
          "gold_answer": "Sophia",
          "predicted_answer": "Sophia",
          "retrieved_context": [
            "user needs to talk to backend lead",
            "Backend Lead is duplicate of Backend Lead",
            "Alex requests concerns from Backend leads"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 9711.442947387695,
          "generation_latency_ms": 5590.193033218384,
          "scoring_latency_ms": 5132.115840911865,
          "total_latency_ms": 20433.751821517944
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the organizational role of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales Lead",
          "retrieved_context": [
            "James owner of Luna",
            "Luna was posted about in general channel",
            "James owns Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4837.172985076904,
          "generation_latency_ms": 5350.675344467163,
          "scoring_latency_ms": 2910.6903076171875,
          "total_latency_ms": 13098.538637161255
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which cloud provider hosts the service associated with the CEO's login errors?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "AWS",
          "retrieved_context": [
            "PrimaryDB8 possibly hosted on AWS",
            "fd870a8a-909a-4e15-8928-f8826f20f871 possibly hosted on AWS",
            "PrimaryDB8 possibly hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6355.904102325439,
          "generation_latency_ms": 5840.592384338379,
          "scoring_latency_ms": 5119.904279708862,
          "total_latency_ms": 17316.40076637268
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Is the primary database currently confirmed to be hosted in a single environment?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "fbf75713-bfab-4f05-b2b6-8e75d51af19c possibly hosted on Azure",
            "PrimaryDB8 possibly hosted on Azure",
            "bb4951e2-610e-4e58-93a6-dbb9d2257a3d expected to be hosted on AWS"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6436.904668807983,
          "generation_latency_ms": 4825.097322463989,
          "scoring_latency_ms": 2812.6115798950195,
          "total_latency_ms": 14074.613571166992
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific activity caused the user's lack of sleep before the auth service check?",
          "answer_type": "short_answer",
          "gold_answer": "quarterly strategy call",
          "predicted_answer": "Will kept him on the phone late talking about the quarterly strategy.",
          "retrieved_context": [
            "7a72fd51-f8df-448b-9746-3a6f56730939 reported by AuthService7",
            "Mia monitoring client side issues for auth service",
            "Alex requested status of authentication service"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6008.830785751343,
          "generation_latency_ms": 3920.449733734131,
          "scoring_latency_ms": 2759.7153186798096,
          "total_latency_ms": 12688.995838165283
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What item did the user ask to be reminded to buy while checking the load balancer logs?",
          "answer_type": "short_answer",
          "gold_answer": "coffee beans",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user checking status of LoadBalancer5",
            "traffic logs retrieved from LoadBalancer5",
            "eeff0494-db48-4122-acd8-5953ff5076be status checked by user"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6409.237623214722,
          "generation_latency_ms": 5000.677108764648,
          "scoring_latency_ms": 2988.003730773926,
          "total_latency_ms": 14397.918462753296
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "When reviewing the CEO's agendas, which department's representation does the user explicitly prioritize?",
          "answer_type": "short_answer",
          "gold_answer": "engineering",
          "predicted_answer": "Engineering",
          "retrieved_context": [
            "a729e4d3-87d9-4a4d-b9a3-a64c9857a87a focuses on product roadmap",
            "c5a85aaf-1926-4ce4-acf3-fb5012c98cd7 may receive report about AuthService7",
            "Will worried about overspending on CEO budget"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5471.870183944702,
          "generation_latency_ms": 2759.772777557373,
          "scoring_latency_ms": 2911.3686084747314,
          "total_latency_ms": 11143.011569976807
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-7",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the user's mechanic?",
          "answer_type": "short_answer",
          "gold_answer": "unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex has reminder to call mechanic call reminder",
            "02e80536-70b4-4894-b6c5-2bb09325413f wanted reminder to call mechanic at 10 AM",
            "2e8572ae-a5c6-482b-a142-7772c9894d54 inquiring about user experience on AuthService7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5487.764835357666,
          "generation_latency_ms": 3064.555883407593,
          "scoring_latency_ms": 2629.7056674957275,
          "total_latency_ms": 11182.026386260986
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific version number is the Analytics Engine currently running?",
          "answer_type": "short_answer",
          "gold_answer": "unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "analytics engine alias of AnalyticsEngine2",
            "613d2086-a524-4db5-ba27-96af8ee25319 running on AWS",
            "user inquiring status of analytics engine"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5348.95396232605,
          "generation_latency_ms": 2702.9383182525635,
          "scoring_latency_ms": 2723.148822784424,
          "total_latency_ms": 10775.041103363037
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-9",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What technical configuration is suspected to be the cause of the cofounder's login errors?",
          "answer_type": "short_answer",
          "gold_answer": "beta version traffic",
          "predicted_answer": "AuthService7 drifting to version 2.0.0-beta",
          "retrieved_context": [
            "Will experiencing login errors on AuthService7",
            "0b4ae8e0-63fe-4694-aa65-0a5a1191ea36 possibly triggering load balancer metrics",
            "88080381-d35c-4c93-b364-391e6dab7f0f concerned about billing for PrimaryDB8"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6547.800540924072,
          "generation_latency_ms": 4760.748624801636,
          "scoring_latency_ms": 2755.1770210266113,
          "total_latency_ms": 14063.72618675232
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-10",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What action did the user plan to take regarding the product roadmap agenda sent by the CEO?",
          "answer_type": "generation",
          "gold_answer": "review for engineering representation",
          "predicted_answer": "review it",
          "retrieved_context": [
            "agenda for all-hands meeting focuses on product roadmap",
            "Will emailed agenda for all-hands meeting",
            "strategy meeting with Will included participant Will"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4915.066480636597,
          "generation_latency_ms": 4906.888961791992,
          "scoring_latency_ms": 2777.1501541137695,
          "total_latency_ms": 12599.105596542358
        }
      ],
      "summary": {
        "overall_accuracy": 0.8181818181818182,
        "total_score": 9,
        "count": 11,
        "by_answer_type": {
          "short_answer": {
            "total": 8,
            "count": 9,
            "accuracy": 0.8888888888888888
          },
          "boolean": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "generation": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_007.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 166.56251049041748,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the 'cofounder' that the user reviewed the infrastructure bill with?",
          "answer_type": "short_answer",
          "gold_answer": "Will",
          "predicted_answer": "Will",
          "retrieved_context": [
            "cofounder participated in infrastructure bill review",
            "user participated in infrastructure bill review",
            "196d210c-e56e-4e0a-8138-a66fd894402c requested infrastructure audit before board meeting"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5227.31876373291,
          "generation_latency_ms": 4827.266216278076,
          "scoring_latency_ms": 2629.880428314209,
          "total_latency_ms": 12684.465408325195
        },
        {
          "probe_id": "world_modeling-category_membership-2",
          "pillar": "world_modeling",
          "subpillar": "type_category_membership",
          "question": "Which employees require access to the beta database for their data science models?",
          "answer_type": "short_answer",
          "gold_answer": "Lucas and James",
          "predicted_answer": "Lucas, James",
          "retrieved_context": [
            "data science guys need access to PrimaryDB9",
            "data science guys need access to GCP cache instance",
            "1bf76330-03c7-44bf-82a5-681ce72ce71b runs queries on AnalyticsEngine6"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5157.296895980835,
          "generation_latency_ms": 5115.204334259033,
          "scoring_latency_ms": 2941.3790702819824,
          "total_latency_ms": 13213.88030052185
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the database that is running the v2.0.0-beta hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "database hosted on Microsoft's cloud",
            "PrimaryDB9 running version version 2.0.0-beta",
            "database hosted in Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7448.4076499938965,
          "generation_latency_ms": 4763.664245605469,
          "scoring_latency_ms": 2820.984363555908,
          "total_latency_ms": 15033.056259155273
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-4",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Despite earlier ambiguous logs, what version was PrimaryDB9 confirmed to be running during the final infrastructure audit?",
          "answer_type": "short_answer",
          "gold_answer": "v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "database upgrade upgrade of PrimaryDB9",
            "maintenance window intended to resolve PrimaryDB9",
            "Will reported stability issues on PrimaryDB9"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6694.586277008057,
          "generation_latency_ms": 4618.283748626709,
          "scoring_latency_ms": 2653.632640838623,
          "total_latency_ms": 13966.502666473389
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-5",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific distraction caused the Product Designer to fail to deliver the UI assets on time?",
          "answer_type": "short_answer",
          "gold_answer": "His cat Luna",
          "predicted_answer": "Luna knocked a glass of water onto his keyboard",
          "retrieved_context": [
            "Product Designer delivered UI assets",
            "Luna interrupted design sync",
            "Oliver responsible for UI assets"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8283.093214035034,
          "generation_latency_ms": 4904.134511947632,
          "scoring_latency_ms": 2691.7765140533447,
          "total_latency_ms": 15879.00424003601
        },
        {
          "probe_id": "temporal_episodic-sequencing-6",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user ask for a reminder to buy cat treats before or after the final infrastructure audit?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "After",
          "retrieved_context": [
            "user plans to buy treats",
            "Alex set reminder for reminder to pick up dry cleaning",
            "user set reminder for 5 PM"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4551.931381225586,
          "generation_latency_ms": 4760.545015335083,
          "scoring_latency_ms": 2705.371379852295,
          "total_latency_ms": 12017.847776412964
        },
        {
          "probe_id": "preference_learning-induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What specific beverage does the user consistently consume before starting their morning work?",
          "answer_type": "short_answer",
          "gold_answer": "Espresso",
          "predicted_answer": "Espresso",
          "retrieved_context": [
            "office coffee machine is broken for user",
            "coffee beans planned to pick up user",
            "user scheduled espresso machine repair call at 2 PM on January 7, 2026"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8498.759508132935,
          "generation_latency_ms": 2871.202230453491,
          "scoring_latency_ms": 2772.5613117218018,
          "total_latency_ms": 14142.523050308228
        },
        {
          "probe_id": "preference_learning-explicit-8",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Does the user prefer to rollback the Azure database to v1.2.0 immediately following the audit?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB9 has rollback version v1.2.0 rollback",
            "user attempting rollback to stable version PrimaryDB9",
            "user attempting rollback to stable version PrimaryDB9"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6530.890941619873,
          "generation_latency_ms": 4541.457176208496,
          "scoring_latency_ms": 2801.8393516540527,
          "total_latency_ms": 13874.187469482422
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the current running version of the primary database hosted on GCP?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "a9a8f5ac-04dd-449f-90d0-bdc46ee607e8 hosted on GCP",
            "PrimaryDB6 hosted on GCP",
            "PrimaryDB6 running on Google Cloud services"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6019.109010696411,
          "generation_latency_ms": 4516.392230987549,
          "scoring_latency_ms": 2849.0257263183594,
          "total_latency_ms": 13384.52696800232
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Sales Lead's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "sales lead works at office",
            "Liam chasing sales lead",
            "Sales Lead conducting demo with prospect"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5735.875606536865,
          "generation_latency_ms": 4620.66650390625,
          "scoring_latency_ms": 4467.691421508789,
          "total_latency_ms": 14824.233531951904
        },
        {
          "probe_id": "procedural_knowledge-task_tracking-11",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "What shopping task did the user ask the assistant to add to their list regarding the Product Designer's pet?",
          "answer_type": "short_answer",
          "gold_answer": "Buy treats for Luna",
          "predicted_answer": "buy treats for Luna",
          "retrieved_context": [
            "buy sandwich bread added to task list for user",
            "assistant will remind to text user",
            "user plans to buy treats"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5664.952754974365,
          "generation_latency_ms": 2792.98734664917,
          "scoring_latency_ms": 3034.512519836426,
          "total_latency_ms": 11492.452621459961
        },
        {
          "probe_id": "procedural_knowledge-task_tracking-12",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "What reminder did the user set for themselves before the standup meeting in the first recorded session?",
          "answer_type": "short_answer",
          "gold_answer": "Grab an extra espresso",
          "predicted_answer": "5 PM",
          "retrieved_context": [
            "user plans to inform standup meeting",
            "user set reminder for 5 PM",
            "Reminder set for January 7, 2026 12:30 PM"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8416.212797164917,
          "generation_latency_ms": 4917.014122009277,
          "scoring_latency_ms": 2699.089288711548,
          "total_latency_ms": 16032.316207885742
        }
      ],
      "summary": {
        "overall_accuracy": 0.5833333333333334,
        "total_score": 7,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 9,
            "accuracy": 0.5555555555555556
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_008.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 158.96275877952576,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "What is the name of the individual referred to as the user's cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Elijah",
          "retrieved_context": [
            "strategy meeting with cofounder attended by user",
            "cofounder pushing for new reporting features",
            "strategy meeting with cofounder attended by Elijah"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6094.5725440979,
          "generation_latency_ms": 4817.983388900757,
          "scoring_latency_ms": 3167.027711868286,
          "total_latency_ms": 14079.583644866943
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which analytics service is hosted on a different cloud provider than the primary database?",
          "answer_type": "short_answer",
          "gold_answer": "AnalyticsEngine9",
          "predicted_answer": "AnalyticsEngine9",
          "retrieved_context": [
            "AnalyticsEngine9 hosted on Microsoft cloud",
            "AnalyticsEngine9 connected via cross-cloud link",
            "7f4d0895-2f70-4edb-be24-05d22a79c345 deployed on Amazon Web Services"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4992.408037185669,
          "generation_latency_ms": 4975.879669189453,
          "scoring_latency_ms": 2815.171480178833,
          "total_latency_ms": 12783.459186553955
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud platform is the database instance that is signalling version v2.0.0-beta hosted?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "Amazon Web Services",
          "retrieved_context": [
            "primary database running version v2.0.0-beta",
            "PrimaryDB1 signaling version v2.0.0-beta",
            "primary database running version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4776.95369720459,
          "generation_latency_ms": 3672.229528427124,
          "scoring_latency_ms": 3908.3454608917236,
          "total_latency_ms": 12357.528686523438
        },
        {
          "probe_id": "declarative_reasoning-baseline_factual_recall-3",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What two specific version numbers are currently conflicting in the primary database logs?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "primary database reported as version version 2.0.0 beta",
            "primary database reported as version version 1.2.0",
            "e6b9a558-fabd-4654-9194-c7106fd904c4 may cause latency in production environment"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8232.791900634766,
          "generation_latency_ms": 4503.304958343506,
          "scoring_latency_ms": 2584.544897079468,
          "total_latency_ms": 15320.64175605774
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-4",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user mention fixing a leaky faucet before or after the discussion about Azure latency?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "72588c8b-5eca-44ba-8c99-127c59cd80f1 wants to ping Liam",
            "James missed database upgrade memo",
            "James distracted user"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5295.704364776611,
          "generation_latency_ms": 3885.8559131622314,
          "scoring_latency_ms": 2658.1897735595703,
          "total_latency_ms": 11839.750051498413
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What domestic task did the user mention as the reason for their weekend feeling too short?",
          "answer_type": "short_answer",
          "gold_answer": "Fixing a leaky faucet",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "dry cleaning reminder scheduled for this evening",
            "User wants reminder for dry cleaning",
            "Alex needs to pick up dry cleaning"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6028.823137283325,
          "generation_latency_ms": 2952.524423599243,
          "scoring_latency_ms": 4659.261226654053,
          "total_latency_ms": 13640.608787536621
        },
        {
          "probe_id": "preference_learning-explicit_preferences-6",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "When requesting a reminder for coffee beans, what specific variety did the user specify?",
          "answer_type": "short_answer",
          "gold_answer": "Dark roast",
          "predicted_answer": "dark roast",
          "retrieved_context": [
            "Alex wants to be reminded to buy coffee beans",
            "dark roast coffee beans reminder set for 5 PM on January 7, 2026",
            "Alex wants to pick up dark roast coffee beans"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5322.553396224976,
          "generation_latency_ms": 2767.1875953674316,
          "scoring_latency_ms": 2603.358507156372,
          "total_latency_ms": 10693.09949874878
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "How does the user characterize the billing situation resulting from the multi-cloud setup?",
          "answer_type": "short_answer",
          "gold_answer": "Fragmented",
          "predicted_answer": "Billing fragmentation",
          "retrieved_context": [
            "billing fragmentation caused by multi-cloud setup",
            "3561c4a5-aa81-49df-841b-8d75b0a3c7c9 includes AWS",
            "3561c4a5-aa81-49df-841b-8d75b0a3c7c9 includes Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4721.055030822754,
          "generation_latency_ms": 2866.292715072632,
          "scoring_latency_ms": 2603.1227111816406,
          "total_latency_ms": 10190.470457077026
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the pet belonging to the Frontend Lead?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Liam holds role Frontend Lead",
            "Liam holds role Frontend Lead",
            "Liam leads frontend"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6505.702972412109,
          "generation_latency_ms": 2616.2073612213135,
          "scoring_latency_ms": 2995.2127933502197,
          "total_latency_ms": 12117.123126983643
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What version of software is the Load Balancer currently reporting?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "CacheLayer7 both report healthy LoadBalancer1",
            "ac03fca9-cadb-4e7b-909c-fd5cba7650da hosted on Amazon cloud",
            "AWS hosts load balancer LB-1"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5488.501071929932,
          "generation_latency_ms": 4201.434373855591,
          "scoring_latency_ms": 2788.858652114868,
          "total_latency_ms": 12478.79409790039
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What structural factor did the assistant identify as the cause of the latency on the Azure instance?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-region calls",
          "predicted_answer": "The hop over to Azure",
          "retrieved_context": [
            "df5a721d-a68a-47d4-8655-1fe20e369146 occurring between AWS",
            "Engine 9 shows latency issue",
            "fc57eec5-1cd7-4076-b34c-4fb02700e6e2 concerns AnalyticsEngine9"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8580.998182296753,
          "generation_latency_ms": 5947.427272796631,
          "scoring_latency_ms": 2863.4555339813232,
          "total_latency_ms": 17391.880989074707
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-11",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "What action did the assistant suggest to address the latency issues observed by the cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Draft migration plan",
          "predicted_answer": "Check the logs",
          "retrieved_context": [
            "Engine 9 shows latency issue",
            "da68b67d-c7a4-4326-b36c-160b1db3e0ad inquired about stability of PrimaryDB1",
            "frontend lead has not flagged UI latency"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8660.056591033936,
          "generation_latency_ms": 4868.29686164856,
          "scoring_latency_ms": 2524.7275829315186,
          "total_latency_ms": 16053.081035614014
        }
      ],
      "summary": {
        "overall_accuracy": 0.6666666666666666,
        "total_score": 8,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 10,
            "accuracy": 0.6
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_009.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 27,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 175.65321373939514,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual referred to by the user as 'my cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Lucas",
          "predicted_answer": "Lucas",
          "retrieved_context": [
            "meeting with cofounder focused on personnel discussion",
            "Lucas cofounder of user",
            "meeting with cofounder with Lucas"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7838.490962982178,
          "generation_latency_ms": 4265.712261199951,
          "scoring_latency_ms": 2746.3455200195312,
          "total_latency_ms": 14850.54874420166
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which cloud provider hosts the database service that the Backend Lead named Oliver is concerned about?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "AWS",
          "retrieved_context": [
            "Oliver member of backend team",
            "Oliver knows about eighth primary db instance",
            "be5c0e7b-9b10-4edd-9abd-b29739d629f1 manages PrimaryDB7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5139.1026973724365,
          "generation_latency_ms": 5053.194999694824,
          "scoring_latency_ms": 23597.002029418945,
          "total_latency_ms": 33789.299726486206
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Identify the team member who holds the same job title as the owner of the cat named Luna.",
          "answer_type": "short_answer",
          "gold_answer": "Oliver",
          "predicted_answer": "Oliver",
          "retrieved_context": [
            "backend lead owns Luna",
            "Liam worried about PrimaryDB8",
            "Liam serves as backend lead for Nebula Corp"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4893.641233444214,
          "generation_latency_ms": 3650.449752807617,
          "scoring_latency_ms": 2670.7139015197754,
          "total_latency_ms": 11214.804887771606
        },
        {
          "probe_id": "declarative_reasoning-state_tracking-2",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What two specific version numbers are currently detected running simultaneously on the AWS database?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "Amazon-hosted instance PrimaryDB8 currently running version v1.2.0",
            "Amazon-hosted instance PrimaryDB8 testing version v2.0.0-beta",
            "eighth primary db instance running version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8886.863946914673,
          "generation_latency_ms": 5505.082607269287,
          "scoring_latency_ms": 2709.5274925231934,
          "total_latency_ms": 17101.474046707153
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Based on the user's schedule, which task occurs earlier in the day: approving the budget report or picking up dry cleaning?",
          "answer_type": "short_answer",
          "gold_answer": "Approving budget report",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user reminded to pick up dry cleaning",
            "dry cleaning reminder scheduled for 5:00 PM",
            "user set reminder for dry cleaning reminder at 5 PM"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4754.675626754761,
          "generation_latency_ms": 3628.355026245117,
          "scoring_latency_ms": 2704.740047454834,
          "total_latency_ms": 11087.770700454712
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-2",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What technical issue is identified as the cause of the latency on the PrimaryDB8 instance?",
          "answer_type": "short_answer",
          "gold_answer": "Conflicting versions",
          "predicted_answer": "version discrepancy",
          "retrieved_context": [
            "36d5ede6-eaf5-4020-85b3-b700fe310356 related to PrimaryDB8",
            "PrimaryDB8 conflict investigation focused on PrimaryDB8",
            "monitoring tools monitoring PrimaryDB8"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8992.61212348938,
          "generation_latency_ms": 4806.063413619995,
          "scoring_latency_ms": 2908.5123538970947,
          "total_latency_ms": 16707.18789100647
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's reaction to the beta push, do they currently prioritize rapid deployment or production stability?",
          "answer_type": "short_answer",
          "gold_answer": "Production stability",
          "predicted_answer": "Production stability",
          "retrieved_context": [
            "PrimaryDB8 flagging versions beta deployment of PrimaryDB8 v2.0.0-beta",
            "Lucas authorized beta deployment of PrimaryDB8 v2.0.0-beta",
            "Liam stressing about v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5614.956855773926,
          "generation_latency_ms": 3358.9048385620117,
          "scoring_latency_ms": 2576.1592388153076,
          "total_latency_ms": 11550.020933151245
        },
        {
          "probe_id": "preference_learning-explicit_preferences-2",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What beverage does the user explicitly rely on to 'wake up properly' in the morning?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "third coffee of the day consumed on January 7, 2026",
            "Luna knocked over coffee",
            "22368c17-8c61-4900-8b4e-dc8b5032a2d3 owes treat for Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5962.969541549683,
          "generation_latency_ms": 3374.8202323913574,
          "scoring_latency_ms": 2630.6238174438477,
          "total_latency_ms": 11968.413591384888
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the specific running version number of the database hosted on Azure?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB7 hosted on Azure",
            "PrimaryDB7 hosted on Microsoft Azure",
            "Amazon-hosted instance PrimaryDB8 currently running version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5269.673585891724,
          "generation_latency_ms": 3722.5682735443115,
          "scoring_latency_ms": 2634.0935230255127,
          "total_latency_ms": 11626.335382461548
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-2",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Product Designer's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Emma requested for Product Design prototype",
            "Emma has role Product Designer",
            "Emma leads product design for Nebula Corp"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5148.019313812256,
          "generation_latency_ms": 2834.890365600586,
          "scoring_latency_ms": 2763.108015060425,
          "total_latency_ms": 10746.017694473267
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What specific data does the user typically request to prepare for a strategy meeting with the CEO?",
          "answer_type": "short_answer",
          "gold_answer": "Latest metrics",
          "predicted_answer": "latest metrics",
          "retrieved_context": [
            "meeting with cofounder focused on personnel discussion",
            "Lucas asked about quarterly projections inquiry",
            "Alex responding to quarterly projections inquiry"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6060.896873474121,
          "generation_latency_ms": 4234.125375747681,
          "scoring_latency_ms": 2752.882719039917,
          "total_latency_ms": 13047.904968261719
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-2",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What was the user's explicit instruction regarding the deployment of the beta version to production?",
          "answer_type": "short_answer",
          "gold_answer": "Do not push",
          "predicted_answer": "I told the team not to push the beta to prod yet.",
          "retrieved_context": [
            "Lucas authorized beta deployment of PrimaryDB8 v2.0.0-beta",
            "PrimaryDB8 flagging versions beta deployment of PrimaryDB8 v2.0.0-beta",
            "Amazon-hosted instance PrimaryDB8 testing version v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6035.96043586731,
          "generation_latency_ms": 3167.902708053589,
          "scoring_latency_ms": 2741.941213607788,
          "total_latency_ms": 11945.804357528687
        }
      ],
      "summary": {
        "overall_accuracy": 0.9166666666666666,
        "total_score": 11,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 9,
            "count": 10,
            "accuracy": 0.9
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_010.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 26,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 156.22318077087402,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which cloud provider hosts the service managed by the Backend Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "AWS",
          "retrieved_context": [
            "Elijah holds role Backend Lead",
            "CacheLayer1 hosted on AWS",
            "AuthService5 hosted on Amazon-hosted services"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4480.055570602417,
          "generation_latency_ms": 5141.589403152466,
          "scoring_latency_ms": 2855.5235862731934,
          "total_latency_ms": 12477.168560028076
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Who is the cofounder concerned about the recent spike in cloud costs?",
          "answer_type": "short_answer",
          "gold_answer": "Charlotte",
          "predicted_answer": "Charlotte",
          "retrieved_context": [
            "cofounder asking about Azure bill spike this month",
            "Alex cofounder of Charlotte",
            "Charlotte worried about dashboard latency"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6184.113502502441,
          "generation_latency_ms": 4321.974039077759,
          "scoring_latency_ms": 2684.2641830444336,
          "total_latency_ms": 13190.351724624634
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Backend Lead",
          "predicted_answer": "Backend Lead",
          "retrieved_context": [
            "Elijah owner of Luna",
            "Elijah owns Luna",
            "vet appointment for Luna for Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4685.33730506897,
          "generation_latency_ms": 3287.992238998413,
          "scoring_latency_ms": 3412.407875061035,
          "total_latency_ms": 11385.737419128418
        },
        {
          "probe_id": "declarative_reasoning-state_tracking-1",
          "pillar": "declarative_reasoning",
          "subpillar": "task_state_tracking",
          "question": "Which two version numbers are simultaneously reported by the sixth cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "CacheLayer6 reports version v1.2.0",
            "64c7321b-fb0c-4214-a31a-7553d6cba1df reported version v1.2.0",
            "CacheLayer6 reports version active process version v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7836.136102676392,
          "generation_latency_ms": 2999.3114471435547,
          "scoring_latency_ms": 2885.9786987304688,
          "total_latency_ms": 13721.426248550415
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-0",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What specific activity by the Data Scientist was identified as the cause of the Azure bill spike?",
          "answer_type": "short_answer",
          "gold_answer": "Running heavy models",
          "predicted_answer": "running heavy models",
          "retrieved_context": [
            "cofounder asking about Azure bill spike this month",
            "AnalyticsEngine6 hosted on Microsoft Azure",
            "AnalyticsEngine6 deployed on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6059.266090393066,
          "generation_latency_ms": 4147.658348083496,
          "scoring_latency_ms": 3070.7688331604004,
          "total_latency_ms": 13277.693271636963
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-1",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "When the user requested a ticket be created regarding the deployment manifest, who was the intended recipient?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Elijah",
          "retrieved_context": [
            "Elijah to look at deployment manifest",
            "23147539-940a-4114-b7ba-0185e67d94c5 concerned about deployment issue in CacheLayer6",
            "23147539-940a-4114-b7ba-0185e67d94c5 will involve to help debug Will"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7205.897808074951,
          "generation_latency_ms": 3781.7611694335938,
          "scoring_latency_ms": 2730.7353019714355,
          "total_latency_ms": 13718.39427947998
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What beverage does the user consistently request before morning meetings?",
          "answer_type": "short_answer",
          "gold_answer": "Espresso",
          "predicted_answer": "Coffee or espresso",
          "retrieved_context": [
            "user just returned from coffee shop",
            "user just returned from coffee shop",
            "036cdf29-d459-47f0-b89f-a8d95e310988 located in coffee shop"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5278.142690658569,
          "generation_latency_ms": 4522.991895675659,
          "scoring_latency_ms": 2723.6406803131104,
          "total_latency_ms": 12524.775266647339
        },
        {
          "probe_id": "preference_learning-belief_revision-1",
          "pillar": "preference_learning",
          "subpillar": "belief_revision",
          "question": "What is the final confirmed time for the dentist appointment, overriding the initially suggested time?",
          "answer_type": "short_answer",
          "gold_answer": "3 PM",
          "predicted_answer": "3 PM",
          "retrieved_context": [
            "dentist appointment scheduled at time 2:00 PM",
            "dentist appointment scheduled for January 7, 2026 15:00:00",
            "user has scheduled dentist appointment"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5334.644079208374,
          "generation_latency_ms": 4793.3619022369385,
          "scoring_latency_ms": 2542.1628952026367,
          "total_latency_ms": 12670.16887664795
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific software version is CacheLayer3 currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "CacheLayer6 running version v1.2.0",
            "CacheLayer6 reporting version v1.2.0",
            "CacheLayer6 reports version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5101.322174072266,
          "generation_latency_ms": 4293.996334075928,
          "scoring_latency_ms": 2703.134298324585,
          "total_latency_ms": 12098.452806472778
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who is the current Project Manager for the Nebula organization?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User plans to sync with about ui changes Noah",
            "User plans to sync with about ui changes Noah",
            "user will involve to help debug Noah"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5867.052316665649,
          "generation_latency_ms": 2609.760046005249,
          "scoring_latency_ms": 2794.196128845215,
          "total_latency_ms": 11271.008491516113
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-0",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the discussion about the Azure bill spike occur before or after the user first noticed the version conflict on CacheLayer6?",
          "answer_type": "short_answer",
          "gold_answer": "After",
          "predicted_answer": "After",
          "retrieved_context": [
            "cofounder asking about Azure bill spike this month",
            "versioning conflict on CacheLayer6 causes latency",
            "versioning conflict on CacheLayer6 involves CacheLayer6"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7387.811183929443,
          "generation_latency_ms": 5230.485439300537,
          "scoring_latency_ms": 2701.718330383301,
          "total_latency_ms": 15320.014953613281
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What action by the Backend Lead likely caused the split versioning on the Azure cache instance?",
          "answer_type": "short_answer",
          "gold_answer": "Leaving canary deployment active",
          "predicted_answer": "Pushed beta version to CacheLayer6",
          "retrieved_context": [
            "versioning issue confuses load balancer",
            "a04118de-a41b-44ea-8a13-f48a153c2a91 investigates version mismatch",
            "CacheLayer6 deployed on Azure environment"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6917.710304260254,
          "generation_latency_ms": 4766.916275024414,
          "scoring_latency_ms": 2864.5927906036377,
          "total_latency_ms": 14549.219369888306
        }
      ],
      "summary": {
        "overall_accuracy": 0.8333333333333334,
        "total_score": 10,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 8,
            "count": 10,
            "accuracy": 0.8
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_011.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 28,
      "num_probes": 7,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 86.55206155776978,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual referred to as the user's cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "Liam",
          "retrieved_context": [
            "Alex has cofounder cofounder",
            "user cofounder of Liam",
            "cofounder worried about investor demo"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4954.315423965454,
          "generation_latency_ms": 3311.026096343994,
          "scoring_latency_ms": 2672.4631786346436,
          "total_latency_ms": 10937.804698944092
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the name of the pet belonging to the engineer currently debugging the Amazon infrastructure?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "Mia debugging Amazon infrastructure",
            "c345a490-5d3d-4731-8474-6403832b8899 humorously caused version conflict on LoadBalancer8",
            "Alex checking services on Amazon Web Services"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5701.281309127808,
          "generation_latency_ms": 3046.624183654785,
          "scoring_latency_ms": 2890.5954360961914,
          "total_latency_ms": 11638.500928878784
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-2",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific missing asset is causing the Sales Lead to panic about the TechGlobal deal?",
          "answer_type": "short_answer",
          "gold_answer": "New dashboard",
          "predicted_answer": "new dashboard design",
          "retrieved_context": [
            "Lucas concerned about closing TechGlobal deal",
            "new dashboard design needed for TechGlobal deal",
            "Lucas worried about client demos"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6700.824975967407,
          "generation_latency_ms": 2839.2250537872314,
          "scoring_latency_ms": 2594.542980194092,
          "total_latency_ms": 12134.59300994873
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-3",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific task is the Data Scientist, Sophia, currently working on?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "model training",
          "retrieved_context": [
            "Sophia possibly running data experiment",
            "Sophia responsible for model training",
            "dfd88a67-661f-4198-b0da-eb09721ad1bd working on new models"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6425.826072692871,
          "generation_latency_ms": 5144.373893737793,
          "scoring_latency_ms": 2853.0287742614746,
          "total_latency_ms": 14423.228740692139
        },
        {
          "probe_id": "preference_learning-explicit_preferences-4",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What beverage does the user repeatedly request in the morning sessions?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "double shot of espresso",
          "retrieved_context": [
            "user wants double shot of espresso",
            "user plans to take coffee break",
            "user set reminder for coffee beans reminder"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5781.306028366089,
          "generation_latency_ms": 2673.3763217926025,
          "scoring_latency_ms": 2849.630832672119,
          "total_latency_ms": 11304.31318283081
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-5",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What versions are currently conflicting on LoadBalancer8 according to the latest status check?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "51000b08-ccf5-4f1a-af39-2f3a7f789e1b occurred on LoadBalancer8",
            "d6376411-cd46-4eaf-91d1-526e2a15c4ce exhibits version conflict",
            "dea80606-93ec-49af-a122-5791538e2a15 involves version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5753.6280155181885,
          "generation_latency_ms": 3213.702917098999,
          "scoring_latency_ms": 2673.4366416931152,
          "total_latency_ms": 11640.767574310303
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-6",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What specific metric did the assistant check to verify the connection between the AWS auth service and the Google database?",
          "answer_type": "short_answer",
          "gold_answer": "Latency",
          "predicted_answer": "latency",
          "retrieved_context": [
            "cross-cloud latency check checks connection from AuthService4",
            "authentication service running on Amazon Web Services",
            "1373e7c7-096d-4112-81b9-314b1c029947 needs to communicate with Google Cloud components"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8178.098440170288,
          "generation_latency_ms": 3503.3926963806152,
          "scoring_latency_ms": 2780.4505825042725,
          "total_latency_ms": 14461.941719055176
        }
      ],
      "summary": {
        "overall_accuracy": 0.7142857142857143,
        "total_score": 5,
        "count": 7,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 6,
            "accuracy": 0.8333333333333334
          },
          "abstain": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_012.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 28,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 24.441195726394653,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does system:cachelayer_8 hosted on?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google Cloud Platform",
          "retrieved_context": [
            "b2403579-bfec-4705-9842-c0eb063d9ead includes CacheLayer8",
            "3009fdc1-bde2-4109-a890-62d71b1fab67 located in Google cloud setup",
            "b2403579-bfec-4705-9842-c0eb063d9ead includes CacheLayer7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7488.049268722534,
          "generation_latency_ms": 3780.4884910583496,
          "scoring_latency_ms": 2628.7922859191895,
          "total_latency_ms": 13897.330045700073
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user plans to discuss infrastructure with Will",
            "user plans to message after Noah",
            "user plans to message after Noah"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4415.987014770508,
          "generation_latency_ms": 3394.1681385040283,
          "scoring_latency_ms": 2730.954647064209,
          "total_latency_ms": 10541.109800338745
        }
      ],
      "summary": {
        "overall_accuracy": 1.0,
        "total_score": 2,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_013.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 29.345185041427612,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does person:lucas has role?",
          "answer_type": "short_answer",
          "gold_answer": "Backend Lead",
          "predicted_answer": "Backend Lead",
          "retrieved_context": [
            "54930802-df1b-4f38-a70a-b67ec9b70aa1 holds role Backend Lead",
            "user plans to message Lucas",
            "Lucas was supposed to finish cleanup script"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5280.021190643311,
          "generation_latency_ms": 3781.6152572631836,
          "scoring_latency_ms": 2631.279706954956,
          "total_latency_ms": 11692.91615486145
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "fc1cd14b-253e-4274-b6cf-868892389881 planning to attend Coffee meeting with Olivia",
            "fc1cd14b-253e-4274-b6cf-868892389881 planning to attend Coffee meeting with Olivia",
            "39654eeb-98bd-4294-8a4b-a836eb919664 plans to message Lucas"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 10700.208187103271,
          "generation_latency_ms": 4343.4083461761475,
          "scoring_latency_ms": 2605.7486534118652,
          "total_latency_ms": 17649.365186691284
        }
      ],
      "summary": {
        "overall_accuracy": 1.0,
        "total_score": 2,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_014.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 27,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 26.741690635681152,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does person:charlotte has role?",
          "answer_type": "short_answer",
          "gold_answer": "CEO",
          "predicted_answer": "CEO",
          "retrieved_context": [
            "cofounder identity Charlotte",
            "Assistant can prepare report for Charlotte",
            "Charlotte pushing roadmap for next quarter"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8224.25103187561,
          "generation_latency_ms": 2820.3227519989014,
          "scoring_latency_ms": 2671.804189682007,
          "total_latency_ms": 13716.377973556519
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "2ab37dc8-8262-49af-8a14-5442352912e5 considering scheduling data science requirements discussion",
            "2ab37dc8-8262-49af-8a14-5442352912e5 participated in quarterly goals discussion",
            "Charlotte participated in quarterly goals discussion"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5483.427286148071,
          "generation_latency_ms": 4598.216772079468,
          "scoring_latency_ms": 2940.051794052124,
          "total_latency_ms": 13021.695852279663
        }
      ],
      "summary": {
        "overall_accuracy": 1.0,
        "total_score": 2,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_015.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 28,
      "num_probes": 11,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 141.14706087112427,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the team member responsible for the 'messy' deployment scripts mentioned by the user?",
          "answer_type": "short_answer",
          "gold_answer": "Lucas",
          "predicted_answer": "Lucas",
          "retrieved_context": [
            "DevOps guy responsible for main gateway deployment",
            "Lucas modified deployment scripts",
            "Lucas member of DevOps"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6030.723333358765,
          "generation_latency_ms": 3622.5979328155518,
          "scoring_latency_ms": 2643.4719562530518,
          "total_latency_ms": 12296.793222427368
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which cloud provider hosts the database service that is NOT co-located with the Auth service?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "a387e631-1ab7-4d83-b804-d992b80df824 located in Google's infrastructure",
            "PrimaryDB2 hosted on Google Cloud Platform",
            "PrimaryDB2 hosted on Google Cloud Platform"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4543.014049530029,
          "generation_latency_ms": 4468.545198440552,
          "scoring_latency_ms": 2860.3289127349854,
          "total_latency_ms": 11871.888160705566
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Based on the user's diagnosis, which specific database service is likely contributing to the latency reported by the cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "PrimaryDB7",
          "predicted_answer": "PrimaryDB7",
          "retrieved_context": [
            "adce35df-8df2-433c-816f-bc324217341d suspected cause hybrid cloud setup",
            "Sophia inquired about dashboard latency issue",
            "592be193-7983-436e-81ec-db46f65ccb4b involves component auth service"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4747.002601623535,
          "generation_latency_ms": 4919.219732284546,
          "scoring_latency_ms": 2652.181625366211,
          "total_latency_ms": 12318.403959274292
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-4",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What is the confirmed operational strategy for LoadBalancer9's versioning, clarifying the initial ambiguity?",
          "answer_type": "short_answer",
          "gold_answer": "Canary testing",
          "predicted_answer": "Canary deployment.",
          "retrieved_context": [
            "fa4d9292-de71-4967-8a16-8649e6359830 includes version v1.2.0",
            "5c259a21-0cf9-462e-8d26-240aaac06b05 running version v1.2.0",
            "5dfbe3e8-3abf-49ca-90f4-7476f0de0d52 running version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5742.371082305908,
          "generation_latency_ms": 4400.693655014038,
          "scoring_latency_ms": 2753.1578540802,
          "total_latency_ms": 12896.222591400146
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the discussion about the hybrid cloud latency occur before or after the user asked to ping the DevOps lead regarding the alerts?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "After",
          "retrieved_context": [
            "4a1fd76b-d5e5-4ea0-88ed-cbdf3cde0c16 caused by cross-cloud communication",
            "adce35df-8df2-433c-816f-bc324217341d suspected cause hybrid cloud setup",
            "025e79ee-cbcc-43e9-805c-4be459938c09 needs to yell at DevOps lead"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6906.243324279785,
          "generation_latency_ms": 4599.676132202148,
          "scoring_latency_ms": 2608.027696609497,
          "total_latency_ms": 14113.94715309143
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-6",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific architectural factor did the user identify as the cause for the dashboard latency around 9 AM?",
          "answer_type": "short_answer",
          "gold_answer": "Hybrid cloud setup",
          "predicted_answer": "hybrid cloud setup",
          "retrieved_context": [
            "dashboard latency issue started around 9 AM, January 7, 2026",
            "dashboard latency issue suspected cause hybrid cloud setup",
            "sales dashboard affected by cross-cloud latency"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7653.878450393677,
          "generation_latency_ms": 4397.766828536987,
          "scoring_latency_ms": 2589.1196727752686,
          "total_latency_ms": 14640.764951705933
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-7",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific version number is the CacheLayer4 service currently running?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "3cca5f3f-5e6b-4c42-ab69-b1015cbc432f deployed in Azure",
            "a0e83e19-80a3-4e62-9992-b06d4a5245f8 hosted in Azure",
            "1768f9d8-d88d-4708-b004-c3b35e079325 hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4905.478715896606,
          "generation_latency_ms": 4316.072702407837,
          "scoring_latency_ms": 2751.2662410736084,
          "total_latency_ms": 11972.817659378052
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Sales Lead's pet?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Emma holds role Sales Lead",
            "Emma holds role Sales Lead",
            "7ab59839-5090-4a42-94b8-7e6df83d01e2 notices issue with sales dashboard"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5976.662158966064,
          "generation_latency_ms": 4490.93222618103,
          "scoring_latency_ms": 2688.2071495056152,
          "total_latency_ms": 13155.80153465271
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-9",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What technical configuration has been identified as problematic for latency when running the primary database?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-cloud hosting",
          "predicted_answer": "hybrid cloud setup",
          "retrieved_context": [
            "adce35df-8df2-433c-816f-bc324217341d suspected cause hybrid cloud setup",
            "latency issues caused by cross-cloud communication",
            "592be193-7983-436e-81ec-db46f65ccb4b involves component cache layer"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8335.376262664795,
          "generation_latency_ms": 4466.827392578125,
          "scoring_latency_ms": 2716.097593307495,
          "total_latency_ms": 15518.301248550415
        },
        {
          "probe_id": "preference_learning-preference_drift-10",
          "pillar": "preference_learning",
          "subpillar": "preference_drift",
          "question": "At what time does the user currently want to be reminded about their dry cleaning, considering their most recent request?",
          "answer_type": "short_answer",
          "gold_answer": "5:30 PM",
          "predicted_answer": "5 PM",
          "retrieved_context": [
            "user set reminder for dry cleaning reminder",
            "user set reminder for dry cleaning reminder",
            "user reminded to do dry cleaning pickup"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5236.348628997803,
          "generation_latency_ms": 3625.1533031463623,
          "scoring_latency_ms": 2628.1516551971436,
          "total_latency_ms": 11489.653587341309
        },
        {
          "probe_id": "preference_learning-explicit_preferences-11",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "How does the user prefer the assistant to handle communication with the DevOps lead when he is offline?",
          "answer_type": "short_answer",
          "gold_answer": "Ping when active",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "1ba29552-5faa-404b-8c2e-b32cf8d51268 spoken by document",
            "coffee mug usually left on meeting room table",
            "Alex owner of coffee mug"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4306.680202484131,
          "generation_latency_ms": 3703.857421875,
          "scoring_latency_ms": 2844.7213172912598,
          "total_latency_ms": 10855.25894165039
        }
      ],
      "summary": {
        "overall_accuracy": 0.5454545454545454,
        "total_score": 6,
        "count": 11,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 11,
            "accuracy": 0.5454545454545454
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_016.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 27,
      "num_probes": 13,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 181.1806080341339,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which specific system is the user referring to as the 'traffic manager in our Google environment'?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer2",
          "predicted_answer": "LoadBalancer2",
          "retrieved_context": [
            "LoadBalancer2 deployed in Google environment",
            "LoadBalancer2 hosted on Google Cloud Platform",
            "LoadBalancer2 hosted on Google Cloud Platform"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7400.979518890381,
          "generation_latency_ms": 3169.4416999816895,
          "scoring_latency_ms": 2639.028787612915,
          "total_latency_ms": 13209.450006484985
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Who are the two individuals identified as arguing over the button push for the beta release?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah and James",
          "predicted_answer": "James and Elijah",
          "retrieved_context": [
            "James arguing over who pushed button for loadbalancer2",
            "Elijah arguing over who pushed button for loadbalancer2",
            "cofounder stressing about board meeting"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8715.317964553833,
          "generation_latency_ms": 3879.595994949341,
          "scoring_latency_ms": 2825.4053592681885,
          "total_latency_ms": 15420.319318771362
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person who kept the leadership team late going over quarterly strategy?",
          "answer_type": "short_answer",
          "gold_answer": "CEO",
          "predicted_answer": "Cofounder",
          "retrieved_context": [
            "quarterly strategy meeting attended by leadership team",
            "quarterly strategy meeting occurred on January 6, 2026",
            "Mia leading strategy session with Mia"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6452.946901321411,
          "generation_latency_ms": 4096.1949825286865,
          "scoring_latency_ms": 2708.5623741149902,
          "total_latency_ms": 13257.704257965088
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-4",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "On which cloud provider is the service hosted that the user described as the 'outlier on Microsoft's cloud'?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "AuthService3 hosted on Microsoft Azure",
            "AuthService3 hosted on Microsoft Azure",
            "e808cbf4-f549-42f1-9cec-e488a00fa367 hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5437.835454940796,
          "generation_latency_ms": 4206.929683685303,
          "scoring_latency_ms": 2753.7412643432617,
          "total_latency_ms": 12398.50640296936
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-5",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What two specific software versions are currently conflicting on the GCP load balancer?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "load balancer hosted on Google's cloud reporting version conflict",
            "99ea7aa5-35b4-45df-8981-a123b03c4c59 reports version conflict",
            "LoadBalancer2 expected software version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7152.7087688446045,
          "generation_latency_ms": 4454.916477203369,
          "scoring_latency_ms": 2701.2274265289307,
          "total_latency_ms": 14308.852672576904
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-6",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "According to the infrastructure review discussion, why is latency expected between the primary database and the authentication service?",
          "answer_type": "short_answer",
          "gold_answer": "Hosted on different clouds",
          "predicted_answer": "PrimaryDB3 is hosted on AWS, while AuthService3 is over on Azure.",
          "retrieved_context": [
            "cross-cloud latency issues involves authentication service",
            "cross-cloud latency issues involves main database",
            "user monitored latency of PrimaryDB3"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8361.433744430542,
          "generation_latency_ms": 3450.359344482422,
          "scoring_latency_ms": 2949.237585067749,
          "total_latency_ms": 14761.030673980713
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-7",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What personal task did the user ask to be reminded of during the conversation about cross-cloud latency?",
          "answer_type": "short_answer",
          "gold_answer": "Call dentist",
          "predicted_answer": "pick up dry cleaning",
          "retrieved_context": [
            "User considered alerting DevOps team",
            "User requested check on LoadBalancer8",
            "User has scheduled meeting 2 PM meeting"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5718.443870544434,
          "generation_latency_ms": 5136.068344116211,
          "scoring_latency_ms": 2646.5206146240234,
          "total_latency_ms": 13501.032829284668
        },
        {
          "probe_id": "preference_learning-preference_induction-8",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the assistant's preparation for the meeting, what type of infrastructure breakdown does the cofounder usually prefer?",
          "answer_type": "short_answer",
          "gold_answer": "High-level summary",
          "predicted_answer": "Infrastructure map",
          "retrieved_context": [
            "Alex preparing for infrastructure review meeting",
            "cofounder stressing about board meeting",
            "meeting with Olivia discusses impact on backend infrastructure"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 10399.288177490234,
          "generation_latency_ms": 4240.242719650269,
          "scoring_latency_ms": 2501.7435550689697,
          "total_latency_ms": 17141.274452209473
        },
        {
          "probe_id": "preference_learning-preference_scope-9",
          "pillar": "preference_learning",
          "subpillar": "preference_scope",
          "question": "Does the user have a stated preference for which cloud provider to review first during infrastructure checks?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "b2e60172-e844-4fe9-98fd-2ac249166706 reviewing infrastructure of Nebula Corp",
            "b2e60172-e844-4fe9-98fd-2ac249166706 reviewing infrastructure of Nebula Corp",
            "b2e60172-e844-4fe9-98fd-2ac249166706 will have check DevOps team"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5532.602071762085,
          "generation_latency_ms": 3660.8471870422363,
          "scoring_latency_ms": 2615.917682647705,
          "total_latency_ms": 11809.366941452026
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the current running version of the authentication service on Azure?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "AuthService3 running on Azure",
            "authentication service alias of authservice3",
            "AuthService3 hosted on Microsoft Azure"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5927.960157394409,
          "generation_latency_ms": 4727.293491363525,
          "scoring_latency_ms": 2644.4499492645264,
          "total_latency_ms": 13299.703598022461
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-11",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who is the team lead for the Analytics Engine?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex pulling utilization reports for AnalyticsEngine7",
            "AnalyticsEngine7 hosted on AWS",
            "Mia relies on AnalyticsEngine7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6805.430889129639,
          "generation_latency_ms": 4939.824104309082,
          "scoring_latency_ms": 2819.4711208343506,
          "total_latency_ms": 14564.726114273071
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-12",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "What specific action did the assistant propose to help resolve the confusion while the DevOps team argued?",
          "answer_type": "short_answer",
          "gold_answer": "Flag the discrepancy",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User considered alerting DevOps team",
            "Alex requested ping to DevOps crew",
            "e93c25b9-c2ae-4f0b-9cee-14f6e402884f needs to see issue with LoadBalancer2"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6106.276512145996,
          "generation_latency_ms": 4219.558000564575,
          "scoring_latency_ms": 2848.853588104248,
          "total_latency_ms": 13174.68810081482
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-13",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What is the user's routine for preparing for meetings with the cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Review infrastructure overview",
          "predicted_answer": "Pulling up the current infrastructure map.",
          "retrieved_context": [
            "cofounder asked about weekly standup",
            "cofounder stressing about board meeting",
            "board meeting slides sent to cofounder"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6674.800634384155,
          "generation_latency_ms": 4912.631511688232,
          "scoring_latency_ms": 2725.4748344421387,
          "total_latency_ms": 14312.906980514526
        }
      ],
      "summary": {
        "overall_accuracy": 0.46153846153846156,
        "total_score": 6,
        "count": 13,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 12,
            "accuracy": 0.5
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 3,
            "accuracy": 0.6666666666666666
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_017.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 34,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 140.71079802513123,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual referred to as 'my cofounder' by the user?",
          "answer_type": "short_answer",
          "gold_answer": "Olivia",
          "predicted_answer": "Olivia",
          "retrieved_context": [
            "user plans to talk to cofounder",
            "user has meeting sync with cofounder",
            "strategy session held with cofounder"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5378.457307815552,
          "generation_latency_ms": 3944.042921066284,
          "scoring_latency_ms": 2739.224672317505,
          "total_latency_ms": 12061.72490119934
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Who shares the Backend Lead responsibilities with the owner of the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "Will member of Backend Leads",
            "Will holds role backend lead",
            "ba4dc00d-9b21-455a-b64b-fc88be390094 leads Backend team"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4924.102306365967,
          "generation_latency_ms": 3431.6718578338623,
          "scoring_latency_ms": 2740.778684616089,
          "total_latency_ms": 11096.552848815918
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service hosted that is currently reporting conflicting versions v1.2.0 and v2.0.0-beta?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "AWS",
          "retrieved_context": [
            "AnalyticsEngine3 reports version v2.0.0-beta",
            "AnalyticsEngine3 running version v2.0.0-beta",
            "AnalyticsEngine3 reporting version v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5654.728651046753,
          "generation_latency_ms": 3409.2161655426025,
          "scoring_latency_ms": 2789.012908935547,
          "total_latency_ms": 11852.957725524902
        },
        {
          "probe_id": "declarative_reasoning-baseline_factual_recall-3",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "Which cloud provider hosts the primary database mentioned during the infrastructure map review?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "PrimaryDB5 hosted on Azure",
            "ad612550-325d-48e0-8d53-c08911b363d7 caused by cross cloud between PrimaryDB5",
            "3d535ddf-f06d-4e6a-8c8c-0860eaafcc92 includes cloud provider Amazon Web Services"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4926.8434047698975,
          "generation_latency_ms": 3085.6575965881348,
          "scoring_latency_ms": 2724.774122238159,
          "total_latency_ms": 10737.275123596191
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "According to the user, what was the specific cause of Will's distraction during their earlier call?",
          "answer_type": "short_answer",
          "gold_answer": "Luna jumping on desk",
          "predicted_answer": "Luna knocked over his coffee",
          "retrieved_context": [
            "Luna distracts Will",
            "user plans to talk to Will",
            "user plans to ask about Will"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6456.246614456177,
          "generation_latency_ms": 2750.0338554382324,
          "scoring_latency_ms": 2723.5682010650635,
          "total_latency_ms": 11929.848670959473
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "During the conversation where the user requested a 'sanity check' on the infrastructure map, where did the assistant locate AuthService6 and AuthService7?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "AWS",
          "retrieved_context": [
            "AuthService instances 6 and 7 hosted on AWS",
            "cofounder inquiring about hosting status of AuthService6",
            "cofounder inquiring about hosting status of AuthService7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5611.714124679565,
          "generation_latency_ms": 3516.6642665863037,
          "scoring_latency_ms": 2857.588291168213,
          "total_latency_ms": 11985.966682434082
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What beverage does the user imply they need before dealing with infrastructure latency or complex messes?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "6e28883d-cfd3-429b-a234-d934b678f5ee caused by three different clouds",
            "James complaining about latency issues",
            "user reminded to buy coffee beans"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5736.3128662109375,
          "generation_latency_ms": 3482.2773933410645,
          "scoring_latency_ms": 2685.556173324585,
          "total_latency_ms": 11904.146432876587
        },
        {
          "probe_id": "preference_learning-explicit_preferences-7",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Does the user explicitly state a preference for using GCP over AWS for authentication services?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "3d535ddf-f06d-4e6a-8c8c-0860eaafcc92 includes cloud provider Google Cloud Platform",
            "ad612550-325d-48e0-8d53-c08911b363d7 caused by cross cloud between AuthService1",
            "3d535ddf-f06d-4e6a-8c8c-0860eaafcc92 includes cloud provider Amazon Web Services"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6300.390243530273,
          "generation_latency_ms": 4590.577840805054,
          "scoring_latency_ms": 2701.6522884368896,
          "total_latency_ms": 13592.620372772217
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the final score of the game the user missed last night?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Olivia wants to see latest user metrics",
            "user informs Oliver",
            "user promised to send numbers to Mia"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4791.788816452026,
          "generation_latency_ms": 2737.502336502075,
          "scoring_latency_ms": 2551.536798477173,
          "total_latency_ms": 10080.827951431274
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the development environment for the Frontend Lead?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "James is Backend Lead",
            "Will member of Backend Leads",
            "three different clouds includes Amazon Web Services"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4581.619739532471,
          "generation_latency_ms": 3437.103748321533,
          "scoring_latency_ms": 2625.1773834228516,
          "total_latency_ms": 10643.900871276855
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What general observation did the assistant make about the difficulty of working from home when discussing Will's situation?",
          "answer_type": "short_answer",
          "gold_answer": "Challenging with a cat",
          "predicted_answer": "Working from home with a cat can be challenging.",
          "retrieved_context": [
            "Will working from home on January 7, 2026",
            "James helps with Will",
            "user plans to ask about Will"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5484.695196151733,
          "generation_latency_ms": 3763.1618976593018,
          "scoring_latency_ms": 2923.769235610962,
          "total_latency_ms": 12171.626329421997
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-11",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What is the documented procedure for migrating AuthService1 from GCP to AWS?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "c806218f-e99c-48b7-ae29-a19664c05d55 running on GCP",
            "82d0a3a2-805e-419c-b904-ed46a358b17b deployed on Google Cloud Platform",
            "AuthService1 requires coordination with Backend team"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5518.006801605225,
          "generation_latency_ms": 3818.270206451416,
          "scoring_latency_ms": 3298.7961769104004,
          "total_latency_ms": 12635.073184967041
        }
      ],
      "summary": {
        "overall_accuracy": 0.9166666666666666,
        "total_score": 11,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 7,
            "count": 8,
            "accuracy": 0.875
          },
          "boolean": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 3,
            "count": 3,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_018.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 28,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 154.59266352653503,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user's cofounder that was concerned about the AWS credits?",
          "answer_type": "short_answer",
          "gold_answer": "Charlotte",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "cofounder wants to ensure on track Nebula Corp",
            "Charlotte is cofounder",
            "Alex investigating caching service on AWS"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8360.118627548218,
          "generation_latency_ms": 2844.650983810425,
          "scoring_latency_ms": 2581.2723636627197,
          "total_latency_ms": 13786.041975021362
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the name of the pet belonging to the Frontend Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "Luna humorously referred to as Frontend Lead",
            "Lucas holds role Frontend Lead",
            "frontend work led by Lucas"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5118.685483932495,
          "generation_latency_ms": 3731.4882278442383,
          "scoring_latency_ms": 2798.1832027435303,
          "total_latency_ms": 11648.356914520264
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Does the service currently running v2.0.0-beta reside on the same cloud provider as PrimaryDB5?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "b4cd6151-ea84-43d6-9a17-937ffe6f352b includes PrimaryDB5",
            "PrimaryDB5 hosted on Google's cloud",
            "PrimaryDB5 hosted on Google Cloud Platform"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5406.511545181274,
          "generation_latency_ms": 3754.777669906616,
          "scoring_latency_ms": 2703.493356704712,
          "total_latency_ms": 11864.782571792603
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "According to the latest diagnostics, is CacheLayer7 running a single stable version?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No.",
          "retrieved_context": [
            "CacheLayer7 running version v1.2.0",
            "CacheLayer7 running version software version v2.0.0-beta",
            "CacheLayer7 has active version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5167.259931564331,
          "generation_latency_ms": 4273.087739944458,
          "scoring_latency_ms": 2616.7571544647217,
          "total_latency_ms": 12057.10482597351
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-0",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why was the Frontend Lead running late in the session where the user verified the database providers?",
          "answer_type": "short_answer",
          "gold_answer": "Cat knocked over monitor",
          "predicted_answer": "His cat Luna knocked over a plant.",
          "retrieved_context": [
            "b5de7182-f8c3-4a27-9254-1d422f95ed0e noticed frontend latency spiking",
            "Lucas participated in frontend standup",
            "Luna humorously referred to as Frontend Lead"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6376.802206039429,
          "generation_latency_ms": 5202.400922775269,
          "scoring_latency_ms": 2708.3969116210938,
          "total_latency_ms": 14287.600040435791
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user identify the conflicting versions on CacheLayer7 before or after learning about Lucas's monitor accident?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "After",
          "retrieved_context": [
            "Olivia investigating CacheLayer7",
            "Alex assigned to check Lucas",
            "user requested verification of version tag on CacheLayer7"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8212.120056152344,
          "generation_latency_ms": 4369.514942169189,
          "scoring_latency_ms": 2785.48002243042,
          "total_latency_ms": 15367.115020751953
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's morning routine requests, what beverage do they frequently consume?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "user planning to take coffee break",
            "user plans coffee before 2:00 PM on January 7, 2026",
            "coffee break taken by user"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5665.848970413208,
          "generation_latency_ms": 4981.964111328125,
          "scoring_latency_ms": 2653.491735458374,
          "total_latency_ms": 13301.304817199707
        },
        {
          "probe_id": "preference_learning-explicit_preferences-1",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Has the user explicitly requested to move the caching layers to GCP?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "b4cd6151-ea84-43d6-9a17-937ffe6f352b includes CacheLayer7",
            "CacheLayer7 hosted on AWS",
            "CacheLayer7 hosted on AWS infrastructure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5236.475706100464,
          "generation_latency_ms": 4427.295446395874,
          "scoring_latency_ms": 2735.121250152588,
          "total_latency_ms": 12398.892402648926
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts PrimaryDB9?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB8 hosted on Google Cloud Platform",
            "PrimaryDB8 hosted on Google's cloud",
            "PrimaryDB5 hosted on Google's cloud"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4624.31526184082,
          "generation_latency_ms": 4934.636831283569,
          "scoring_latency_ms": 2638.2040977478027,
          "total_latency_ms": 12197.156190872192
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who holds the role of VP of Marketing?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Charlotte holds role CEO",
            "user holds role CEO",
            "board meeting with Charlotte discussed role CEO role"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6811.539649963379,
          "generation_latency_ms": 4264.293432235718,
          "scoring_latency_ms": 2694.6029663085938,
          "total_latency_ms": 13770.43604850769
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What action does the assistant consistently take when the user mentions buying items like coffee beans or cat food?",
          "answer_type": "short_answer",
          "gold_answer": "Adds to shopping list",
          "predicted_answer": "Adds to shopping list",
          "retrieved_context": [
            "user reminded to buy cat food",
            "coffee beans added to shopping list for Alex",
            "user planning to take coffee break"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4453.138589859009,
          "generation_latency_ms": 2801.666021347046,
          "scoring_latency_ms": 2736.891269683838,
          "total_latency_ms": 9991.695880889893
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What is the recurring cause of interruptions during the Frontend Lead's standups?",
          "answer_type": "short_answer",
          "gold_answer": "His cat Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "Frontend Lead noticed frontend latency spiking",
            "Luna interrupted last standup meeting",
            "Luna distracting frontend team"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5914.511442184448,
          "generation_latency_ms": 5139.415740966797,
          "scoring_latency_ms": 2849.648952484131,
          "total_latency_ms": 13903.576135635376
        }
      ],
      "summary": {
        "overall_accuracy": 0.75,
        "total_score": 9,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 7,
            "accuracy": 0.5714285714285714
          },
          "boolean": {
            "total": 3,
            "count": 3,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_019.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 28,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 151.66193675994873,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user referring to when they mention their 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Emma",
          "predicted_answer": "Emma",
          "retrieved_context": [
            "cofounder pressuring for user",
            "meeting with cofounder and Charlotte attended by cofounder",
            "cofounder attended early budget review"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5513.863563537598,
          "generation_latency_ms": 4165.645122528076,
          "scoring_latency_ms": 2662.3308658599854,
          "total_latency_ms": 12341.83955192566
        },
        {
          "probe_id": "world_modeling-relationship_mapping-0",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which cloud platform hosts the database instance specifically used for legacy enterprise clients?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "PrimaryDB1 hosted on Amazon AWS",
            "PrimaryDB1 hosted on AWS",
            "PrimaryDB1 hosted on Amazon"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4935.280799865723,
          "generation_latency_ms": 3876.185894012451,
          "scoring_latency_ms": 2996.6208934783936,
          "total_latency_ms": 11808.087587356567
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person responsible for the sales strategy?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales Lead",
          "retrieved_context": [
            "Alex needs to coordinate with Sales",
            "Charlotte holds role Sales Lead",
            "Charlotte leads Sales"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7222.128391265869,
          "generation_latency_ms": 2733.626127243042,
          "scoring_latency_ms": 2979.891538619995,
          "total_latency_ms": 12935.646057128906
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-0",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Does the user consider the conflicting version flags on PrimaryDB1 to be an error or an expected state?",
          "answer_type": "short_answer",
          "gold_answer": "Expected state",
          "predicted_answer": "Error",
          "retrieved_context": [
            "daily report flags version conflict of PrimaryDB1",
            "120b2a3a-df2c-4a2e-b673-47a17f8d09bf includes version v1.2.0",
            "PrimaryDB1 flagging version v1.2.0"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5780.244827270508,
          "generation_latency_ms": 2722.2161293029785,
          "scoring_latency_ms": 2729.466199874878,
          "total_latency_ms": 11231.927156448364
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-0",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user explain the reason for the version conflict on PrimaryDB1 before or after adding coffee beans to their shopping list?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "After",
          "retrieved_context": [
            "120b2a3a-df2c-4a2e-b673-47a17f8d09bf includes version v1.2.0",
            "daily report flags version conflict of PrimaryDB1",
            "Sophia needs to be informed about version mismatch on PrimaryDB1"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6419.015645980835,
          "generation_latency_ms": 4494.143486022949,
          "scoring_latency_ms": 2654.836893081665,
          "total_latency_ms": 13567.99602508545
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-0",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What specific errand did the user ask to be reminded about for 5:30 PM?",
          "answer_type": "short_answer",
          "gold_answer": "Pick up dry cleaning",
          "predicted_answer": "dry cleaning",
          "retrieved_context": [
            "user requested reminder for 6 PM",
            "Alex set reminder for 5 PM",
            "user set reminder for dry cleaning pickup"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5676.109552383423,
          "generation_latency_ms": 3891.772508621216,
          "scoring_latency_ms": 2798.4495162963867,
          "total_latency_ms": 12366.331577301025
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What communication style does the user imply is preferred during early morning interactions before they have had caffeine?",
          "answer_type": "short_answer",
          "gold_answer": "Brief",
          "predicted_answer": "Direct and task-oriented",
          "retrieved_context": [
            "Alex wants to grab before coffee",
            "power nap happens before standup",
            "user reminded to pick up milk"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5843.318462371826,
          "generation_latency_ms": 4669.224739074707,
          "scoring_latency_ms": 2658.2319736480713,
          "total_latency_ms": 13170.775175094604
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What beverage does the user imply is necessary for them to function effectively in the morning?",
          "answer_type": "short_answer",
          "gold_answer": "Espresso",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "Alex going to grab coffee",
            "Alex owns coffee mug",
            "double espresso reminder scheduled for January 7, 2026T17:26:46Z"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 7088.635683059692,
          "generation_latency_ms": 4525.645017623901,
          "scoring_latency_ms": 2689.0769004821777,
          "total_latency_ms": 14303.357601165771
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who is the current VP of Engineering?",
          "answer_type": "abstain",
          "gold_answer": "not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Olivia holds role Product Design",
            "Alex has meeting with CEO",
            "Charlotte holds role Sales Lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5845.161914825439,
          "generation_latency_ms": 3069.8859691619873,
          "scoring_latency_ms": 2714.0488624572754,
          "total_latency_ms": 11629.096746444702
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts PrimaryDB2?",
          "answer_type": "abstain",
          "gold_answer": "not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB1 hosted on Amazon AWS",
            "PrimaryDB1 hosted on AWS",
            "PrimaryDB1 hosted on Amazon"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4121.222734451294,
          "generation_latency_ms": 3798.006296157837,
          "scoring_latency_ms": 2629.629135131836,
          "total_latency_ms": 10548.858165740967
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-0",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What technical process explains why a database might report two different versions simultaneously according to the user?",
          "answer_type": "short_answer",
          "gold_answer": "Blue-green deployment",
          "predicted_answer": "Canary testing the upgrade",
          "retrieved_context": [
            "a0a747bb-9a03-44ca-9fbb-b93f77f95ba6 versions of PrimaryDB1",
            "20189a2c-c9ea-4373-bdc7-b687051fb588 reports version v2.0.0-beta",
            "120b2a3a-df2c-4a2e-b673-47a17f8d09bf affects PrimaryDB1"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 7626.465082168579,
          "generation_latency_ms": 4586.652517318726,
          "scoring_latency_ms": 2720.9651470184326,
          "total_latency_ms": 14934.082746505737
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "Who does the user identify as the point of contact for UI issues caused by API changes?",
          "answer_type": "short_answer",
          "gold_answer": "Sophia",
          "predicted_answer": "Sophia",
          "retrieved_context": [
            "e02339e4-4981-447f-a95d-5d4fd53ceeb6 responsible for UI updates",
            "4508beca-4e31-439f-a1f7-8a2be6c15733 is part of frontend work",
            "Olivia discusses UI latency"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5880.637407302856,
          "generation_latency_ms": 3313.5862350463867,
          "scoring_latency_ms": 3610.281467437744,
          "total_latency_ms": 12804.505109786987
        }
      ],
      "summary": {
        "overall_accuracy": 0.5833333333333334,
        "total_score": 7,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 10,
            "accuracy": 0.5
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_020.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 28,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 227.64129972457886,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who did the user plan to meet for coffee prior to the board meeting?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "cofounder",
          "retrieved_context": [
            "coffee meeting with cofounder scheduled before board meeting",
            "2 PM reminder reminds to attend coffee meeting with cofounder",
            "User meeting with cofounder"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6630.13219833374,
          "generation_latency_ms": 3784.1949462890625,
          "scoring_latency_ms": 2778.2669067382812,
          "total_latency_ms": 13192.594051361084
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which cloud provider hosts the cache instance identified as causing the cross-cloud hop latency?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "CacheLayer6 hosted on Azure",
            "CacheLayer7 hosted on AWS",
            "CacheLayer7 hosted on Amazon cloud"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 69040.08507728577,
          "generation_latency_ms": 5101.866245269775,
          "scoring_latency_ms": 2626.147985458374,
          "total_latency_ms": 76768.09930801392
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales Lead",
          "retrieved_context": [
            "James has pet Luna",
            "James has pet Luna",
            "e99ae2dd-8e01-4bee-9180-c23dc76d69ed pet of James"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5521.575927734375,
          "generation_latency_ms": 3483.5898876190186,
          "scoring_latency_ms": 2748.673915863037,
          "total_latency_ms": 11753.83973121643
        },
        {
          "probe_id": "declarative_reasoning-state_tracking-3",
          "pillar": "declarative_reasoning",
          "subpillar": "task_state_tracking",
          "question": "Which two software versions were detected running simultaneously on the AWS cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "CacheLayer7 running on AWS",
            "main cache layer hosted on AWS",
            "750c89a4-5e58-4a5b-a7b7-d1a55af85d71 hosted on AWS"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8557.165145874023,
          "generation_latency_ms": 4186.012029647827,
          "scoring_latency_ms": 2632.6358318328857,
          "total_latency_ms": 15375.813007354736
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What architectural configuration did the user identify as the primary cause of backend latency?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-cloud hop",
          "predicted_answer": "hybrid setup where the sixth cache layer is sitting over on Azure",
          "retrieved_context": [
            "hybrid setup causes latency",
            "frontend lead can coordinate latency test",
            "49e7324a-18bf-47d5-aaec-afcab758c2a0 causing issues for frontend team"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 9368.80350112915,
          "generation_latency_ms": 3942.2709941864014,
          "scoring_latency_ms": 2657.6762199401855,
          "total_latency_ms": 15968.750715255737
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user notice the deployment glitch on CacheLayer7 before or after the discussion about the board meeting?",
          "answer_type": "short_answer",
          "gold_answer": "After",
          "predicted_answer": "After",
          "retrieved_context": [
            "CacheLayer7 affected by deployment script glitch",
            "deployment script glitch affects CacheLayer7",
            "User suspects issue with CacheLayer7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6339.492321014404,
          "generation_latency_ms": 4595.005512237549,
          "scoring_latency_ms": 2710.0677490234375,
          "total_latency_ms": 13644.56558227539
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's complaints about latency, which infrastructure setup do they appear to dislike?",
          "answer_type": "short_answer",
          "gold_answer": "Hybrid setup",
          "predicted_answer": "hybrid setup",
          "retrieved_context": [
            "Mia complained about latency",
            "hybrid setup causes latency",
            "user requested latency logs investigation"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 9615.133285522461,
          "generation_latency_ms": 2756.274461746216,
          "scoring_latency_ms": 2576.8954753875732,
          "total_latency_ms": 14948.30322265625
        },
        {
          "probe_id": "preference_learning-explicit_preferences-7",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Why did the user explicitly state they wanted to buy a toy for Luna?",
          "answer_type": "short_answer",
          "gold_answer": "To please James",
          "predicted_answer": "To get on James's good side.",
          "retrieved_context": [
            "toy intended for Luna",
            "e99ae2dd-8e01-4bee-9180-c23dc76d69ed pet of James",
            "James has pet Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5726.3548374176025,
          "generation_latency_ms": 2956.7809104919434,
          "scoring_latency_ms": 2758.676052093506,
          "total_latency_ms": 11441.811800003052
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Data Scientist's pet?",
          "answer_type": "abstain",
          "gold_answer": "Not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user plans to ask data scientist",
            "4545dcb4-01cf-400e-82d5-611a3e54e915 analyzing analytics pipeline",
            "Charlotte holds role Data Scientist"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8093.947410583496,
          "generation_latency_ms": 4179.601192474365,
          "scoring_latency_ms": 2909.1804027557373,
          "total_latency_ms": 15182.729005813599
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the database layer?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "CacheLayer7 hosted on Amazon cloud",
            "CacheLayer6 hosted in Azure",
            "CacheLayer6 hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4940.75345993042,
          "generation_latency_ms": 4475.168466567993,
          "scoring_latency_ms": 2648.932933807373,
          "total_latency_ms": 12064.854860305786
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What risk did the assistant identify regarding the concurrent execution of two versions on the same instance?",
          "answer_type": "short_answer",
          "gold_answer": "Data inconsistency",
          "predicted_answer": "data inconsistency",
          "retrieved_context": [
            "Liam monitors risks of version mismatches",
            "deployment script glitch caused simultaneous running of v1.2.0",
            "deployment script glitch caused simultaneous running of v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8521.56114578247,
          "generation_latency_ms": 2673.4206676483154,
          "scoring_latency_ms": 2745.7382678985596,
          "total_latency_ms": 13940.720081329346
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-11",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "How did the assistant verify the status of the traffic distributor on Amazon?",
          "answer_type": "short_answer",
          "gold_answer": "Pulled up metrics",
          "predicted_answer": "By pulling up stats and checking latency metrics.",
          "retrieved_context": [
            "e896c314-3f62-4e52-9767-1695ed11ea04 deployed in AWS environment",
            "LoadBalancer1 operates in AWS environment",
            "Liam worried about traffic routing of LoadBalancer1"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6632.355690002441,
          "generation_latency_ms": 3837.2795581817627,
          "scoring_latency_ms": 2871.666431427002,
          "total_latency_ms": 13341.301679611206
        }
      ],
      "summary": {
        "overall_accuracy": 0.8333333333333334,
        "total_score": 10,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 8,
            "count": 10,
            "accuracy": 0.8
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_021.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 28,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 203.76925015449524,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the 'cofounder' that requested a status update on the production environment?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "Liam",
          "retrieved_context": [
            "cofounder expected to send updated quarterly goals",
            "user has sync with cofounder",
            "4cec31d4-3353-417f-bf32-eaaf2de3d304 pressuring about quarterly numbers"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5929.318428039551,
          "generation_latency_ms": 4874.841213226318,
          "scoring_latency_ms": 2872.642993927002,
          "total_latency_ms": 13676.802635192871
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the job title of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Backend Lead",
          "predicted_answer": "Backend Lead",
          "retrieved_context": [
            "Luna owned by Will",
            "Will has pet Luna",
            "Will owns Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5275.9881019592285,
          "generation_latency_ms": 2657.709836959839,
          "scoring_latency_ms": 2744.7564601898193,
          "total_latency_ms": 10678.454399108887
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service managed by the Data Scientist hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "AnalyticsEngine1 hosted on Azure",
            "AnalyticsEngine1 possibly hosted on Azure",
            "auth service hosted on Google Cloud Platform"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5012.194395065308,
          "generation_latency_ms": 4788.048267364502,
          "scoring_latency_ms": 2905.3263664245605,
          "total_latency_ms": 12705.56902885437
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Which two versions of the analytics engine are currently reporting conflicting signals in the logs?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "Analytics Engine version discrepancy logged for Alex",
            "37a4572c-4323-41ea-bc40-c7acc92c8e9f runs on AnalyticsEngine1",
            "Analytics Engine running version version 2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8423.774719238281,
          "generation_latency_ms": 5082.058906555176,
          "scoring_latency_ms": 2624.542474746704,
          "total_latency_ms": 16130.376100540161
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why was the Backend Lead exhausted during the conversation by the coffee machine?",
          "answer_type": "short_answer",
          "gold_answer": "His cat kept him awake",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex needs to talk to backend leads",
            "Alex inquiring about Backend Lead",
            "Will member of backend leads"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8966.839790344238,
          "generation_latency_ms": 5499.598741531372,
          "scoring_latency_ms": 2572.6399421691895,
          "total_latency_ms": 17039.0784740448
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "In the same conversation where the user asked for a reminder to call their mom, what was the status of the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "Mixed signals",
          "predicted_answer": "It's a bit mixed. I'm seeing telemetry from v1.2.0, but v2.0.0-beta is also appearing in the logs.",
          "retrieved_context": [
            "67ec9bb6-dafe-40af-b3be-012f2a9a49b2 requested status for AnalyticsEngine1",
            "60ab4841-26b8-4323-8d19-d42750122f59 checking status of analytics engine",
            "Alex checking status of analytics engine v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 10476.908445358276,
          "generation_latency_ms": 3495.4802989959717,
          "scoring_latency_ms": 2685.661554336548,
          "total_latency_ms": 16658.050298690796
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's reaction to the logs, which version of the analytics engine do they prefer to be active in production?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0",
          "predicted_answer": "v1.2.0",
          "retrieved_context": [
            "Analytics Engine has main production version v1.2.0",
            "AnalyticsEngine1 has active version v1.2.0",
            "v2.0.0-beta alias of AnalyticsEngine1"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6241.3880825042725,
          "generation_latency_ms": 5938.299894332886,
          "scoring_latency_ms": 2665.6291484832764,
          "total_latency_ms": 14845.317125320435
        },
        {
          "probe_id": "preference_learning-explicit_preferences-7",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Has the user explicitly requested to filter the Auth Service logs to a single cloud provider?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "0d502d4e-dd95-4a9c-a36a-e7c8858a6328 still active on GCP",
            "25d76163-2f6f-4b72-9d9e-ec783163b5bd operates on GCP",
            "4bb9f236-9edd-469c-8de3-407d7848da6d describes configuration of AuthService2"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5893.163681030273,
          "generation_latency_ms": 4531.518459320068,
          "scoring_latency_ms": 2815.094232559204,
          "total_latency_ms": 13239.776372909546
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific version number is the Load Balancer currently running?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Liam inquiring about LoadBalancer4",
            "f3d3a9e0-c1ad-48a0-9798-da6ef344eb0d runs on GCP",
            "b6f323ac-264f-4de4-98f1-bb88fdb94d7f reports healthy status"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4654.959201812744,
          "generation_latency_ms": 3661.6921424865723,
          "scoring_latency_ms": 2636.8963718414307,
          "total_latency_ms": 10953.547716140747
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "Is the Auth Service currently hosted exclusively on Azure?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "AuthService2 hosted on Microsoft Azure",
            "AuthService2 partially hosted on Azure",
            "AuthService2 hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 40844.677448272705,
          "generation_latency_ms": 4906.717777252197,
          "scoring_latency_ms": 2754.3861865997314,
          "total_latency_ms": 48505.781412124634
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "Who should be contacted regarding discrepancies in the data science model deployments?",
          "answer_type": "short_answer",
          "gold_answer": "Sophia",
          "predicted_answer": "Sophia",
          "retrieved_context": [
            "Sophia has role Data Scientist",
            "Sophia holds role Data Scientist",
            "Sophia experiences errors on Analytics Engine"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4966.240644454956,
          "generation_latency_ms": 5536.176443099976,
          "scoring_latency_ms": 2730.5996417999268,
          "total_latency_ms": 13233.016729354858
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-11",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What routine action does the user typically take before starting the daily triage?",
          "answer_type": "short_answer",
          "gold_answer": "Grab coffee",
          "predicted_answer": "preparing for daily triage",
          "retrieved_context": [
            "user preparing for daily triage",
            "Alex preparing for daily standup",
            "user anticipates long afternoon"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 10089.056730270386,
          "generation_latency_ms": 3149.9593257904053,
          "scoring_latency_ms": 2844.1946506500244,
          "total_latency_ms": 16083.210706710815
        }
      ],
      "summary": {
        "overall_accuracy": 0.8333333333333334,
        "total_score": 10,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 8,
            "count": 10,
            "accuracy": 0.8
          },
          "boolean": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_022.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 30,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 154.53285241127014,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user referring to when they mention their 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Elijah",
          "retrieved_context": [
            "Alex has cofounder cofounder",
            "Alex has sync with cofounder",
            "cofounder concerned about cloud spend"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5363.009452819824,
          "generation_latency_ms": 3680.2961826324463,
          "scoring_latency_ms": 3275.691032409668,
          "total_latency_ms": 12318.996667861938
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the name of the pet belonging to the Sales Lead who is known for watching the dashboards?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "Ava is lead of sales leadership team",
            "Ava asked about sales dashboard lagging issue",
            "Sophia is lead of sales leadership team"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5427.209377288818,
          "generation_latency_ms": 3591.4018154144287,
          "scoring_latency_ms": 2991.4627075195312,
          "total_latency_ms": 12010.073900222778
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service running conflicting versions v1.2.0 and v2.0.0-beta hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "LoadBalancer3 reported version v2.0.0-beta",
            "LoadBalancer3 has version v2.0.0-beta",
            "LoadBalancer3 running version v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5190.554618835449,
          "generation_latency_ms": 4662.648916244507,
          "scoring_latency_ms": 2621.5527057647705,
          "total_latency_ms": 12474.756240844727
        },
        {
          "probe_id": "declarative_reasoning-composition-4",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which specific service is hosted on the same cloud platform as 'AnalyticsEngine9'?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer3",
          "predicted_answer": "LoadBalancer3",
          "retrieved_context": [
            "881ede92-d27b-4cf2-a5cb-921375a67863 hosted on Azure",
            "76b3e75d-1f8b-440c-b1f1-896199e1618f hosted on Microsoft Azure",
            "54e2f5ce-dd75-4241-a0cd-e06205a7377b located in Azure infrastructure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4594.705820083618,
          "generation_latency_ms": 4473.379135131836,
          "scoring_latency_ms": 2644.625186920166,
          "total_latency_ms": 11712.71014213562
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What item did the user ask to be reminded to buy immediately after discussing Elijah's confusion about the load balancer's location?",
          "answer_type": "short_answer",
          "gold_answer": "Milk",
          "predicted_answer": "Milk",
          "retrieved_context": [
            "Alex inquired about LoadBalancer3",
            "671c8341-39a3-45f4-bfb8-f08e9fefe606 reported issue with LoadBalancer3",
            "LoadBalancer3 possibly updated by Elijah"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6043.8666343688965,
          "generation_latency_ms": 3838.728666305542,
          "scoring_latency_ms": 2732.2287559509277,
          "total_latency_ms": 12614.824056625366
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-6",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user ask to be reminded about 'dry cleaning' before or after they asked to be reminded about 'milk'?",
          "answer_type": "short_answer",
          "gold_answer": "After",
          "predicted_answer": "Before",
          "retrieved_context": [
            "Assistant reminder set for dry cleaning",
            "user set reminder for 2 PM reminder to pick up dry cleaning",
            "user set reminder for 2 PM reminder to pick up dry cleaning"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6006.19912147522,
          "generation_latency_ms": 4644.744873046875,
          "scoring_latency_ms": 2766.4496898651123,
          "total_latency_ms": 13417.393684387207
        },
        {
          "probe_id": "preference_learning-explicit_preferences-7",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What consumable item does the user explicitly state is their 'first priority' before they can function?",
          "answer_type": "short_answer",
          "gold_answer": "Caffeine",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "Alex owns coffee",
            "Alex requested reminder for milk pickup reminder",
            "Alex reminded to pick up milk"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6281.301259994507,
          "generation_latency_ms": 4161.594390869141,
          "scoring_latency_ms": 2653.7716388702393,
          "total_latency_ms": 13096.667289733887
        },
        {
          "probe_id": "preference_learning-preference_induction-8",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Regarding the conflicting versions on LoadBalancer3, does the user prefer to keep the beta percentage high or low?",
          "answer_type": "short_answer",
          "gold_answer": "Low",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "LoadBalancer3 running version beta v2.0.0",
            "326acca0-d46d-4cbe-9f78-10138467543c causes instability in LoadBalancer3",
            "LoadBalancer3 version state includes version v2.0.0-beta"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5276.037931442261,
          "generation_latency_ms": 4983.766317367554,
          "scoring_latency_ms": 2831.20059967041,
          "total_latency_ms": 13091.004848480225
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider is 'CacheLayer9' hosted on?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "8261e079-0791-4d4e-a3ea-ada69b1268e9 hosted on Google Cloud Platform",
            "number 7 cache layer instance hosted on Google Cloud Platform",
            "24aafbbe-f7f0-4ec3-ab3a-8d79e4860a5e located on Google Cloud Platform"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7154.8426151275635,
          "generation_latency_ms": 4068.073034286499,
          "scoring_latency_ms": 2670.0313091278076,
          "total_latency_ms": 13892.94695854187
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "What specific version number is System:LoadBalancer_7 currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "76aa4c65-eca7-488a-82d9-425a464cb5d2 includes version v1.2.0",
            "LoadBalancer3 running version v1.2.0",
            "LoadBalancer3 running version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5197.748899459839,
          "generation_latency_ms": 4007.390260696411,
          "scoring_latency_ms": 2916.1574840545654,
          "total_latency_ms": 12121.296644210815
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-11",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "What specific action did the user decide to take to resolve the jitter caused by the split configuration on LoadBalancer3?",
          "answer_type": "short_answer",
          "gold_answer": "Manually kill the beta instance",
          "predicted_answer": "kill the beta process",
          "retrieved_context": [
            "LoadBalancer3 caused cost spike",
            "LoadBalancer3 possibly updated by Elijah",
            "Alex needs fixing LoadBalancer3"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8825.51622390747,
          "generation_latency_ms": 4885.453462600708,
          "scoring_latency_ms": 2553.093433380127,
          "total_latency_ms": 16264.063119888306
        },
        {
          "probe_id": "procedural_knowledge-task_state_tracking-12",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "What is the current versioning state of the load balancer hosted on Azure?",
          "answer_type": "short_answer",
          "gold_answer": "Conflicting versions",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "LoadBalancer3 reported running version v1.2.0",
            "LoadBalancer3 running version v1.2.0",
            "LoadBalancer3 active version v1.2.0"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4956.521034240723,
          "generation_latency_ms": 3879.843235015869,
          "scoring_latency_ms": 2664.994239807129,
          "total_latency_ms": 11501.35850906372
        }
      ],
      "summary": {
        "overall_accuracy": 0.6666666666666666,
        "total_score": 8,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 10,
            "accuracy": 0.6
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_023.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 27,
      "num_probes": 8,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 104.50233435630798,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the 'cofounder' the user intends to sync with regarding the cloud footprint?",
          "answer_type": "short_answer",
          "gold_answer": "Mia",
          "predicted_answer": "Mia",
          "retrieved_context": [
            "cofounder attending board meeting",
            "f6225495-4441-4ce2-9596-740624b62b71 scheduled for January 7, 2026 12:00 PM",
            "0bc158f2-a103-4644-b574-e339c504b91b manages cloud footprint including AnalyticsEngine2"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6099.4462966918945,
          "generation_latency_ms": 4745.621919631958,
          "scoring_latency_ms": 2966.038465499878,
          "total_latency_ms": 13811.10668182373
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which team member is associated with the pet named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Charlotte",
          "predicted_answer": "Charlotte",
          "retrieved_context": [
            "Charlotte has pet Luna",
            "f0461bed-6596-400b-bbe1-61b22236fb17 had vet visit",
            "Charlotte owns Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4786.091327667236,
          "generation_latency_ms": 4158.754348754883,
          "scoring_latency_ms": 2622.8156089782715,
          "total_latency_ms": 11567.66128540039
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which cloud provider hosts the database that the user described as an 'outlier'?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "PrimaryDB3 is outlier compared to PrimaryDB6",
            "PrimaryDB3 hosted on Microsoft Azure",
            "PrimaryDB3 hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4690.686464309692,
          "generation_latency_ms": 3548.8104820251465,
          "scoring_latency_ms": 2901.5722274780273,
          "total_latency_ms": 11141.069173812866
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What two conflicting versions is AnalyticsEngine3 currently reporting?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "AnalyticsEngine3 reporting version v1.2.0",
            "AnalyticsEngine3 reporting version v2.0.0-beta",
            "v2.0.0-beta alias of AnalyticsEngine3"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8407.708644866943,
          "generation_latency_ms": 4598.127126693726,
          "scoring_latency_ms": 2548.1691360473633,
          "total_latency_ms": 15554.004907608032
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What external factor did the Data Scientist blame for the model latency issues?",
          "answer_type": "short_answer",
          "gold_answer": "Her cat",
          "predicted_answer": "Her cat Luna chewing on the ethernet cable",
          "retrieved_context": [
            "0e88fa12-2f87-4d37-b702-383a54e898a9 complained about latency of AnalyticsEngine3",
            "Sales Lead experiences latency due to PrimaryDB3",
            "f242e979-b738-4850-be6c-3413dd913a40 not caused by PrimaryDB3"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5661.411285400391,
          "generation_latency_ms": 4105.635404586792,
          "scoring_latency_ms": 3463.21964263916,
          "total_latency_ms": 13230.266332626343
        },
        {
          "probe_id": "preference_learning-explicit_preferences-1",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What specific item did the user request a reminder to purchase on the way home?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee beans",
          "predicted_answer": "milk, coffee beans",
          "retrieved_context": [
            "user wants to be reminded to buy milk",
            "User added task Reminder to buy coffee beans",
            "user reminded to buy cat treats"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8301.466703414917,
          "generation_latency_ms": 5108.258008956909,
          "scoring_latency_ms": 2579.026699066162,
          "total_latency_ms": 15988.751411437988
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the Sales Lead's infrastructure?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "1e26b30c-e27c-4889-a641-c60d49e7f162 hosted on Google Cloud Platform",
            "AnalyticsEngine3 hosted on GCP",
            "PrimaryDB3 hosted on Microsoft Azure"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4850.552558898926,
          "generation_latency_ms": 4287.554502487183,
          "scoring_latency_ms": 2708.9192867279053,
          "total_latency_ms": 11847.026348114014
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-1",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "Who did the assistant plan to contact regarding the UI glitches caused by the engine version conflict?",
          "answer_type": "short_answer",
          "gold_answer": "Sophia and Ava",
          "predicted_answer": "Sophia and Ava",
          "retrieved_context": [
            "user needs to sync with UI team",
            "user handling version conflict on AnalyticsEngine3",
            "Frontend Leads should be flagged about version conflict"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5588.801145553589,
          "generation_latency_ms": 2883.418083190918,
          "scoring_latency_ms": 2878.4139156341553,
          "total_latency_ms": 11350.633144378662
        }
      ],
      "summary": {
        "overall_accuracy": 0.875,
        "total_score": 7,
        "count": 8,
        "by_answer_type": {
          "short_answer": {
            "total": 7,
            "count": 7,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_024.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 29,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 120.39625549316406,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which individual is identified as the user's cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Elijah",
          "retrieved_context": [
            "cofounder Elijah wants breakdown of user",
            "cofounder is Elijah",
            "cofounder may have signed off on new budget"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4616.174697875977,
          "generation_latency_ms": 3177.133083343506,
          "scoring_latency_ms": 2507.7784061431885,
          "total_latency_ms": 10301.08618736267
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the name of the pet belonging to the person who shares the Sales Lead role with Oliver?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "161e5134-d03d-464a-b463-1ccc399c997c leads sales team",
            "Oliver leads sales team",
            "Oliver leads sales department"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5756.228685379028,
          "generation_latency_ms": 2842.932939529419,
          "scoring_latency_ms": 2622.739553451538,
          "total_latency_ms": 11221.901178359985
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service hosted that the user described as 'sitting all alone'?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google Cloud Platform",
          "retrieved_context": [
            "AuthService1 hosted on Google Cloud Platform",
            "AuthService1 hosted on Google Cloud Platform",
            "auth service hosted on Google Cloud Platform"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5840.625286102295,
          "generation_latency_ms": 2594.5346355438232,
          "scoring_latency_ms": 3040.9092903137207,
          "total_latency_ms": 11476.069211959839
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-1",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "Which specific database resource is hosted on the platform provided by Microsoft?",
          "answer_type": "short_answer",
          "gold_answer": "PrimaryDB7",
          "predicted_answer": "PrimaryDB7",
          "retrieved_context": [
            "PrimaryDB7 running on Microsoft's cloud",
            "PrimaryDB7 hosted on Azure",
            "Azure database has active version version 2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4460.550546646118,
          "generation_latency_ms": 3154.951572418213,
          "scoring_latency_ms": 2859.1792583465576,
          "total_latency_ms": 10474.681377410889
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who is currently designated as the Backend Lead?",
          "answer_type": "abstain",
          "gold_answer": "unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "997f21d8-f022-443a-9a0e-29e4220e59f0 led by Noah",
            "997f21d8-f022-443a-9a0e-29e4220e59f0 led by Olivia",
            "Alex plans to include Frontend leads meeting"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7076.595306396484,
          "generation_latency_ms": 4298.520803451538,
          "scoring_latency_ms": 2913.5303497314453,
          "total_latency_ms": 14288.646459579468
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What software version is currently running on AuthService1?",
          "answer_type": "abstain",
          "gold_answer": "unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user needs to check logs and sync AuthService1",
            "user needs to check logs and sync AuthService1",
            "AuthService1 running on GCP"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5321.860074996948,
          "generation_latency_ms": 4155.333995819092,
          "scoring_latency_ms": 2715.425491333008,
          "total_latency_ms": 12192.619562149048
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-0",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "During the conversation about the 'multi-cloud mess', what item did the user ask to be reminded to buy?",
          "answer_type": "short_answer",
          "gold_answer": "Milk",
          "predicted_answer": "Unknown",
          "retrieved_context": [],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 2594.8550701141357,
          "generation_latency_ms": 2839.963436126709,
          "scoring_latency_ms": 3039.182424545288,
          "total_latency_ms": 8474.000930786133
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user request a reminder to call their mom before or after requesting a reminder for espresso pods?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Before",
          "retrieved_context": [
            "coffee beans purchase reminder reminder for user",
            "latte reminder scheduled for ten minutes after January 7, 2026 17:07:23 UTC",
            "user needs before talking to double espresso"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7843.911647796631,
          "generation_latency_ms": 3255.0058364868164,
          "scoring_latency_ms": 2693.920612335205,
          "total_latency_ms": 13792.838096618652
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's greetings in the session logs, at what time of day do they typically discuss infrastructure status?",
          "answer_type": "short_answer",
          "gold_answer": "Morning",
          "predicted_answer": "Morning",
          "retrieved_context": [
            "CEO discussed infrastructure with user",
            "Alex needs to prepare uptime reports",
            "infrastructure migration deadline at end of day"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5425.821781158447,
          "generation_latency_ms": 4599.590539932251,
          "scoring_latency_ms": 2565.6538009643555,
          "total_latency_ms": 12591.066122055054
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-0",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "Which two cloud providers does the user repeatedly confuse regarding service locations?",
          "answer_type": "short_answer",
          "gold_answer": "Azure and GCP",
          "predicted_answer": "AWS and Google Cloud",
          "retrieved_context": [
            "auth service hosted on Google Cloud",
            "auth service hosted on Google Cloud Platform",
            "Amazon infrastructure includes PrimaryDB5"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 7783.557176589966,
          "generation_latency_ms": 4949.481010437012,
          "scoring_latency_ms": 2835.1237773895264,
          "total_latency_ms": 15568.161964416504
        }
      ],
      "summary": {
        "overall_accuracy": 0.8,
        "total_score": 8,
        "count": 10,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 8,
            "accuracy": 0.75
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_025.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 27,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 123.84278583526611,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which individual is identified as the user's cofounder who worries about stability?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "Liam",
          "retrieved_context": [
            "cofounder anxious about new login rollout",
            "cofounder online recently for user",
            "user plans to message cofounder"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5870.580673217773,
          "generation_latency_ms": 4762.030124664307,
          "scoring_latency_ms": 2618.952512741089,
          "total_latency_ms": 13251.563310623169
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the name of the pet belonging to the DevOps engineer who works alongside Lucas?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "Lucas works in DevOps",
            "Lucas member of DevOps engineers",
            "8f4c6633-4fb2-42e6-9094-746ee05cb5ce assigned to DevOps rotation"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5695.209980010986,
          "generation_latency_ms": 2791.3520336151123,
          "scoring_latency_ms": 2645.991325378418,
          "total_latency_ms": 11132.553339004517
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service hosted that is currently experiencing a version mismatch with a beta release?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google Cloud Platform",
          "retrieved_context": [
            "e30e874f-b18e-468f-8300-12485d422563 involves version v2.0.0-beta",
            "auth service version conflict includes version v2.0.0-beta",
            "AuthService 7 hosted on Google Cloud Platform"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7338.407516479492,
          "generation_latency_ms": 4644.96636390686,
          "scoring_latency_ms": 2680.0668239593506,
          "total_latency_ms": 14663.440704345703
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which analytics engine is deployed on the same cloud platform as the authentication service?",
          "answer_type": "short_answer",
          "gold_answer": "AnalyticsEngine3",
          "predicted_answer": "AnalyticsEngine3",
          "retrieved_context": [
            "161ad2fd-4b12-4555-bbb5-98ea710c5613 includes Engine3",
            "22fb55d3-3dcd-4c5d-8dca-6d7843e7e430 running on GCP",
            "22fb55d3-3dcd-4c5d-8dca-6d7843e7e430 co located with AuthService7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4237.5853061676025,
          "generation_latency_ms": 4450.434684753418,
          "scoring_latency_ms": 2699.575424194336,
          "total_latency_ms": 11387.595415115356
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why was Oliver distracted during the standup meeting mentioned in the session where the user discussed quarterly goals?",
          "answer_type": "short_answer",
          "gold_answer": "Luna knocked over water",
          "predicted_answer": "Luna knocked over his water",
          "retrieved_context": [
            "Oliver was distracted during standup",
            "Oliver distracted by Luna",
            "Liam stressing about quarterly goals"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6499.632120132446,
          "generation_latency_ms": 4024.4643688201904,
          "scoring_latency_ms": 2650.362014770508,
          "total_latency_ms": 13174.458503723145
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-1",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "In the conversation where the user complained about paying invoices to every cloud provider, where was AnalyticsEngine5 stated to be hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "Engine 5 hosted on Microsoft's cloud",
            "Data Scientist forgets hosting of AnalyticsEngine5",
            "AnalyticsEngine5 deployed on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5173.164129257202,
          "generation_latency_ms": 4358.688831329346,
          "scoring_latency_ms": 2678.4796714782715,
          "total_latency_ms": 12210.33263206482
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's comments about the infrastructure map, how do they feel about the current multi-cloud setup?",
          "answer_type": "short_answer",
          "gold_answer": "dislikes it",
          "predicted_answer": "Negative.",
          "retrieved_context": [
            "architecture review will discuss multi-cloud sprawl",
            "networking challenges caused by multi-cloud setup",
            "706838c3-73f1-4e23-8858-5ffff0acc5ae makes management tricky for cloud spend"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5110.201358795166,
          "generation_latency_ms": 5480.730295181274,
          "scoring_latency_ms": 2739.6175861358643,
          "total_latency_ms": 13330.549240112305
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific software version is AnalyticsEngine6 currently running?",
          "answer_type": "abstain",
          "gold_answer": "unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "c827398d-5b09-4349-becd-e547aa6b1c83 part of analytics suite",
            "5d232803-a566-4344-9b38-b2dc2571f084 part of distributed analytics setup",
            "AnalyticsEngine5 part of distributed analytics setup"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4599.598407745361,
          "generation_latency_ms": 3724.107265472412,
          "scoring_latency_ms": 2866.015672683716,
          "total_latency_ms": 11189.72134590149
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-2",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who holds the role of CFO at Nebula Corp?",
          "answer_type": "abstain",
          "gold_answer": "unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Liam holds role CEO",
            "coffee meeting with Liam discussion topic Nebula's roadmap",
            "CEO needs to approve billing consolidation"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5607.421875,
          "generation_latency_ms": 2978.8825511932373,
          "scoring_latency_ms": 2803.258180618286,
          "total_latency_ms": 11389.562606811523
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-1",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What specific action did the assistant perform when the user requested to be prompted about calling the dentist?",
          "answer_type": "short_answer",
          "gold_answer": "set a reminder",
          "predicted_answer": "Reminder set",
          "retrieved_context": [
            "user set reminder for dentist call reminder",
            "user plans to make dentist call",
            "Assistant reminded of appointment at 3 PM"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5263.798713684082,
          "generation_latency_ms": 4209.580421447754,
          "scoring_latency_ms": 2623.713254928589,
          "total_latency_ms": 12097.092390060425
        }
      ],
      "summary": {
        "overall_accuracy": 1.0,
        "total_score": 10,
        "count": 10,
        "by_answer_type": {
          "short_answer": {
            "total": 8,
            "count": 8,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_026.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 31,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 156.24845957756042,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the owner of the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Will",
          "predicted_answer": "Will",
          "retrieved_context": [
            "Will sent photo of Luna",
            "Will owns Luna",
            "Will showed pictures of Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5237.238168716431,
          "generation_latency_ms": 2681.8795204162598,
          "scoring_latency_ms": 2619.1298961639404,
          "total_latency_ms": 10538.24758529663
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which cloud provider hosts the load balancer that is currently running a beta version?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google Cloud Platform",
          "retrieved_context": [
            "403a8462-ac2b-4cf3-8a77-520174cdbf68 hosted on Google Cloud Platform",
            "2ce91480-039b-4967-95f4-ac351855e3db hosted in Google Cloud",
            "LoadBalancer6 hosted in Google Cloud"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5056.536912918091,
          "generation_latency_ms": 4394.856929779053,
          "scoring_latency_ms": 7762.7997398376465,
          "total_latency_ms": 17214.19358253479
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person who had to take their pet to the vet?",
          "answer_type": "short_answer",
          "gold_answer": "DevOps",
          "predicted_answer": "DevOps lead",
          "retrieved_context": [
            "Will taking to vet visit",
            "Will needed to do taking Luna to the vet",
            "Will taking to vet Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5147.565126419067,
          "generation_latency_ms": 2766.2250995635986,
          "scoring_latency_ms": 2622.0946311950684,
          "total_latency_ms": 10535.884857177734
        },
        {
          "probe_id": "declarative_reasoning-baseline_factual_recall-3",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "Which specific service is hosted on the Azure platform?",
          "answer_type": "short_answer",
          "gold_answer": "AuthService9",
          "predicted_answer": "AuthService9",
          "retrieved_context": [
            "AuthService9 hosted on Microsoft Azure",
            "AuthService9 hosted on Azure",
            "AuthService9 hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4421.796560287476,
          "generation_latency_ms": 3201.0767459869385,
          "scoring_latency_ms": 2925.3149032592773,
          "total_latency_ms": 10548.188209533691
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What event caused the DevOps lead to be delayed in starting his work day?",
          "answer_type": "short_answer",
          "gold_answer": "Vet visit",
          "predicted_answer": "Luna knocked over a plant",
          "retrieved_context": [
            "DevOps lead planned to fix LoadBalancer4",
            "canary deployment likely set up by DevOps lead",
            "user preparing for morning stand-up"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8229.743957519531,
          "generation_latency_ms": 5077.057600021362,
          "scoring_latency_ms": 2808.8271617889404,
          "total_latency_ms": 16115.628719329834
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "In the most recent infrastructure review, which load balancer was confirmed to still be running on AWS?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer8",
          "predicted_answer": "LoadBalancer8",
          "retrieved_context": [
            "LoadBalancer8 hosted on Amazon Web Services",
            "load balancers partially hosted on Amazon",
            "AWS load balancer number 8 hosted on Amazon Web Services"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5571.4685916900635,
          "generation_latency_ms": 2770.3769207000732,
          "scoring_latency_ms": 2713.4358882904053,
          "total_latency_ms": 11055.281400680542
        },
        {
          "probe_id": "preference_learning-explicit_preferences-6",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What specific beverage does the user require before they can focus on infrastructure or meetings?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "double espresso",
          "retrieved_context": [
            "user needs before double espresso",
            "board meeting preceded by double espresso",
            "user preparing for morning stand-up"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 7867.213487625122,
          "generation_latency_ms": 3624.784231185913,
          "scoring_latency_ms": 2726.4959812164307,
          "total_latency_ms": 14218.493700027466
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's initial request in Session 25, which cloud provider's resources do they prioritize reviewing first?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google Cloud",
          "retrieved_context": [
            "9412cea4-109d-4a69-861e-e1c4cc11a6d9 includes AWS",
            "user needs to check cloud spend",
            "9412cea4-109d-4a69-861e-e1c4cc11a6d9 includes Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7274.54948425293,
          "generation_latency_ms": 3370.0242042541504,
          "scoring_latency_ms": 2731.7779064178467,
          "total_latency_ms": 13376.351594924927
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What software version is currently running on LoadBalancer8?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "248ad6a5-5a24-4411-bfdb-332e4a152b49 running on AWS",
            "7b28cc0b-c885-46f5-ab68-ba691536650c hosted on Amazon",
            "b0e3d47b-8a3e-4064-8456-06b458e012e1 reported as version version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4553.9350509643555,
          "generation_latency_ms": 4479.40468788147,
          "scoring_latency_ms": 2663.9907360076904,
          "total_latency_ms": 11697.330474853516
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of Lucas's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "ad73a660-f515-490c-b2c9-f6ed8a1b6154 pet of Will",
            "6fbc2af9-5e74-4a5d-83d9-29dd61417415 available to help user",
            "user ensures access for Lucas"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4692.395210266113,
          "generation_latency_ms": 4181.708812713623,
          "scoring_latency_ms": 2776.2317657470703,
          "total_latency_ms": 11650.335788726807
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "If a load balancer flags two different versions simultaneously, what type of deployment does the user identify this as?",
          "answer_type": "short_answer",
          "gold_answer": "Canary deployment",
          "predicted_answer": "canary deployment",
          "retrieved_context": [
            "version conflict on LoadBalancer4 indicates stalled blue-green deployment",
            "b7a2f841-ee68-47ef-9a66-170c3b06bffa caused by canary deployment",
            "f9a7bbd5-36ab-4ad4-8499-11085ac9e06c reports version conflict on LoadBalancer4"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5318.898916244507,
          "generation_latency_ms": 5378.531217575073,
          "scoring_latency_ms": 2622.377872467041,
          "total_latency_ms": 13319.808006286621
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-11",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What specific state configuration indicated to the assistant that a canary deployment was active on LoadBalancer4?",
          "answer_type": "short_answer",
          "gold_answer": "Two different versions",
          "predicted_answer": "version mismatch",
          "retrieved_context": [
            "version mismatch on LoadBalancer4 caused by canary deployment",
            "version conflict on LoadBalancer4 indicates stalled blue-green deployment",
            "dashboard inconsistency about LoadBalancer4"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8428.552389144897,
          "generation_latency_ms": 4743.541479110718,
          "scoring_latency_ms": 2788.236379623413,
          "total_latency_ms": 15960.330247879028
        }
      ],
      "summary": {
        "overall_accuracy": 0.75,
        "total_score": 9,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 7,
            "count": 10,
            "accuracy": 0.7
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_027.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 22.082979917526245,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does system:loadbalancer_2 running version?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "f7357569-378c-43cd-b364-fc62f7772beb reported version v1.2.0",
            "LoadBalancer2 running version v1.2.0",
            "LoadBalancer2 reported version v1.2.0"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5215.710401535034,
          "generation_latency_ms": 3549.722671508789,
          "scoring_latency_ms": 2566.0111904144287,
          "total_latency_ms": 11331.444263458252
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user plans to text about dinner sister",
            "user plans to discuss new UI specs",
            "user plans to email Ava"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5102.483034133911,
          "generation_latency_ms": 2865.584373474121,
          "scoring_latency_ms": 2779.388904571533,
          "total_latency_ms": 10747.456312179565
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 1,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_028.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 146.12000703811646,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which cloud provider hosts the service where the Product Designer requires write access?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB2 hosted on AWS",
            "PrimaryDB2 hosted on AWS",
            "PrimaryDB2 hosted on AWS instance"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4672.005176544189,
          "generation_latency_ms": 4895.039796829224,
          "scoring_latency_ms": 2677.157402038574,
          "total_latency_ms": 12244.202375411987
        },
        {
          "probe_id": "world_modeling-category_membership-1",
          "pillar": "world_modeling",
          "subpillar": "type_category_membership",
          "question": "Which specific infrastructure services are currently confirmed to be running on the Google Cloud Platform?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer4 and AnalyticsEngine1",
          "predicted_answer": "AnalyticsEngine1, LoadBalancer4",
          "retrieved_context": [
            "f9cd2ecd-9e77-4ee0-b10d-ec346ab70bd4 running on Google's infrastructure",
            "AnalyticsEngine1 running on Google Cloud",
            "analytics engine hosted on Google Cloud Platform"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4804.883718490601,
          "generation_latency_ms": 3889.265298843384,
          "scoring_latency_ms": 2612.1950149536133,
          "total_latency_ms": 11306.344032287598
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the professional role of the individual who owns a cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales lead",
          "retrieved_context": [
            "a6d8a6a9-b0d9-4379-90e5-2703d73dfde4 owned by Charlotte",
            "buy cat treats intended for Luna",
            "969a4ce1-cd7f-493d-abf2-9b00a5c57cde appeared during call with sales leads"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5650.007247924805,
          "generation_latency_ms": 3473.8452434539795,
          "scoring_latency_ms": 2641.8232917785645,
          "total_latency_ms": 11765.675783157349
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "According to the latest system logs discussed, what is the version status of the second primary database?",
          "answer_type": "short_answer",
          "gold_answer": "Split between v1.2.0 and v2.0.0-beta",
          "predicted_answer": "Conflicting; both v1.2.0 and v2.0.0-beta are",
          "retrieved_context": [
            "4965a50a-af85-44cb-946c-fedb9a6788a3 issue in second primary database",
            "second primary database underwent update",
            "second primary database instance flagged as active version version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7426.08380317688,
          "generation_latency_ms": 4980.762720108032,
          "scoring_latency_ms": 2665.619373321533,
          "total_latency_ms": 15072.465896606445
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific technical issue is causing the user's cofounder to worry about the platform's stability?",
          "answer_type": "short_answer",
          "gold_answer": "Version mismatch on PrimaryDB2",
          "predicted_answer": "Latency issues due to cross-cloud communication overhead",
          "retrieved_context": [
            "user plans to bother cofounder",
            "Mia worried about system stability concern",
            "87bd35fa-e63b-44dc-99b5-e13270d5ffa0 requesting latency report from Alex"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5736.027479171753,
          "generation_latency_ms": 4976.104974746704,
          "scoring_latency_ms": 2685.122013092041,
          "total_latency_ms": 13397.254467010498
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "In the conversation regarding the stuck migration, did the user complain about the coffee before or after requesting permission updates for Liam and Charlotte?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Before",
          "retrieved_context": [
            "481c7ac1-1a43-42c8-9dc4-54493024dae1 needs permissions updated on AuthService9",
            "1dc9ca6c-62e9-41e3-afeb-ab19ba78a97f took before coffee",
            "Charlotte needs permissions updated on AuthService9"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5891.189336776733,
          "generation_latency_ms": 2626.192331314087,
          "scoring_latency_ms": 2659.853935241699,
          "total_latency_ms": 11177.23560333252
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's reaction to the office machine, what is their implied preference regarding coffee strength?",
          "answer_type": "short_answer",
          "gold_answer": "Strong coffee",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user took before coffee",
            "coffee beans has type dark roast",
            "user plans to buy coffee beans"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4871.508598327637,
          "generation_latency_ms": 3728.396415710449,
          "scoring_latency_ms": 2605.602741241455,
          "total_latency_ms": 11205.507755279541
        },
        {
          "probe_id": "preference_learning-constraint_hierarchy-7",
          "pillar": "preference_learning",
          "subpillar": "constraint_hierarchy",
          "question": "What specific access level constraint did the user define for the Sales Leads regarding the authentication service?",
          "answer_type": "short_answer",
          "gold_answer": "Read access only",
          "predicted_answer": "read access",
          "retrieved_context": [
            "03974a69-d687-48d7-b0e8-1c912392d673 part of core data services",
            "03974a69-d687-48d7-b0e8-1c912392d673 hosted on AWS",
            "Alex plans to sync with sales leads"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5594.874143600464,
          "generation_latency_ms": 3201.308250427246,
          "scoring_latency_ms": 2726.8199920654297,
          "total_latency_ms": 11523.00238609314
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider is the company's email server hosted on?",
          "answer_type": "short_answer",
          "gold_answer": "not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB2 hosted on Amazon Web Services",
            "8c132f4a-a4a7-4985-b5a1-08c68d9ec9f2 hosted on Amazon Web Services",
            "PrimaryDB2 hosted on AWS"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5114.488840103149,
          "generation_latency_ms": 4593.187093734741,
          "scoring_latency_ms": 2662.538528442383,
          "total_latency_ms": 12370.214462280273
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the pet owned by the Sales Lead named Liam?",
          "answer_type": "short_answer",
          "gold_answer": "not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "f9f63651-e1ce-4bb3-9744-d5d73c988fbc member of sales team",
            "e038f878-e716-48a9-a8fe-0d9cc99db803 member of Sales team",
            "sales leads meeting includes participant Liam"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4137.926816940308,
          "generation_latency_ms": 3740.6063079833984,
          "scoring_latency_ms": 2735.971689224243,
          "total_latency_ms": 10614.50481414795
        },
        {
          "probe_id": "procedural_knowledge-task_state_tracking-10",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "What follow-up action did the assistant commit to regarding the Product Designer's mockups?",
          "answer_type": "short_answer",
          "gold_answer": "Ping him",
          "predicted_answer": "I'll keep an eye out for his commit.",
          "retrieved_context": [
            "Oliver follows up on new product mockups",
            "Oliver expected to upload new mockups",
            "UI mocks review with Oliver attended by cofounder"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4912.969350814819,
          "generation_latency_ms": 4661.915302276611,
          "scoring_latency_ms": 2954.3051719665527,
          "total_latency_ms": 12529.189825057983
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-11",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What specific system mechanism does the assistant use to verify permissions for services hosted on AWS?",
          "answer_type": "short_answer",
          "gold_answer": "IAM roles",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "03974a69-d687-48d7-b0e8-1c912392d673 hosted on AWS",
            "fefb6590-9c28-4e99-a320-0cda701d7aec hosted on Amazon Web Services",
            "AuthService9 status operational"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5192.765712738037,
          "generation_latency_ms": 4981.980085372925,
          "scoring_latency_ms": 2719.602584838867,
          "total_latency_ms": 12894.34838294983
        }
      ],
      "summary": {
        "overall_accuracy": 0.5833333333333334,
        "total_score": 7,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 7,
            "count": 12,
            "accuracy": 0.5833333333333334
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_029.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 26,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 145.51042485237122,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the 'cofounder' that the user mentions is paranoid about vendor lock-in?",
          "answer_type": "short_answer",
          "gold_answer": "Mia",
          "predicted_answer": "Mia",
          "retrieved_context": [
            "cofounder concerned about cloud redundancy",
            "user preparing for sync with cofounder",
            "5a79b3ee-d265-4324-9619-398be5fc37eb is stressing about latency spikes"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6354.447364807129,
          "generation_latency_ms": 3148.7553119659424,
          "scoring_latency_ms": 2631.253957748413,
          "total_latency_ms": 12134.456634521484
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "On which cloud provider's infrastructure are the databases PrimaryDB6 and PrimaryDB7 hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Microsoft Azure",
          "retrieved_context": [
            "PrimaryDB6 hosted on Microsoft Azure",
            "PrimaryDB7 hosted on Microsoft Azure",
            "Elijah set up PrimaryDB6"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5037.388801574707,
          "generation_latency_ms": 2849.6782779693604,
          "scoring_latency_ms": 3025.218963623047,
          "total_latency_ms": 10912.286043167114
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which specific service hosted on AWS is currently reporting conflicting version headers?",
          "answer_type": "short_answer",
          "gold_answer": "CacheLayer4",
          "predicted_answer": "CacheLayer4",
          "retrieved_context": [
            "cache service hosted on Amazon Web Services",
            "CacheLayer4 hosted on Amazon Web Services",
            "Elijah modified deployment manifest of cache service on AWS"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5998.092412948608,
          "generation_latency_ms": 5108.981370925903,
          "scoring_latency_ms": 2691.624641418457,
          "total_latency_ms": 13798.698425292969
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-1",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "The user implies a hard constraint against running which software version in the production environment?",
          "answer_type": "short_answer",
          "gold_answer": "v2.0.0-beta",
          "predicted_answer": "v2.0.0-beta",
          "retrieved_context": [
            "Ava stressed about version mismatch conflict",
            "fdb6484b-e416-497e-b479-9a1d0f6b156b reports version v2.0.0-beta",
            "Elijah mentioned version mismatch conflict"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5003.18717956543,
          "generation_latency_ms": 4538.127899169922,
          "scoring_latency_ms": 2736.4611625671387,
          "total_latency_ms": 12277.77624130249
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "In the session immediately following the discussion about the failed blue-green deployment, what personal task did the user ask to be reminded of?",
          "answer_type": "short_answer",
          "gold_answer": "Pick up dry cleaning",
          "predicted_answer": "buy espresso beans",
          "retrieved_context": [
            "user requested flag for DevOps team",
            "user reminded to call mom at 6 PM",
            "milk reminder set for user"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4227.2703647613525,
          "generation_latency_ms": 5816.105127334595,
          "scoring_latency_ms": 3041.8052673339844,
          "total_latency_ms": 13085.180759429932
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What deployment strategy did the user suspect caused the split-brain situation on the cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "Blue-green deployment",
          "predicted_answer": "blue-green deployment",
          "retrieved_context": [
            "CacheLayer4 has problem split-brain issue",
            "blue-green deployment failure suspected cause of issue in CacheLayer4",
            "Ava managing deployment of CacheLayer4"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5525.261878967285,
          "generation_latency_ms": 2975.302219390869,
          "scoring_latency_ms": 2737.842559814453,
          "total_latency_ms": 11238.406658172607
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's repeated requests across sessions, what specific beverage is essential to their morning routine?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "30982d16-b14d-481a-bf7d-a85971d1bca9 requested by user",
            "user consumed double espresso",
            "user needs to pick up espresso beans"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 3700.4504203796387,
          "generation_latency_ms": 3284.2912673950195,
          "scoring_latency_ms": 2662.4858379364014,
          "total_latency_ms": 9647.22752571106
        },
        {
          "probe_id": "preference_learning-explicit_preferences-1",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Does the user approve of running the beta version of the cache layer in the production environment?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "CacheLayer4 running version v2.0.0-beta",
            "CacheLayer4 runs version 2.0 beta version",
            "CacheLayer4 reporting version v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4931.699514389038,
          "generation_latency_ms": 4683.220148086548,
          "scoring_latency_ms": 2562.620162963867,
          "total_latency_ms": 12177.539825439453
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific software version is PrimaryDB2 currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB2 running on Google Cloud Platform",
            "PrimaryDB2 hosted on GCP",
            "e0832262-3c1a-4c68-a6f3-5c6e3a451ca0 hosted on Google Cloud"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4398.19073677063,
          "generation_latency_ms": 5191.8487548828125,
          "scoring_latency_ms": 2568.451404571533,
          "total_latency_ms": 12158.490896224976
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-2",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Sales Lead's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Sales Lead is Liam",
            "082bfba0-0f18-49d3-80f8-57d410735824 has revenue numbers ready for Liam",
            "Alex requested revenue figures via Sales Lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5130.079746246338,
          "generation_latency_ms": 5329.417705535889,
          "scoring_latency_ms": 3039.8802757263184,
          "total_latency_ms": 13499.377727508545
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "Which team lead was identified as requiring the beta version of the cache layer for a new UI?",
          "answer_type": "short_answer",
          "gold_answer": "Olivia",
          "predicted_answer": "Olivia",
          "retrieved_context": [
            "Frontend Lead may know about version conflict on CacheLayer4",
            "engineering team to be contacted about version conflict on CacheLayer4",
            "v2.0.0-beta version of CacheLayer4"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5630.836009979248,
          "generation_latency_ms": 4376.156330108643,
          "scoring_latency_ms": 2650.8874893188477,
          "total_latency_ms": 12657.879829406738
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-1",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "When the user requested a health check on the 'databases hosted on Azure', which specific system identifiers did the assistant report on?",
          "answer_type": "short_answer",
          "gold_answer": "PrimaryDB7 and PrimaryDB6",
          "predicted_answer": "PrimaryDB7 and PrimaryDB6",
          "retrieved_context": [
            "databases on Microsoft's cloud hosted on Azure deployments",
            "PrimaryDB7 hosted on Microsoft Azure",
            "7f5c587a-d6cb-4cda-aad1-4e9419c3422e includes PrimaryDB7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4794.0192222595215,
          "generation_latency_ms": 4532.623767852783,
          "scoring_latency_ms": 2578.3815383911133,
          "total_latency_ms": 11905.024528503418
        }
      ],
      "summary": {
        "overall_accuracy": 0.9166666666666666,
        "total_score": 11,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 8,
            "count": 9,
            "accuracy": 0.8888888888888888
          },
          "boolean": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_030.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 26,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 23.25640559196472,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does system:loadbalancer_3 hosted on?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "03dc08c8-9159-4ae3-ac91-a8b63b8b0cae hosted in Microsoft environment",
            "70a50851-f700-4ad2-a99e-a10aad10b873 part of Azure resources",
            "740ddb50-e2ef-4987-97e2-811f3a7304e5 part of Azure components"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4143.905401229858,
          "generation_latency_ms": 4533.668279647827,
          "scoring_latency_ms": 3113.987445831299,
          "total_latency_ms": 11791.561126708984
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "hike planned by user",
            "hike scheduled for January 8, 2026",
            "user plans to message Slack"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5037.850618362427,
          "generation_latency_ms": 3668.4038639068604,
          "scoring_latency_ms": 2755.4593086242676,
          "total_latency_ms": 11461.713790893555
        }
      ],
      "summary": {
        "overall_accuracy": 1.0,
        "total_score": 2,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_031.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 27,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 23.902372121810913,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does person:user has role?",
          "answer_type": "short_answer",
          "gold_answer": "CTO",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "603f7894-e6d3-4f7f-83af-891e4b8fbd4f will notify Sophia",
            "603f7894-e6d3-4f7f-83af-891e4b8fbd4f will notify Sophia",
            "Sophia has role Product Designer"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5293.813705444336,
          "generation_latency_ms": 3199.336051940918,
          "scoring_latency_ms": 2622.76029586792,
          "total_latency_ms": 11115.910053253174
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex plans to check weather for Saturday",
            "Noah stressing about board meeting",
            "Noah asked about quarterly projections"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4873.668670654297,
          "generation_latency_ms": 4983.701944351196,
          "scoring_latency_ms": 2926.208019256592,
          "total_latency_ms": 12783.578634262085
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 1,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_032.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 29,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 126.41883111000061,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which individual is the user referring to when mentioning their 'cofounder' who is concerned about quarterly report data?",
          "answer_type": "short_answer",
          "gold_answer": "Oliver",
          "predicted_answer": "Oliver",
          "retrieved_context": [
            "cofounder reported dashboard lag",
            "cofounder concerned about monthly cloud bills",
            "7e00ed0f-c4c8-480b-81ef-437b72e36301 needs report from new engine instance 6"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4557.967185974121,
          "generation_latency_ms": 4959.524869918823,
          "scoring_latency_ms": 2588.310718536377,
          "total_latency_ms": 12105.802774429321
        },
        {
          "probe_id": "world_modeling-category_membership-2",
          "pillar": "world_modeling",
          "subpillar": "type_category_membership",
          "question": "Among the discussed systems, which service is the outlier regarding its hosting provider compared to the primary databases?",
          "answer_type": "short_answer",
          "gold_answer": "CacheLayer1",
          "predicted_answer": "CacheLayer1",
          "retrieved_context": [
            "12367830-3241-470b-bd6c-09a03253b7fb hosted on AWS",
            "3d58d143-581f-44fe-bf1c-f677e9e69181 hosted on AWS",
            "primarydb4 hosted on AWS"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5062.858819961548,
          "generation_latency_ms": 3465.3356075286865,
          "scoring_latency_ms": 2834.08260345459,
          "total_latency_ms": 11362.277030944824
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the name of the pet belonging to the team member who holds the role of Product Designer?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "Luna unofficial mascot of design team",
            "Luna pet of Olivia",
            "Luna present during design review"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4838.05775642395,
          "generation_latency_ms": 3197.413921356201,
          "scoring_latency_ms": 2803.7450313568115,
          "total_latency_ms": 10839.216709136963
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-4",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "According to the system signals discussed in the latest sessions, which two versions of the analytics engine are running simultaneously?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "third analytics engine exhibits version mismatch",
            "main analytics engine running version v1.2.0",
            "AnalyticsEngine3 has active signals for version version 2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7915.510416030884,
          "generation_latency_ms": 4283.451080322266,
          "scoring_latency_ms": 2755.581855773926,
          "total_latency_ms": 14954.543352127075
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-5",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific event caused the delay in the Product Designer uploading the new assets?",
          "answer_type": "short_answer",
          "gold_answer": "Her cat knocked over a plant",
          "predicted_answer": "Luna walked across her keyboard",
          "retrieved_context": [
            "design assets uploaded on this morning",
            "Olivia responsible for uploading new UI assets",
            "Olivia expected to upload new UI assets"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5826.498508453369,
          "generation_latency_ms": 5306.636810302734,
          "scoring_latency_ms": 2867.7868843078613,
          "total_latency_ms": 14000.922203063965
        },
        {
          "probe_id": "temporal_episodic-sequencing-6",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the discussion about the Google Cloud latency occur before or after the user first mentioned the dual-version issue with the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "After",
          "predicted_answer": "After",
          "retrieved_context": [
            "b26bde20-4696-4792-82e1-71835043f6b9 possibly caused by AnalyticsEngine6",
            "user inquired about cloud provider AnalyticsEngine6",
            "third analytics engine exhibits version mismatch"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5636.245012283325,
          "generation_latency_ms": 5626.010894775391,
          "scoring_latency_ms": 2773.679494857788,
          "total_latency_ms": 14035.935401916504
        },
        {
          "probe_id": "preference_learning-induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's complaints about the infrastructure, what architectural arrangement does the user implicitly dislike?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-cloud hosting",
          "predicted_answer": "Multi-cloud architecture",
          "retrieved_context": [
            "Liam complains about latency of CacheLayer1",
            "Alex concerned about CacheLayer1",
            "Liam complained during sprint review"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4600.011587142944,
          "generation_latency_ms": 5143.072128295898,
          "scoring_latency_ms": 2658.7071418762207,
          "total_latency_ms": 12401.790857315063
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider is the company's email server hosted on?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB7 hosted on Amazon",
            "PrimaryDB4 hosted on Amazon",
            "AnalyticsEngine3 hosted on AWS"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5069.854021072388,
          "generation_latency_ms": 3842.844247817993,
          "scoring_latency_ms": 2578.058958053589,
          "total_latency_ms": 11490.75722694397
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the current VP of Marketing?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Oliver has role CEO",
            "Liam leads backend team",
            "Liam holds role Backend Lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8209.188222885132,
          "generation_latency_ms": 2894.496440887451,
          "scoring_latency_ms": 2919.544458389282,
          "total_latency_ms": 14023.229122161865
        },
        {
          "probe_id": "procedural_knowledge-task_state-10",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "Why is the DevOps lead currently unable to assist with migrating the cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "Swamped with deployment pipeline",
          "predicted_answer": "He's swamped with the deployment pipeline.",
          "retrieved_context": [
            "Will needs to prioritize DevOps ticket",
            "5f67ee02-8499-4895-b899-5ce8f653befc experienced by CacheLayer1",
            "Will maintains CacheLayer1"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4310.455322265625,
          "generation_latency_ms": 4287.714004516602,
          "scoring_latency_ms": 2591.338872909546,
          "total_latency_ms": 11189.508199691772
        }
      ],
      "summary": {
        "overall_accuracy": 0.8,
        "total_score": 8,
        "count": 10,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 8,
            "accuracy": 0.75
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_033.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 29,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 326.5929355621338,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user referring to when they mention their cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Ava",
          "predicted_answer": "Ava",
          "retrieved_context": [
            "user has cofounder cofounder",
            "user plans to sync with cofounder",
            "user scheduled for sync with cofounder"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5284.70253944397,
          "generation_latency_ms": 4984.988451004028,
          "scoring_latency_ms": 2714.7138118743896,
          "total_latency_ms": 12984.404802322388
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "On which cloud provider is the service managed by the backend lead testing the beta version hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "Will leading backend push of v2.0.0-beta",
            "auth service hosted on AWS",
            "cache layer hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4563.715934753418,
          "generation_latency_ms": 2595.50404548645,
          "scoring_latency_ms": 2971.0965156555176,
          "total_latency_ms": 10130.316495895386
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the name of the pet belonging to the DevOps team member who was worried about the update?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "DevOps team includes member Mia",
            "DevOps team includes member Mia",
            "DevOps team includes member Lucas"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4563.709020614624,
          "generation_latency_ms": 4970.773220062256,
          "scoring_latency_ms": 2766.6971683502197,
          "total_latency_ms": 12301.1794090271
        },
        {
          "probe_id": "declarative_reasoning-verbatim_recall-3",
          "pillar": "declarative_reasoning",
          "subpillar": "verbatim_recall",
          "question": "What specific two-word phrase did the user use to describe the situation where the cache layer was reporting two different version headers?",
          "answer_type": "verbatim",
          "gold_answer": "split-brain situation",
          "predicted_answer": "version mismatch",
          "retrieved_context": [
            "CacheLayer5 exhibits version mismatch issue",
            "CacheLayer5 reporting version v2.0.0-beta",
            "CacheLayer5 reports version version 2.0.0 beta"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 9682.87467956543,
          "generation_latency_ms": 5387.754678726196,
          "scoring_latency_ms": 2784.877300262451,
          "total_latency_ms": 17855.506658554077
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-4",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user ask for a reminder about the dentist appointment before or after asking for the dry cleaning reminder?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "After",
          "retrieved_context": [
            "user reminded to pick up dry cleaning",
            "dry cleaning reminder scheduled for 5:00 PM",
            "dentist call reminder scheduled for 2 PM on January 7, 2026"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5218.255519866943,
          "generation_latency_ms": 3253.0465126037598,
          "scoring_latency_ms": 4082.045316696167,
          "total_latency_ms": 12553.34734916687
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-5",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why did the user suspect a version mismatch was causing issues with the dashboard?",
          "answer_type": "short_answer",
          "gold_answer": "Lag / Slowness",
          "predicted_answer": "The dashboard claimed v1.2.0, but logs showed v2.0.0-beta.",
          "retrieved_context": [
            "version mismatch causes dashboard lag",
            "version mismatch problem dashboard version v1.2.0",
            "Mia suspects version mismatch issue"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6631.621599197388,
          "generation_latency_ms": 5067.670583724976,
          "scoring_latency_ms": 2702.268362045288,
          "total_latency_ms": 14401.560544967651
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on previous orders, what food does the user prefer for team lunches?",
          "answer_type": "short_answer",
          "gold_answer": "Pizza",
          "predicted_answer": "Pizza",
          "retrieved_context": [
            "pizza order reminder set for user",
            "user wants to be reminded to pick up coffee beans",
            "eb916bf9-840c-4569-8f60-805d1327c0bc scheduled for noon"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 176077.16965675354,
          "generation_latency_ms": 4997.346878051758,
          "scoring_latency_ms": 2800.562620162964,
          "total_latency_ms": 183875.07915496826
        },
        {
          "probe_id": "preference_learning-explicit_preferences-7",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Does the user prefer to message Mia personally about the update or have the assistant do it?",
          "answer_type": "short_answer",
          "gold_answer": "Personally",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user wants to ask about Mia",
            "Alex communicates about Mia",
            "Mia has vet appointment"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5505.045175552368,
          "generation_latency_ms": 4503.0412673950195,
          "scoring_latency_ms": 2704.1683197021484,
          "total_latency_ms": 12712.254762649536
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of James's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Luna pet of Mia",
            "f38d255f-d2ab-44cb-bd8c-edcbd625d69e splits with backend logic",
            "Alex requested assistance from James"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7836.528539657593,
          "generation_latency_ms": 4178.749561309814,
          "scoring_latency_ms": 2737.3337745666504,
          "total_latency_ms": 14752.611875534058
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What version of software is running on the primary database hosted on Azure?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "439c6346-5193-45dd-819f-c4c1a3e546b7 hosted on Azure",
            "79449dc3-47ac-4a36-8a15-fa31f5c21d2e hosted on Microsoft Azure",
            "v2.0.0-beta alias of Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5169.3761348724365,
          "generation_latency_ms": 4416.310548782349,
          "scoring_latency_ms": 2958.2979679107666,
          "total_latency_ms": 12543.984651565552
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-10",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "Who are the two individuals usually responsible for handling infrastructure tickets?",
          "answer_type": "short_answer",
          "gold_answer": "Mia and Lucas",
          "predicted_answer": "Mia and Lucas",
          "retrieved_context": [
            "Ava expected to question about infrastructure user",
            "server-side teams has issue split between James and Will",
            "Mia can perform DevOps tasks"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4821.134805679321,
          "generation_latency_ms": 3073.470115661621,
          "scoring_latency_ms": 2866.12868309021,
          "total_latency_ms": 10760.733604431152
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-11",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "Who should be contacted regarding issues with the backend beta push?",
          "answer_type": "short_answer",
          "gold_answer": "Will",
          "predicted_answer": "Lucas",
          "retrieved_context": [
            "Will member of backend team",
            "James has role Backend Lead",
            "James can review backend logs"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4810.5456829071045,
          "generation_latency_ms": 4201.225757598877,
          "scoring_latency_ms": 2691.6191577911377,
          "total_latency_ms": 11703.39059829712
        }
      ],
      "summary": {
        "overall_accuracy": 0.5833333333333334,
        "total_score": 7,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 9,
            "accuracy": 0.5555555555555556
          },
          "verbatim": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_034.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 177.73558020591736,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual referred to as the user's 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Charlotte",
          "predicted_answer": "Charlotte",
          "retrieved_context": [
            "cofounder pressuring for fixing AuthService5 issue",
            "budget meeting with cofounder",
            "cofounder identity of Charlotte"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4862.0285987854,
          "generation_latency_ms": 7412.3334884643555,
          "scoring_latency_ms": 2709.972858428955,
          "total_latency_ms": 14984.334945678711
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which team member is the owner of the pet named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Mia",
          "predicted_answer": "Mia",
          "retrieved_context": [
            "Luna belongs to Mia",
            "Luna associated with design team",
            "Mia showed photos of Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4988.934755325317,
          "generation_latency_ms": 3768.829584121704,
          "scoring_latency_ms": 2660.853862762451,
          "total_latency_ms": 11418.618202209473
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which infrastructure component is hosted on a different cloud provider than the Primary Database and Cache Layer?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer8",
          "predicted_answer": "LoadBalancer8",
          "retrieved_context": [
            "PrimaryDB3 co-located with CacheLayer4",
            "CacheLayer4 hosted on Google Cloud Platform",
            "c98c23c2-5790-4351-b2cc-60d1ccf4d7bb hosted on GCP"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5645.531177520752,
          "generation_latency_ms": 3624.476671218872,
          "scoring_latency_ms": 3253.676652908325,
          "total_latency_ms": 12523.68450164795
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Is the authentication service currently running a single version or multiple versions simultaneously?",
          "answer_type": "short_answer",
          "gold_answer": "Multiple versions",
          "predicted_answer": "Multiple versions simultaneously",
          "retrieved_context": [
            "6374540e-28e0-45dd-ae60-95d2bf5e4abf running version Auth service v1.2.0",
            "auth service running version v2.0.0-beta",
            "6374540e-28e0-45dd-ae60-95d2bf5e4abf running version Auth service v2.0.0 beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4618.24107170105,
          "generation_latency_ms": 2989.288091659546,
          "scoring_latency_ms": 2651.939868927002,
          "total_latency_ms": 10259.469032287598
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "According to the production logs, what is the primary architectural cause of the observed latency?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-cloud hop",
          "predicted_answer": "cross-cloud hop",
          "retrieved_context": [
            "latency logs record latency for production environment",
            "cross-cloud hop causes latency in latency logs",
            "cross-cloud latency caused by LoadBalancer8"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7875.756740570068,
          "generation_latency_ms": 3090.0399684906006,
          "scoring_latency_ms": 3136.371850967407,
          "total_latency_ms": 14102.168560028076
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did Luna knock over a plant before or after she was reported getting stuck in a box?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "After.",
          "retrieved_context": [
            "Luna stuck in box",
            "Luna got into trouble on morning",
            "Luna got into mischief during weekend"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4245.973587036133,
          "generation_latency_ms": 5229.334115982056,
          "scoring_latency_ms": 3156.1219692230225,
          "total_latency_ms": 12631.429672241211
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the frontend service?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "7941f876-5583-44da-b447-a8a094bd5afe hosted on GCP",
            "auth service hosted on GCP",
            "LoadBalancer8 hosted on Amazon cloud"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4573.7621784210205,
          "generation_latency_ms": 4675.9819984436035,
          "scoring_latency_ms": 2661.038398742676,
          "total_latency_ms": 11910.7825756073
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-2",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the pet owned by the Sales Lead?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Oliver holds role sales lead",
            "Luna belongs to Mia",
            "Sophia holds role DevOps lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 26211.94362640381,
          "generation_latency_ms": 4436.5808963775635,
          "scoring_latency_ms": 2948.4570026397705,
          "total_latency_ms": 33596.98152542114
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Does the user prefer maintaining the current multi-cloud setup or consolidating the infrastructure?",
          "answer_type": "short_answer",
          "gold_answer": "Consolidating",
          "predicted_answer": "Consolidating the infrastructure",
          "retrieved_context": [
            "2f7168d7-2443-433d-a4d0-8c3f4154c5e2 includes Google Cloud Platform",
            "Alex viewed infrastructure dashboard",
            "0d37dc7c-fdc4-4125-9d06-5fad004d5ac8 hosted on GCP"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5040.818929672241,
          "generation_latency_ms": 5112.357139587402,
          "scoring_latency_ms": 4172.989845275879,
          "total_latency_ms": 14326.165914535522
        },
        {
          "probe_id": "preference_learning-preference_induction-2",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "How does the user feel about the topology map showing the load balancer on AWS?",
          "answer_type": "short_answer",
          "gold_answer": "Annoyed",
          "predicted_answer": "It's hurting my eyes.",
          "retrieved_context": [
            "a342e5c7-6705-4b46-8075-a016590771dd hosted on Amazon",
            "LoadBalancer8 hosted on AWS",
            "ae2a21b9-89f2-4682-af60-8d98c239ae68 hosted on AWS"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4607.488632202148,
          "generation_latency_ms": 3586.902379989624,
          "scoring_latency_ms": 3107.1648597717285,
          "total_latency_ms": 11301.555871963501
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What general observation did the assistant make regarding the nature of architectures that span AWS and GCP?",
          "answer_type": "short_answer",
          "gold_answer": "They can be complex",
          "predicted_answer": "It is a bit of an unusual setup.",
          "retrieved_context": [
            "0d37dc7c-fdc4-4125-9d06-5fad004d5ac8 hosted on GCP",
            "0d37dc7c-fdc4-4125-9d06-5fad004d5ac8 hosted on GCP",
            "2f7168d7-2443-433d-a4d0-8c3f4154c5e2 includes Google Cloud Platform"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5054.611444473267,
          "generation_latency_ms": 7402.840137481689,
          "scoring_latency_ms": 3362.583637237549,
          "total_latency_ms": 15820.035219192505
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-1",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "When the user mentioned buying treats for Luna, what action did the assistant confirm taking?",
          "answer_type": "short_answer",
          "gold_answer": "Added a reminder",
          "predicted_answer": "Added a reminder to buy treats for Mia's cat.",
          "retrieved_context": [
            "user set reminder for reminder to buy treats for Luna",
            "reminder to buy treats for Luna for Luna",
            "Mia mentioned treat preference for Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6723.548412322998,
          "generation_latency_ms": 4508.76259803772,
          "scoring_latency_ms": 3609.604597091675,
          "total_latency_ms": 14841.915607452393
        }
      ],
      "summary": {
        "overall_accuracy": 0.75,
        "total_score": 9,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 7,
            "count": 10,
            "accuracy": 0.7
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_035.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 36,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 128.75734686851501,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user referring to when they mention a meeting with their cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Mia",
          "predicted_answer": "Mia",
          "retrieved_context": [
            "user preparing for 1:1 meeting with cofounder",
            "user preparing for 1:1 meeting with cofounder",
            "board meeting mentioned by cofounder"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5094.167947769165,
          "generation_latency_ms": 3952.3684978485107,
          "scoring_latency_ms": 4133.564233779907,
          "total_latency_ms": 13180.100679397583
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the name of the pet belonging to the Sales Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "Luna belongs to Sales",
            "Olivia holds role Sales Lead",
            "Olivia holds role Sales Lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4751.547813415527,
          "generation_latency_ms": 3797.1246242523193,
          "scoring_latency_ms": 3665.5142307281494,
          "total_latency_ms": 12214.186668395996
        },
        {
          "probe_id": "preference_learning-preference_induction-3",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's morning routines, what beverage do they require to function properly?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Espresso",
          "retrieved_context": [
            "Alex owns coffee machine",
            "Alex requested morning status checks",
            "user wants to check if opened new coffee shop downstairs"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5229.978799819946,
          "generation_latency_ms": 4923.553466796875,
          "scoring_latency_ms": 5169.424057006836,
          "total_latency_ms": 15322.956323623657
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-4",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "On which cloud provider is the primary database hosted?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "152d1748-4168-42e9-b068-a713576c6c05 hosted on Google Cloud Platform",
            "152d1748-4168-42e9-b068-a713576c6c05 hosted on Google Cloud Platform",
            "AuthService9 hosted on Google Cloud"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6485.461950302124,
          "generation_latency_ms": 4296.203136444092,
          "scoring_latency_ms": 3209.3496322631836,
          "total_latency_ms": 13991.0147190094
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-5",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "When the user requests the 'morning status checks', which service is verified immediately after the load balancers?",
          "answer_type": "short_answer",
          "gold_answer": "AuthService9",
          "predicted_answer": "AuthService9",
          "retrieved_context": [
            "Alex requested morning status checks",
            "LoadBalancer2 reports healthy status",
            "LoadBalancer9 reports healthy status"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 3566.868305206299,
          "generation_latency_ms": 3112.656831741333,
          "scoring_latency_ms": 3070.8680152893066,
          "total_latency_ms": 9750.393152236938
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-6",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "During the conversation where the user mentioned being 'barely awake', what specific data were they preparing to review with Mia?",
          "answer_type": "short_answer",
          "gold_answer": "Quarterly figures",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "436c8516-3570-4f1d-b0b9-47dcfa397811 involves Mia",
            "user reminds to message Mia",
            "06f7fc05-9be0-4f5c-8c71-c948493b3cc8 requested meeting with Alex"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4453.786611557007,
          "generation_latency_ms": 4258.451700210571,
          "scoring_latency_ms": 4757.560968399048,
          "total_latency_ms": 13469.799280166626
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-7",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "Given that the authentication service is co-located with the load balancers, which cloud provider hosts it?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google Cloud Platform",
          "retrieved_context": [
            "authentication service number 9 hosted in Google Cloud Platform",
            "AuthService9 hosted on Google Cloud Platform",
            "Auth9 hosted on Google Cloud"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5885.629177093506,
          "generation_latency_ms": 3891.4363384246826,
          "scoring_latency_ms": 3873.542308807373,
          "total_latency_ms": 13650.607824325562
        },
        {
          "probe_id": "world_modeling-relationship_mapping-8",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the job title of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales Lead",
          "retrieved_context": [
            "e0bf2452-6417-486a-85b1-c013de63175f owns Luna",
            "Olivia owns Luna",
            "Olivia owns Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5432.292461395264,
          "generation_latency_ms": 3926.450490951538,
          "scoring_latency_ms": 4220.93939781189,
          "total_latency_ms": 13579.682350158691
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "What is the single definitive running version of CacheLayer6?",
          "answer_type": "short_answer",
          "gold_answer": "Ambiguous",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "CacheLayer6 running version v1.2.0",
            "CacheLayer6 running version v2.0.0-beta",
            "CacheLayer6 source of cache issue"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 3822.3044872283936,
          "generation_latency_ms": 5251.269817352295,
          "scoring_latency_ms": 3485.466480255127,
          "total_latency_ms": 12559.040784835815
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-10",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "In the session where the user reviewed architecture diagrams, did they ask about the load balancers before or after asking for a lunch reminder?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Before",
          "retrieved_context": [
            "user planning to attend lunch meeting with Noah",
            "user instructed to investigate backend lead",
            "user preparing for 1:1 meeting with cofounder"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4274.862766265869,
          "generation_latency_ms": 3336.1809253692627,
          "scoring_latency_ms": 3381.7899227142334,
          "total_latency_ms": 10992.833614349365
        }
      ],
      "summary": {
        "overall_accuracy": 0.7,
        "total_score": 7,
        "count": 10,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 9,
            "accuracy": 0.6666666666666666
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_036.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 11,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 154.7967345714569,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual referred to by the user as 'my cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "cofounder concerned about budget",
            "James cofounder of user",
            "cofounder inquired about caching service"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8655.944347381592,
          "generation_latency_ms": 3491.9872283935547,
          "scoring_latency_ms": 3717.3218727111816,
          "total_latency_ms": 15865.253448486328
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What professional role is shared by both Emma and Mia?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales Lead",
          "retrieved_context": [
            "Emma shares role with Mia",
            "Mia holds role Sales Lead",
            "Emma holds role Sales Lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6063.271284103394,
          "generation_latency_ms": 4573.516130447388,
          "scoring_latency_ms": 3521.278142929077,
          "total_latency_ms": 14158.065557479858
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which two specific cloud providers are generating the high egress fees due to cross-cloud traffic?",
          "answer_type": "short_answer",
          "gold_answer": "Azure and AWS",
          "predicted_answer": "Azure and AWS",
          "retrieved_context": [
            "cross-cloud traffic explains egress fees",
            "cross-cloud traffic involves load balancer",
            "b347cf49-f675-4d59-8bc7-691df7faa3ce causing infrastructure costs"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5805.052995681763,
          "generation_latency_ms": 4784.184694290161,
          "scoring_latency_ms": 3385.4875564575195,
          "total_latency_ms": 13974.725246429443
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-4",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "Which infrastructure component is violating the production stability constraint by running a beta version?",
          "answer_type": "short_answer",
          "gold_answer": "CacheLayer5",
          "predicted_answer": "CacheLayer5",
          "retrieved_context": [
            "24abc579-d5b6-407e-86aa-4e0e31932c79 related to version mismatch problem",
            "66854e31-d8d3-4db2-9e69-6f116a6fd75f involves beta monitor",
            "CacheLayer5 running version v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5030.639410018921,
          "generation_latency_ms": 5002.575159072876,
          "scoring_latency_ms": 3659.041166305542,
          "total_latency_ms": 13692.255735397339
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What specific disruption involving a pet occurred during the frontend sync meeting?",
          "answer_type": "short_answer",
          "gold_answer": "Luna jumped on keyboard",
          "predicted_answer": "Luna interrupted frontend sync",
          "retrieved_context": [
            "Luna interrupted frontend sync",
            "Luna interrupted standup meeting",
            "user plans to schedule sync with frontend team"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 7972.603559494019,
          "generation_latency_ms": 3726.038694381714,
          "scoring_latency_ms": 3154.048204421997,
          "total_latency_ms": 14852.69045829773
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-6",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why is the user specifically worried about James discovering the current state of the cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "Testing beta in production",
          "predicted_answer": "James is the CEO and is worried about platform stability and infrastructure costs.",
          "retrieved_context": [
            "Alex concerned about CacheLayer5",
            "James worried about platform stability concern",
            "user will explain to James"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6867.032289505005,
          "generation_latency_ms": 5455.180644989014,
          "scoring_latency_ms": 3589.6975994110107,
          "total_latency_ms": 15911.91053390503
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-7",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the company's email server?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Azure owned by Microsoft",
            "AuthService1 hosted on Google Cloud Platform",
            "PrimaryDB5 hosted on Microsoft cloud"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4452.769994735718,
          "generation_latency_ms": 4053.7452697753906,
          "scoring_latency_ms": 3443.5832500457764,
          "total_latency_ms": 11950.098514556885
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "What is the specific version number currently running on the PrimaryDB5 instance?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "0c46a0d3-c5eb-4110-9c29-80ac35caa1c7 hosted on Azure",
            "d7119207-7763-44a3-83cb-ba1b0f4f2af5 hosted on Azure",
            "657c1f2e-a0fe-49cb-9e58-dc3cb583a5c9 hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5122.208118438721,
          "generation_latency_ms": 6079.153776168823,
          "scoring_latency_ms": 3730.380058288574,
          "total_latency_ms": 14931.741952896118
        },
        {
          "probe_id": "preference_learning-preference_induction-9",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "When the assistant offered to draft a message to James regarding the version mismatch, how did the user prefer to handle the communication?",
          "answer_type": "short_answer",
          "gold_answer": "Handle it personally",
          "predicted_answer": "No, I'll handle him.",
          "retrieved_context": [
            "user will explain to James",
            "user plans to inform about James",
            "user plans to inform about James"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5673.703670501709,
          "generation_latency_ms": 4252.498626708984,
          "scoring_latency_ms": 3270.890474319458,
          "total_latency_ms": 13197.092771530151
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-10",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "According to the user's routine, what is the required duration for steeping tea?",
          "answer_type": "short_answer",
          "gold_answer": "Ten minutes",
          "predicted_answer": "ten minutes",
          "retrieved_context": [
            "user set timer for ten minutes",
            "user plans to take coffee break",
            "Alex scheduled for caffeine break reminder"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5993.711471557617,
          "generation_latency_ms": 4521.055221557617,
          "scoring_latency_ms": 4014.7407054901123,
          "total_latency_ms": 14529.507398605347
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-11",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "Based on the user's discussions about the cloud bill, what architectural choice is identified as the primary cause of high costs?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-cloud data transfer",
          "predicted_answer": "Multi-cloud setup",
          "retrieved_context": [
            "user needs to explain ridiculous cloud bill",
            "b347cf49-f675-4d59-8bc7-691df7faa3ce causing infrastructure costs",
            "infrastructure costs related to major providers"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4904.430389404297,
          "generation_latency_ms": 3408.9293479919434,
          "scoring_latency_ms": 3377.491235733032,
          "total_latency_ms": 11690.850973129272
        }
      ],
      "summary": {
        "overall_accuracy": 0.6363636363636364,
        "total_score": 7,
        "count": 11,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 9,
            "accuracy": 0.5555555555555556
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_037.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 28,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 198.24540853500366,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which specific individual is the user referring to as their 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "Alex has cofounder cofounder",
            "cofounder requests by status update",
            "cofounder concerned about dashboard issue"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5280.220985412598,
          "generation_latency_ms": 5132.101058959961,
          "scoring_latency_ms": 4177.711009979248,
          "total_latency_ms": 14590.033054351807
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which team member flagged the latency issues on the database hosted on Google Cloud?",
          "answer_type": "short_answer",
          "gold_answer": "Olivia",
          "predicted_answer": "Olivia",
          "retrieved_context": [
            "Olivia flagged latency on main database",
            "770605ad-d6d5-414a-92d1-e3de309c0eeb concerned about database latency",
            "main database hosted in Google Cloud environment"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5215.63196182251,
          "generation_latency_ms": 3578.666925430298,
          "scoring_latency_ms": 4758.364200592041,
          "total_latency_ms": 13552.663087844849
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Despite earlier conflicting headers, what version is the GCP load balancer confirmed to be running after the update?",
          "answer_type": "short_answer",
          "gold_answer": "v2.0.0-beta",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "LoadBalancer9 reported version v1.2.0",
            "LoadBalancer9 reporting version LoadBalancer9 version v2.0.0-beta",
            "LoadBalancer9 running version version v1.2.0"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8038.524389266968,
          "generation_latency_ms": 5773.5631465911865,
          "scoring_latency_ms": 3636.9216442108154,
          "total_latency_ms": 17449.00918006897
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the 'segregated' load balancer hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "other load balancer instances hosted on Google's cloud",
            "LoadBalancer9 hosted on Google Cloud Platform",
            "load balancers hosted in Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4107.260704040527,
          "generation_latency_ms": 4157.494783401489,
          "scoring_latency_ms": 3374.8133182525635,
          "total_latency_ms": 11639.56880569458
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific action taken by the DevOps lead caused LoadBalancer9 to switch to the beta version?",
          "answer_type": "short_answer",
          "gold_answer": "pushed an update",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "DevOps lead reported issue on LoadBalancer9",
            "DevOps team testing LoadBalancer9",
            "8e58daf9-5bea-4498-8918-87e5766c9f4a reported running version v2.0.0 beta"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6882.769823074341,
          "generation_latency_ms": 5829.266309738159,
          "scoring_latency_ms": 3202.899932861328,
          "total_latency_ms": 15914.936065673828
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user request the reminder to water plants before or after the reminder to pick up dry cleaning mentioned in Session llm-22?",
          "answer_type": "short_answer",
          "gold_answer": "after",
          "predicted_answer": "Before",
          "retrieved_context": [
            "user reminded to water plants",
            "user reminded to pick up dry cleaning",
            "user set dry cleaning reminder"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5939.747333526611,
          "generation_latency_ms": 6653.101205825806,
          "scoring_latency_ms": 3531.048536300659,
          "total_latency_ms": 16123.897075653076
        },
        {
          "probe_id": "preference_learning-explicit_preferences-1",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "When preparing reports for the CEO, what specific metric does he prefer to focus on?",
          "answer_type": "short_answer",
          "gold_answer": "uptime",
          "predicted_answer": "Uptime",
          "retrieved_context": [
            "user needs to prepare quarterly reports",
            "quarterly reports prepared for James",
            "Nebula Corp subject of usage report"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5511.472702026367,
          "generation_latency_ms": 4095.372438430786,
          "scoring_latency_ms": 3665.0230884552,
          "total_latency_ms": 13271.868228912354
        },
        {
          "probe_id": "preference_learning-constraint_hierarchy-1",
          "pillar": "preference_learning",
          "subpillar": "constraint_hierarchy",
          "question": "The user is nervous about beta versions but accepts them under what condition?",
          "answer_type": "short_answer",
          "gold_answer": "Olivia signed off",
          "predicted_answer": "Canary deploy",
          "retrieved_context": [
            "Will authorized software version v2.0.0-beta deployment",
            "Will would be upset if knows v2.0.0-beta",
            "Will investigates presence of v2.0.0-beta"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5608.168125152588,
          "generation_latency_ms": 5703.1569480896,
          "scoring_latency_ms": 3558.096170425415,
          "total_latency_ms": 14869.421243667603
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the pet belonging to the Product Designer named Lucas?",
          "answer_type": "short_answer",
          "gold_answer": "not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "a0b8f803-443e-48a4-9362-a12acfcca15a working on product design",
            "3269cc41-ffcc-4988-925f-b694dcaa3bad holds role Product Designer",
            "Lucas member of design team"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5705.895185470581,
          "generation_latency_ms": 3868.9539432525635,
          "scoring_latency_ms": 3434.922933578491,
          "total_latency_ms": 13009.772062301636
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-2",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What software version is the Azure-hosted load balancer currently running?",
          "answer_type": "short_answer",
          "gold_answer": "not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "software version v2.0.0-beta currently running on load balancer unit 9",
            "LoadBalancer9 running version version v1.2.0",
            "LoadBalancer9 running version version v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4749.25422668457,
          "generation_latency_ms": 26402.40168571472,
          "scoring_latency_ms": 3543.031692504883,
          "total_latency_ms": 34694.687604904175
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What condition does the Backend Lead typically verify before allowing a rollout?",
          "answer_type": "short_answer",
          "gold_answer": "backend is solid",
          "predicted_answer": "approved backend",
          "retrieved_context": [
            "assistant monitoring logs for Backend Lead",
            "Partial rollout describes state of LoadBalancer9",
            "GCP PrimaryDB7 checked during Production environment sanity check"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6435.07719039917,
          "generation_latency_ms": 5116.080760955811,
          "scoring_latency_ms": 3787.1084213256836,
          "total_latency_ms": 15338.266372680664
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-1",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "How did the assistant determine the version conflict on LoadBalancer9?",
          "answer_type": "short_answer",
          "gold_answer": "checking logs",
          "predicted_answer": "reporting both v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "ad9882c2-51a8-4c20-b932-42650af0de0e issue on LoadBalancer9",
            "Olivia noticed version mismatch on LoadBalancer9",
            "64629979-78e5-4458-8767-039536362eae about LoadBalancer9"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6755.543947219849,
          "generation_latency_ms": 5783.060789108276,
          "scoring_latency_ms": 5209.519863128662,
          "total_latency_ms": 17748.124599456787
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 12,
            "accuracy": 0.5
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_038.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 27,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 164.02462434768677,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which executive team member is reportedly concerned about the infrastructure costs?",
          "answer_type": "short_answer",
          "gold_answer": "Sophia",
          "predicted_answer": "Sophia",
          "retrieved_context": [
            "Sophia is stressing about infrastructure costs",
            "1f1bce9b-6b7b-400c-9dc6-4de092e8794e to be presented at all-hands meeting",
            "Sophia inquiring about infrastructure stability"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5391.019344329834,
          "generation_latency_ms": 3788.365125656128,
          "scoring_latency_ms": 3345.283269882202,
          "total_latency_ms": 12524.667739868164
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which service is co-located on the same cloud provider as the system handling traffic flow?",
          "answer_type": "short_answer",
          "gold_answer": "CacheLayer3",
          "predicted_answer": "CacheLayer3",
          "retrieved_context": [
            "LoadBalancer5 hosted on Google cloud infrastructure",
            "LoadBalancer5 hosted on Google Cloud Platform",
            "LoadBalancer5 hosted on Google Cloud Platform (GCP)"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5498.647451400757,
          "generation_latency_ms": 4629.923582077026,
          "scoring_latency_ms": 3001.7330646514893,
          "total_latency_ms": 13130.304098129272
        },
        {
          "probe_id": "declarative_reasoning-multi_hop-1",
          "pillar": "declarative_reasoning",
          "subpillar": "multi_hop_reasoning",
          "question": "The database connected to the Google-hosted load balancer is running on which infrastructure provider?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "AWS",
          "retrieved_context": [
            "55e4fb40-a2f0-4adc-bfd1-946c6db36428 routes traffic to PrimaryDB6",
            "55e4fb40-a2f0-4adc-bfd1-946c6db36428 alias of load balancer",
            "LoadBalancer5 routes traffic to CacheLayer3"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4257.436037063599,
          "generation_latency_ms": 4698.166608810425,
          "scoring_latency_ms": 2994.758367538452,
          "total_latency_ms": 11950.361013412476
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What versions of the caching service are currently active according to the latest diagnostics?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "CacheLayer3 reports active version v1.2.0",
            "CacheLayer3 reports active version v2.0.0-beta",
            "380af012-61e3-467d-829b-21a2a275ad08 reported by CacheLayer3"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6696.516752243042,
          "generation_latency_ms": 4357.107877731323,
          "scoring_latency_ms": 3323.3282566070557,
          "total_latency_ms": 14376.95288658142
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific deployment failure did the user identify as the cause of the cache latency spikes?",
          "answer_type": "short_answer",
          "gold_answer": "Stuck canary deployment",
          "predicted_answer": "version mismatch",
          "retrieved_context": [
            "fc40503b-1e30-4513-af68-e17e3657dac1 suspected cause LoadBalancer5",
            "Elijah responsible for deployment of third cache layer",
            "network hop possible cause of CacheLayer3"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6017.659664154053,
          "generation_latency_ms": 5259.634733200073,
          "scoring_latency_ms": 3273.430109024048,
          "total_latency_ms": 14550.724506378174
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user identify the stuck canary deployment before or after requesting a lunch reminder?",
          "answer_type": "short_answer",
          "gold_answer": "After",
          "predicted_answer": "After",
          "retrieved_context": [
            "Elijah started canary deployment",
            "lunch order reminder scheduled for January 7, 2026 18:20:01 UTC",
            "lunch reminder at 12:30 PM on January 7, 2026 scheduled for January 7, 2026 12:30:00"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7360.037803649902,
          "generation_latency_ms": 5413.755178451538,
          "scoring_latency_ms": 3105.335235595703,
          "total_latency_ms": 15879.128217697144
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "How did the user respond to the assistant's offer to block calendar time for the hiking trip?",
          "answer_type": "short_answer",
          "gold_answer": "Deferred it",
          "predicted_answer": "Unknown",
          "retrieved_context": [],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 2684.7598552703857,
          "generation_latency_ms": 3751.0643005371094,
          "scoring_latency_ms": 3146.937131881714,
          "total_latency_ms": 9582.761287689209
        },
        {
          "probe_id": "preference_learning-preference_induction-2",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What specific administrative action does the user consistently request across multiple sessions?",
          "answer_type": "short_answer",
          "gold_answer": "Setting reminders",
          "predicted_answer": "Set reminders",
          "retrieved_context": [
            "Sophia prefers fast load times for reporting dashboard",
            "Elijah investigating backend logs",
            "Will requesting latest numbers from analytics engine"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6134.992361068726,
          "generation_latency_ms": 5740.083932876587,
          "scoring_latency_ms": 3265.429973602295,
          "total_latency_ms": 15140.506267547607
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the frontend application?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Google Cloud",
          "retrieved_context": [
            "LoadBalancer5 hosted on Google cloud infrastructure",
            "LoadBalancer5 hosted on Google Cloud Platform",
            "LoadBalancer5 hosted on Google Cloud Platform (GCP)"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4918.609142303467,
          "generation_latency_ms": 4278.1360149383545,
          "scoring_latency_ms": 2968.7588214874268,
          "total_latency_ms": 12165.503978729248
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-2",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the user's pet?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Luna pet of Noah",
            "Luna owned by Noah",
            "Luna considered as team mascot"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5169.449329376221,
          "generation_latency_ms": 3878.248453140259,
          "scoring_latency_ms": 2807.741403579712,
          "total_latency_ms": 11855.439186096191
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-1",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What method did the user employ to check for cross-cloud bottlenecks between GCP and AWS?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-reference with database",
          "predicted_answer": "Asking the assistant to cross-reference the load balancer on GCP with the main database on AWS",
          "retrieved_context": [
            "cross-cloud hop suspected bottleneck for platform performance issues",
            "latency spike caused by cross-cloud hop",
            "3af6bce9-758b-4408-88bd-3abd8f573748 caused by LoadBalancer5"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8821.38180732727,
          "generation_latency_ms": 5173.2892990112305,
          "scoring_latency_ms": 3110.3906631469727,
          "total_latency_ms": 17105.061769485474
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What configuration state was determined to be the root cause of the conflicting signals in the cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "Split state",
          "predicted_answer": "version mismatch",
          "retrieved_context": [
            "380af012-61e3-467d-829b-21a2a275ad08 reported by CacheLayer3",
            "network hop possible cause of CacheLayer3",
            "4cc8b0e1-d0ad-40d6-baa5-b3f7614834e1 affects cache layer"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 7519.088983535767,
          "generation_latency_ms": 5175.346374511719,
          "scoring_latency_ms": 3013.1115913391113,
          "total_latency_ms": 15707.546949386597
        }
      ],
      "summary": {
        "overall_accuracy": 0.6666666666666666,
        "total_score": 8,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 8,
            "count": 12,
            "accuracy": 0.6666666666666666
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_039.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 29,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 28.170116424560547,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does person:mia has role?",
          "answer_type": "short_answer",
          "gold_answer": "Frontend Lead",
          "predicted_answer": "Frontend Lead",
          "retrieved_context": [
            "eb0e8936-a049-41a0-b55e-0d013585c029 holds role Frontend Lead",
            "b5ae9b96-7a69-44b3-a7be-7a6c99af3031 holds role Frontend Lead",
            "5672d866-4215-4e19-9968-ed101475ee51 posted in general channel"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5357.848405838013,
          "generation_latency_ms": 5443.647384643555,
          "scoring_latency_ms": 3197.6513862609863,
          "total_latency_ms": 13999.147176742554
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Mia invited to Meeting in an hour",
            "Mia sharing frontend updates",
            "Elijah needs to vent about quarterly sales figures"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6121.6278076171875,
          "generation_latency_ms": 4972.676753997803,
          "scoring_latency_ms": 3072.3235607147217,
          "total_latency_ms": 14166.628122329712
        }
      ],
      "summary": {
        "overall_accuracy": 1.0,
        "total_score": 2,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_040.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 31,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 180.86324667930603,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which cloud provider hosts the service that the Data Scientist complained about regarding latency?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "GCP and AWS",
          "retrieved_context": [
            "LoadBalancer2 hosted on Azure",
            "LoadBalancer1 has instances on Google Cloud Platform",
            "LoadBalancer1 reporting activity on GCP"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6290.08936882019,
          "generation_latency_ms": 4864.457130432129,
          "scoring_latency_ms": 3190.2472972869873,
          "total_latency_ms": 14344.793796539307
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Who is the Backend Lead responsible for the service currently experiencing a version leak?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "user confirmed backend lead is James",
            "James holds role Backend Lead",
            "Alex intends to ping backend lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7302.819013595581,
          "generation_latency_ms": 4722.790718078613,
          "scoring_latency_ms": 3635.0014209747314,
          "total_latency_ms": 15660.611152648926
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the individual who set the Friday deadline for the visual language drafts?",
          "answer_type": "short_answer",
          "gold_answer": "CEO",
          "predicted_answer": "CEO",
          "retrieved_context": [
            "Will handling new visual language",
            "Will member of design team",
            "Sophia handling new visual language"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4975.184679031372,
          "generation_latency_ms": 5104.198455810547,
          "scoring_latency_ms": 3468.921422958374,
          "total_latency_ms": 13548.304557800293
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What specific software versions were observed running on LoadBalancer2 during the latest infrastructure check?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "v1.2.0 running version on LoadBalancer2",
            "v2.0.0-beta running version on LoadBalancer2",
            "LoadBalancer2 running on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5849.621534347534,
          "generation_latency_ms": 4582.431077957153,
          "scoring_latency_ms": 3228.9512157440186,
          "total_latency_ms": 13661.003828048706
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-0",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the discussion about the Azure budget email occur before or after the user requested a dry cleaning reminder?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "After",
          "retrieved_context": [
            "Emma sent Azure budget email",
            "dry cleaning reminder at 5:00 PM on January 7, 2026 scheduled for January 7, 2026 17:00:00 UTC",
            "Azure budget email includes cost breakdown for AuthService9"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 7610.095262527466,
          "generation_latency_ms": 5916.5661334991455,
          "scoring_latency_ms": 4136.414289474487,
          "total_latency_ms": 17663.0756855011
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific infrastructure issue caused the user to request a flag be sent to the Backend Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Beta version traffic in production",
          "predicted_answer": "Two different versions of LoadBalancer2 (v1.2.0 and v2.0.0-beta) were active simultaneously.",
          "retrieved_context": [
            "user will check with Backend Lead",
            "Alex intends to ping backend lead",
            "Alex requested to flag issue to James"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6760.267972946167,
          "generation_latency_ms": 4698.119163513184,
          "scoring_latency_ms": 3421.4978218078613,
          "total_latency_ms": 14879.884958267212
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What physical activity does the user imply helps them prepare mentally for the work day?",
          "answer_type": "short_answer",
          "gold_answer": "Running",
          "predicted_answer": "quick run",
          "retrieved_context": [
            "Alex checking time before 10 AM standup",
            "b5ca5040-44c3-441f-80e4-1708cb67eadf participated in standup meeting",
            "quick run scheduled for 11:00 AM"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 7272.425174713135,
          "generation_latency_ms": 4997.657060623169,
          "scoring_latency_ms": 3575.129508972168,
          "total_latency_ms": 15845.211744308472
        },
        {
          "probe_id": "preference_learning-preference_scope-1",
          "pillar": "preference_learning",
          "subpillar": "preference_scope",
          "question": "Does the user express a preference for managing financial details like Azure bills personally?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "Emma worried about cloud spend on Azure",
            "Alex needs to discuss billing with Emma",
            "Emma may recall billing for LoadBalancer1"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5321.541547775269,
          "generation_latency_ms": 5530.045509338379,
          "scoring_latency_ms": 3752.307415008545,
          "total_latency_ms": 14603.894472122192
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the pet belonging to the Product Designer named Will?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Will holds role Product Designer",
            "design team includes Will",
            "Will handling product design"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4770.808696746826,
          "generation_latency_ms": 4869.369745254517,
          "scoring_latency_ms": 4010.737180709839,
          "total_latency_ms": 13650.915622711182
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the currently running version of AuthService3?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "migration for third auth service concerns AuthService3",
            "AuthService3 deployed on AWS",
            "AuthService3 reporting from AWS"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5659.7912311553955,
          "generation_latency_ms": 3971.4953899383545,
          "scoring_latency_ms": 3280.093193054199,
          "total_latency_ms": 12911.37981414795
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-0",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "According to the user's instructions during the beta leak incident, who is the point of contact for resolving backend configuration errors?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "user confirmed backend lead is James",
            "user will check with Backend Lead",
            "Alex intends to ping backend lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5909.649133682251,
          "generation_latency_ms": 5462.3353481292725,
          "scoring_latency_ms": 4173.8176345825195,
          "total_latency_ms": 15545.802116394043
        },
        {
          "probe_id": "procedural_knowledge-task_state_tracking-1",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "What is the current deadline status for the visual language drafts assigned to Sophia and Will?",
          "answer_type": "short_answer",
          "gold_answer": "Due Friday",
          "predicted_answer": "Friday",
          "retrieved_context": [
            "23143e60-b2e2-4312-8317-2d27e089bdbf preparing for upcoming UI review",
            "Sophia finalizing new UI assets",
            "Emma requested drafts from Sophia"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 10364.397048950195,
          "generation_latency_ms": 4592.876195907593,
          "scoring_latency_ms": 3497.3483085632324,
          "total_latency_ms": 18454.62155342102
        }
      ],
      "summary": {
        "overall_accuracy": 0.6666666666666666,
        "total_score": 8,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 9,
            "accuracy": 0.5555555555555556
          },
          "boolean": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_041.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 32,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 173.83610773086548,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "What is the job title of the individual the user refers to as 'my cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "CEO",
          "predicted_answer": "Cofounder",
          "retrieved_context": [
            "Alex has cofounder cofounder",
            "user plans to meet with cofounder",
            "cofounder pitching to board"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6767.884254455566,
          "generation_latency_ms": 3180.919647216797,
          "scoring_latency_ms": 3192.983388900757,
          "total_latency_ms": 13141.78729057312
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What professional role does the owner of the cat named 'Luna' hold?",
          "answer_type": "short_answer",
          "gold_answer": "Frontend Lead",
          "predicted_answer": "Frontend Lead",
          "retrieved_context": [
            "Frontend Lead appreciates inquiry about Luna",
            "Frontend Lead needs to cat proof apartment for Luna",
            "Ava holds role Frontend Lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7768.615961074829,
          "generation_latency_ms": 3219.149351119995,
          "scoring_latency_ms": 3340.2154445648193,
          "total_latency_ms": 14327.980756759644
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which cloud provider hosts the service currently running the v2.0.0-beta version?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "GCP",
          "retrieved_context": [
            "1782a019-09ae-4155-aae0-0e1b775e1517 running on GCP host",
            "Google cloud environment active version v2.0.0-beta",
            "Google cloud environment active version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5859.419822692871,
          "generation_latency_ms": 3031.886577606201,
          "scoring_latency_ms": 2919.4674491882324,
          "total_latency_ms": 11810.773849487305
        },
        {
          "probe_id": "declarative_reasoning-baseline_factual_recall-4",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What type of service is hosted on the Azure platform?",
          "answer_type": "short_answer",
          "gold_answer": "Auth service",
          "predicted_answer": "Authentication service",
          "retrieved_context": [
            "Azure owned by Microsoft",
            "instance 6 hosted on Azure",
            "AuthService6 hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 23859.539270401,
          "generation_latency_ms": 4706.131219863892,
          "scoring_latency_ms": 2866.2161827087402,
          "total_latency_ms": 31431.886672973633
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What specific event was the CEO anxious about regarding platform stability?",
          "answer_type": "short_answer",
          "gold_answer": "Investor demo",
          "predicted_answer": "upcoming presentation",
          "retrieved_context": [
            "CEO anxious about platform stability",
            "cofounder requested stability report",
            "platform stability required for upcoming presentation"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5987.596273422241,
          "generation_latency_ms": 3196.3155269622803,
          "scoring_latency_ms": 2918.956995010376,
          "total_latency_ms": 12102.868795394897
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-6",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user ask about the location of LoadBalancer9 before or after the discussion about the 'happy Tuesday' log discrepancies?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex inquired about LoadBalancer9",
            "Alex checked status of LoadBalancer9",
            "Alex requested latency check for LoadBalancer9"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4842.140674591064,
          "generation_latency_ms": 5175.85563659668,
          "scoring_latency_ms": 2869.983434677124,
          "total_latency_ms": 12887.979745864868
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "How does the user characterize their stance on running the split version setup on the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "Risky but necessary",
          "predicted_answer": "risky but necessary",
          "retrieved_context": [
            "Second analytics engine running version Version v1.2.0",
            "Second analytics engine running version Version v2.0.0-beta",
            "AnalyticsEngine2 running version version v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5325.7129192352295,
          "generation_latency_ms": 4851.200103759766,
          "scoring_latency_ms": 2969.9907302856445,
          "total_latency_ms": 13146.90375328064
        },
        {
          "probe_id": "preference_learning-explicit_preferences-8",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Which cloud provider has the user explicitly designated as their preferred choice for all future services?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Azure owned by Microsoft",
            "auth service 6 hosted on Azure",
            "AuthService6 hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4077.845335006714,
          "generation_latency_ms": 2963.214874267578,
          "scoring_latency_ms": 3076.197385787964,
          "total_latency_ms": 10117.257595062256
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What software version is the system 'LoadBalancer9' currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "02a6ff07-f700-49a8-bb4b-f95a054065d1 located in AWS environment",
            "58985c8e-bb7b-4ec2-981f-e433e85f1a8c hosted on AWS",
            "3d0cc900-a9b5-4b5e-9f39-91966b87e5bc hosted on AWS"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6567.312479019165,
          "generation_latency_ms": 4286.669969558716,
          "scoring_latency_ms": 2759.3624591827393,
          "total_latency_ms": 13613.34490776062
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the pet owned by the DevOps Lead?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Charlotte holds role DevOps lead",
            "Luna alias of Frontend Lead",
            "Luna often mentioned by Frontend Lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4359.167575836182,
          "generation_latency_ms": 4223.865509033203,
          "scoring_latency_ms": 2949.4616985321045,
          "total_latency_ms": 11532.49478340149
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-11",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "Who does the user intend to contact to resolve the race condition on the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Elijah",
          "retrieved_context": [
            "Elijah suspects desync of backend AnalyticsEngine2",
            "Alex monitoring AnalyticsEngine2",
            "Elijah responsible for updating Second analytics engine"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4947.001695632935,
          "generation_latency_ms": 4958.651304244995,
          "scoring_latency_ms": 3014.81032371521,
          "total_latency_ms": 12920.46332359314
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-12",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What method does the assistant use to verify the current status and version of the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "Checking telemetry",
          "predicted_answer": "Telemetry",
          "retrieved_context": [
            "7d0be071-a03e-49fb-a299-af7c4c2b92de active on AnalyticsEngine2",
            "AnalyticsEngine2 running version version v1.2.0",
            "AnalyticsEngine2 running version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5378.224849700928,
          "generation_latency_ms": 8602.944135665894,
          "scoring_latency_ms": 2746.680498123169,
          "total_latency_ms": 16727.84948348999
        }
      ],
      "summary": {
        "overall_accuracy": 0.75,
        "total_score": 9,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 9,
            "accuracy": 0.6666666666666666
          },
          "abstain": {
            "total": 3,
            "count": 3,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_042.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 27,
      "num_probes": 9,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 135.8281171321869,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual referred to as the 'cofounder' that was reviewing the billing dashboard?",
          "answer_type": "short_answer",
          "gold_answer": "Will",
          "predicted_answer": "Will",
          "retrieved_context": [
            "cofounder holds role CEO",
            "cofounder strict about costs of Azure",
            "cofounder identity of Will"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 26594.367742538452,
          "generation_latency_ms": 3017.873764038086,
          "scoring_latency_ms": 2736.2537384033203,
          "total_latency_ms": 32348.49524497986
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the name of the pet belonging to the person who leads the sales department?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "Emma leads sales department",
            "Emma runs sales team",
            "Emma is Sales Lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 3919.893980026245,
          "generation_latency_ms": 4985.170602798462,
          "scoring_latency_ms": 2814.9783611297607,
          "total_latency_ms": 11720.042943954468
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the core data storage system managed by the Backend Lead hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "CacheLayer4 suggested hosting on GCP",
            "CacheLayer4 partially hosted on AWS",
            "fbbd3b7e-1ed3-48ab-af5b-0d9a131e86ea hosted on Microsoft Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4026.524543762207,
          "generation_latency_ms": 4167.256832122803,
          "scoring_latency_ms": 2859.6935272216797,
          "total_latency_ms": 11053.47490310669
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Despite the logs suggesting a beta version, what version number does the user assert is the stable release for the primary database?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0",
          "predicted_answer": "v1.2.0",
          "retrieved_context": [
            "version v2.0.0-beta running on PrimaryDB2",
            "uptime logs suggests version is v2.0.0-beta",
            "PrimaryDB2 reported as version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5177.345275878906,
          "generation_latency_ms": 5090.532302856445,
          "scoring_latency_ms": 2814.8508071899414,
          "total_latency_ms": 13082.728385925293
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-4",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "What personal task did the user request a reminder for immediately before asking about the Sales Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Call mom",
          "predicted_answer": "dry cleaning",
          "retrieved_context": [
            "user has call with Sales Lead",
            "user needs reminder for reminder to ask Emma about lunch",
            "user needs reminder for reminder to ask Emma about lunch"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4941.993236541748,
          "generation_latency_ms": 5134.058952331543,
          "scoring_latency_ms": 2849.074363708496,
          "total_latency_ms": 12925.126552581787
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-5",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why did the user suggest the Azure portal might be lagging during the conversation about infrastructure confusion?",
          "answer_type": "short_answer",
          "gold_answer": "Conflicting version info",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Oliver thinks caused by cross cloud issue latency on the cache layer",
            "user reviewing Nebula Corp infrastructure map",
            "user reviewing Nebula Corp infrastructure map"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6008.300542831421,
          "generation_latency_ms": 5140.684127807617,
          "scoring_latency_ms": 2952.4264335632324,
          "total_latency_ms": 14101.41110420227
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on previous interactions, how does the user view the presence of Emma's pet during video calls?",
          "answer_type": "short_answer",
          "gold_answer": "Hilarious",
          "predicted_answer": "Distracting",
          "retrieved_context": [
            "e0c225c1-1d1a-4114-b446-3d151b475385 may bring pet to office",
            "user wants to ask about cat Emma",
            "b41f7c66-3023-46dc-892c-20ee91d0d7a4 showed pet pictures during morning of January 7, 2026"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5485.355615615845,
          "generation_latency_ms": 5086.007833480835,
          "scoring_latency_ms": 2957.3709964752197,
          "total_latency_ms": 13528.7344455719
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-7",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific software version is the LoadBalancer8 currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "80cf5868-2c89-4c76-8084-01628b2a831c located in Azure",
            "3e25a778-6a4f-41f2-80e5-e2e42303049d reported healthy status",
            "PrimaryDB2 active version is v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4361.761808395386,
          "generation_latency_ms": 4234.064340591431,
          "scoring_latency_ms": 3164.623975753784,
          "total_latency_ms": 11760.4501247406
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-8",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What protocol did the assistant agree to follow regarding the conflicting database versions in the production environment?",
          "answer_type": "generation",
          "gold_answer": "Treat v1.2.0 as active",
          "predicted_answer": "Treat v1.2.0 as the active version for the production environment while keeping the beta flags in mind.",
          "retrieved_context": [
            "b19bdc8f-054c-45b3-a899-09d34da91af9 has conflicting version reports with v2.0 beta",
            "6963d5ed-7f64-4126-8821-b1b2c54e45c5 inquiring about database version conflict",
            "Oliver concerned about version mismatch in PrimaryDB2"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 7646.39687538147,
          "generation_latency_ms": 4926.788806915283,
          "scoring_latency_ms": 2691.676616668701,
          "total_latency_ms": 15264.862298965454
        }
      ],
      "summary": {
        "overall_accuracy": 0.5555555555555556,
        "total_score": 5,
        "count": 9,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 7,
            "accuracy": 0.5714285714285714
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "generation": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_043.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 26,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 153.14634466171265,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "What is the organizational role of the person who owns a cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales",
          "retrieved_context": [
            "Liam owns pet Luna",
            "Liam owner of Luna",
            "Liam owns Luna"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4514.469385147095,
          "generation_latency_ms": 3056.1466217041016,
          "scoring_latency_ms": 2908.0474376678467,
          "total_latency_ms": 10478.663444519043
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which other service is hosted on the same cloud provider as AuthService6?",
          "answer_type": "short_answer",
          "gold_answer": "CacheLayer4",
          "predicted_answer": "CacheLayer4",
          "retrieved_context": [
            "auth service hosted on Google Cloud Platform",
            "auth service alias of AuthService6",
            "AnalyticsEngine5 potentially causing latency due to different hosting AuthService6"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5894.752025604248,
          "generation_latency_ms": 3014.0037536621094,
          "scoring_latency_ms": 2724.91717338562,
          "total_latency_ms": 11633.672952651978
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service that is currently exhibiting version mismatches hosted?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "GCP",
          "retrieved_context": [
            "auth service hosted on Google Cloud Platform",
            "CacheLayer1 hosted on Amazon Web Services",
            "first cache layer hosted on AWS"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6263.939142227173,
          "generation_latency_ms": 2761.4526748657227,
          "scoring_latency_ms": 2842.7140712738037,
          "total_latency_ms": 11868.1058883667
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "According to the logs, which two versions are simultaneously reported for the fourth cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "conflicting logs related to CacheLayer4",
            "fourth cache layer version reported as v1.2.0",
            "code version v1.2.0 reported running on fourth cache layer"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4626.9371509552,
          "generation_latency_ms": 4868.591785430908,
          "scoring_latency_ms": 2745.8412647247314,
          "total_latency_ms": 12241.37020111084
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-4",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What weather condition did the user mention while discussing the ambiguous metrics of the fourth cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "Rain",
          "predicted_answer": "Rain",
          "retrieved_context": [
            "Alex checking status of fourth cache layer",
            "Alex requested information about CacheLayer4",
            "fourth cache layer part of infrastructure headaches"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8867.56443977356,
          "generation_latency_ms": 4846.118211746216,
          "scoring_latency_ms": 2725.3451347351074,
          "total_latency_ms": 16439.027786254883
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-5",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why did the user specifically request a breakdown of infrastructure by provider before 10 AM?",
          "answer_type": "short_answer",
          "gold_answer": "Meeting with Lucas",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Lucas inquired about cloud spend distribution",
            "43034173-42f9-4fd8-98cb-cd6a39b48299 discussion topic for standup meeting with Lucas",
            "Alex preparing infrastructure costs update"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5720.688819885254,
          "generation_latency_ms": 4899.342775344849,
          "scoring_latency_ms": 2904.310703277588,
          "total_latency_ms": 13524.34229850769
        },
        {
          "probe_id": "preference_learning-explicit_preferences-6",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "When mapping out infrastructure for the cloud spend discussion, did the user prefer a breakdown by service usage or by provider?",
          "answer_type": "short_answer",
          "gold_answer": "By provider",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex viewing GCP infrastructure dashboard",
            "Alex preparing infrastructure costs update",
            "AnalyticsEngine5 hosted on AWS"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5476.96590423584,
          "generation_latency_ms": 2961.2817764282227,
          "scoring_latency_ms": 2961.8523120880127,
          "total_latency_ms": 11400.099992752075
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's morning routine, what specific type of coffee do they appear to favor?",
          "answer_type": "short_answer",
          "gold_answer": "Double espresso",
          "predicted_answer": "Double espresso",
          "retrieved_context": [
            "Alex grabbed double espresso",
            "Alex added to shopping list coffee beans",
            "3b1d52a5-986f-4785-9811-43ab0ca2566a set reminder for Reminder to pick up milk"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5148.356676101685,
          "generation_latency_ms": 3710.131883621216,
          "scoring_latency_ms": 2796.1504459381104,
          "total_latency_ms": 11654.63900566101
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What version of software is currently running on AnalyticsEngine5?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "data science team uses AnalyticsEngine5",
            "AnalyticsEngine5 hosted on AWS",
            "Noah inquired about AnalyticsEngine5"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5331.6473960876465,
          "generation_latency_ms": 4822.286605834961,
          "scoring_latency_ms": 2680.9186935424805,
          "total_latency_ms": 12834.852695465088
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who holds the role of Frontend Lead in the organization?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Will shares role with backend lead role",
            "Sophia designated as backend lead backend team",
            "Backend Lead signs off on backend changes for migration"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5467.069387435913,
          "generation_latency_ms": 4442.342042922974,
          "scoring_latency_ms": 2934.44561958313,
          "total_latency_ms": 12843.857049942017
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What technical metric was the team testing by splitting the cache layers across different providers?",
          "answer_type": "short_answer",
          "gold_answer": "Latency",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "GCP metrics monitoring fourth cache layer",
            "fourth cache layer part of infrastructure headaches",
            "fourth cache layer hosted on GCP"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8929.423570632935,
          "generation_latency_ms": 5101.3593673706055,
          "scoring_latency_ms": 2672.7206707000732,
          "total_latency_ms": 16703.503608703613
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-11",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What future task did the assistant schedule regarding the user's mother?",
          "answer_type": "short_answer",
          "gold_answer": "Call in one hour",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "assistant offers to add coffee break reminder",
            "assistant offers to add coffee break reminder",
            "Luna subject of vet appointment for Luna"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4673.512935638428,
          "generation_latency_ms": 4056.3650131225586,
          "scoring_latency_ms": 2707.8492641448975,
          "total_latency_ms": 11437.727212905884
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 12,
            "accuracy": 0.5
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_044.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 31,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 155.99928784370422,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which individual is the user referring to when mentioning their 'cofounder' who is worried about login stability?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "cofounder requesting user stats for the sales team",
            "James alias of cofounder",
            "cofounder should use analytics engine"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7308.413743972778,
          "generation_latency_ms": 4013.3888721466064,
          "scoring_latency_ms": 2906.841516494751,
          "total_latency_ms": 14228.644132614136
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the name of the pet belonging to the person who holds the Frontend Lead role?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "Luna talked about by Frontend Lead",
            "Emma leads frontend team",
            "Backend Lead responsible for backend sync"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5729.778528213501,
          "generation_latency_ms": 2675.2140522003174,
          "scoring_latency_ms": 2935.3158473968506,
          "total_latency_ms": 11340.308427810669
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service that is currently running a beta version hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "analytics engine hosted on Amazon Web Services",
            "LoadBalancer7 hosted on Google Cloud Platform",
            "AnalyticsEngine6 running on AWS"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5756.133317947388,
          "generation_latency_ms": 4357.169151306152,
          "scoring_latency_ms": 2882.221221923828,
          "total_latency_ms": 12995.523691177368
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-1",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "Which specific service did the user identify as causing infrastructure fragmentation due to its hosting location on Google Cloud?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer2",
          "predicted_answer": "LoadBalancer2",
          "retrieved_context": [
            "a50f7d57-d126-4464-89af-5741e95e97d1 wants to consolidate multicloud environment",
            "LoadBalancer7 hosted on Google Cloud Platform",
            "a50f7d57-d126-4464-89af-5741e95e97d1 wants to consolidate multicloud environment"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4415.867328643799,
          "generation_latency_ms": 4986.667633056641,
          "scoring_latency_ms": 2846.568822860718,
          "total_latency_ms": 12249.103784561157
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-0",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific event caused the Frontend Lead to get distracted while debugging the login UI?",
          "answer_type": "short_answer",
          "gold_answer": "Luna jumped on keyboard",
          "predicted_answer": "Luna jumped on her keyboard during the Zoom call",
          "retrieved_context": [
            "Luna talked about by Frontend Lead",
            "Sophia asked to check backend logs",
            "Emma leads frontend team"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7404.53314781189,
          "generation_latency_ms": 5340.63982963562,
          "scoring_latency_ms": 2779.346466064453,
          "total_latency_ms": 15524.519443511963
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user ask to check the Azure deployment slots before or after inquiring about the status of the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex checking status of analytics engine",
            "Alex asked to check LoadBalancer2",
            "Sophia asked to check backend logs"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6491.685152053833,
          "generation_latency_ms": 5164.979457855225,
          "scoring_latency_ms": 2919.8102951049805,
          "total_latency_ms": 14576.474905014038
        },
        {
          "probe_id": "preference_learning-explicit_preferences-0",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What specific beverage did the user state they required before the standup meeting?",
          "answer_type": "short_answer",
          "gold_answer": "Double espresso",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "user grabbed coffee",
            "user grabbed coffee",
            "Alex preparing for standup meeting"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5699.057340621948,
          "generation_latency_ms": 3013.483762741089,
          "scoring_latency_ms": 3124.6964931488037,
          "total_latency_ms": 11837.23759651184
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's complaints about fragmentation, which cloud provider is implied to be the non-preferred or 'odd' location for the load balancer?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "LoadBalancer7 hosted on Google Cloud Platform",
            "LoadBalancer7 located near CacheLayer5",
            "CacheLayer5 linked to LoadBalancer7"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4514.895439147949,
          "generation_latency_ms": 5069.238901138306,
          "scoring_latency_ms": 2789.330244064331,
          "total_latency_ms": 12373.464584350586
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What software version is the Analytics Engine currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex checking status of analytics engine",
            "AnalyticsEngine6 running on AWS",
            "9d1ae7ad-cc33-4114-9043-19aa8750a2d0 running on AWS"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4968.611478805542,
          "generation_latency_ms": 4740.279674530029,
          "scoring_latency_ms": 2966.28999710083,
          "total_latency_ms": 12675.181150436401
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the tools used by the Sales Lead?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "AWS",
          "retrieved_context": [
            "analytics engine hosted on Amazon Web Services",
            "LoadBalancer7 hosted on Google Cloud Platform",
            "AnalyticsEngine6 running on AWS"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4220.158338546753,
          "generation_latency_ms": 4889.767408370972,
          "scoring_latency_ms": 2911.80682182312,
          "total_latency_ms": 12021.732568740845
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "Which monitoring service does the assistant use to check the status of the AWS-hosted analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "CloudWatch",
          "predicted_answer": "AWS dashboard",
          "retrieved_context": [
            "analytics engine monitored via AWS dashboard",
            "analytics engine hosted on Amazon Web Services",
            "AnalyticsEngine6 running on AWS"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6702.330589294434,
          "generation_latency_ms": 3799.9682426452637,
          "scoring_latency_ms": 2793.076992034912,
          "total_latency_ms": 13295.37582397461
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What does the assistant identify as a 'classic hazard' for the Frontend Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Her cat",
          "predicted_answer": "Her cat blocking the screen.",
          "retrieved_context": [
            "Luna talked about by Frontend Lead",
            "Emma leads frontend team",
            "Charlotte holds role Sales Lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4578.737735748291,
          "generation_latency_ms": 5124.218225479126,
          "scoring_latency_ms": 3144.7653770446777,
          "total_latency_ms": 12847.721338272095
        }
      ],
      "summary": {
        "overall_accuracy": 0.5833333333333334,
        "total_score": 7,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 10,
            "accuracy": 0.6
          },
          "abstain": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_045.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 31,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 125.05501866340637,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which team member is referred to as the 'DevOps specialist' responsible for patching the database?",
          "answer_type": "short_answer",
          "gold_answer": "Will",
          "predicted_answer": "Will",
          "retrieved_context": [
            "Will responsible for patching PrimaryDB9",
            "3ced23ce-16ba-45b1-a2c2-c8b2a57ce743 contacted about Will",
            "Will responsible for checking PrimaryDB9"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4460.816860198975,
          "generation_latency_ms": 4597.9461669921875,
          "scoring_latency_ms": 2874.34720993042,
          "total_latency_ms": 11933.110237121582
        },
        {
          "probe_id": "world_modeling-relationship_mapping-0",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "On which cloud provider is the service hosted that the CEO is specifically concerned about regarding budget fragmentation?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "AWS",
          "retrieved_context": [
            "Will tasked with auditing multi-cloud redundancy issue",
            "2232d39d-dc1f-4731-84c0-05492d1f883d involves CacheLayer5",
            "CacheLayer5 documented as hosted on GCP"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4028.0585289001465,
          "generation_latency_ms": 5608.766555786133,
          "scoring_latency_ms": 2773.181676864624,
          "total_latency_ms": 12410.006761550903
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person who owns a cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales Lead",
          "retrieved_context": [
            "8ee65ff1-dc09-4921-baa4-9d0e1c461203 owned by Sales Lead",
            "Ava owner of Luna",
            "Sales Lead may have information about Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4992.384910583496,
          "generation_latency_ms": 4621.574878692627,
          "scoring_latency_ms": 2813.433885574341,
          "total_latency_ms": 12427.393674850464
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-0",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "The analytics engine is causing latency because it is hosted on a different provider than the primary database. Where is the primary database hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "192d3c51-9527-401d-8d4c-b2826407ad36 hosted on AWS",
            "167d426b-e96f-4991-b570-adaaa002377f hosted on AWS",
            "analytics engine hosted on AWS"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6925.687074661255,
          "generation_latency_ms": 4331.354856491089,
          "scoring_latency_ms": 2775.3512859344482,
          "total_latency_ms": 14032.393217086792
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-0",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "During the conversation where the user decided to hold off on emailing James, what personal reminder was set?",
          "answer_type": "short_answer",
          "gold_answer": "Dentist appointment",
          "predicted_answer": "Call mom at 6 PM",
          "retrieved_context": [
            "Alex set reminder for 5 PM on January 7, 2026",
            "user reminded to pick up 5 PM",
            "user plans to clarify with James"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4455.306053161621,
          "generation_latency_ms": 2843.5370922088623,
          "scoring_latency_ms": 2821.002960205078,
          "total_latency_ms": 10119.846105575562
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-0",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why did the DevOps specialist describe his work as a 'nightmare' in recent discussions?",
          "answer_type": "short_answer",
          "gold_answer": "Latency",
          "predicted_answer": "Latency",
          "retrieved_context": [
            "DevOps guy contacted about Will",
            "Will performs DevOps work",
            "b97ca50e-1a83-4f59-ad13-2a19598713ab tweaking configuration on Azure instance"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6615.813970565796,
          "generation_latency_ms": 3506.192445755005,
          "scoring_latency_ms": 2797.2497940063477,
          "total_latency_ms": 12919.256210327148
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's morning routine comments, what specific beverage do they require to function?",
          "answer_type": "short_answer",
          "gold_answer": "Espresso",
          "predicted_answer": "Double shot of espresso",
          "retrieved_context": [
            "user needs to function with double shot of espresso",
            "0ceee501-3ec2-438f-a6a1-eb09bd14eaf5 part of shopping list",
            "Alex added task buy espresso beans"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5287.798643112183,
          "generation_latency_ms": 2828.9992809295654,
          "scoring_latency_ms": 2734.708786010742,
          "total_latency_ms": 10851.50671005249
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the service managed by the Frontend Lead?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "196292f4-da0e-48a9-849c-49b5b1815d60 assists with UI updates",
            "Emma holds role Frontend Lead",
            "primary database hosted on Microsoft's cloud"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4211.718320846558,
          "generation_latency_ms": 2924.359083175659,
          "scoring_latency_ms": 3266.0882472991943,
          "total_latency_ms": 10402.165651321411
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "Is the PrimaryDB9 system currently running exclusively on version v2.0.0-beta?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "PrimaryDB9 has version v2.0.0-beta",
            "v2.0.0 beta alias of PrimaryDB9",
            "PrimaryDB9 v1.2.0 version mismatch with PrimaryDB9 v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7574.1376876831055,
          "generation_latency_ms": 5361.056804656982,
          "scoring_latency_ms": 3532.752275466919,
          "total_latency_ms": 16467.946767807007
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "How does the assistant determine the version status of the PrimaryDB9 when asked?",
          "answer_type": "short_answer",
          "gold_answer": "Checks headers",
          "predicted_answer": "Logs",
          "retrieved_context": [
            "Will inquiring about PrimaryDB9",
            "user monitoring status of PrimaryDB9",
            "version mismatch on primary database concerns PrimaryDB9"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5744.266033172607,
          "generation_latency_ms": 4832.087755203247,
          "scoring_latency_ms": 2885.8749866485596,
          "total_latency_ms": 13462.228775024414
        }
      ],
      "summary": {
        "overall_accuracy": 0.8,
        "total_score": 8,
        "count": 10,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 8,
            "accuracy": 0.75
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "boolean": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_046.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 145.56045603752136,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the cofounder the user plans to have lunch with?",
          "answer_type": "short_answer",
          "gold_answer": "Oliver",
          "predicted_answer": "Oliver",
          "retrieved_context": [
            "sync meeting with cofounder with Oliver",
            "Alex has planned Lunch with Oliver",
            "sync meeting with cofounder discusses quarterly burn rate"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5459.075450897217,
          "generation_latency_ms": 3386.0507011413574,
          "scoring_latency_ms": 2783.820629119873,
          "total_latency_ms": 11628.946781158447
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which infrastructure provider hosts the database that Sophia is concerned about regarding latency?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google Cloud Platform",
          "retrieved_context": [
            "Sophia concerned about latency to PrimaryDB9",
            "Sophia investigating latency between clouds",
            "Olivia investigating latency between clouds"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5853.127956390381,
          "generation_latency_ms": 3750.8387565612793,
          "scoring_latency_ms": 2871.8414306640625,
          "total_latency_ms": 12475.808143615723
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which two specific version numbers are simultaneously active on the authentication service hosted on AWS?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "seventh auth service instance hosted on Amazon Web Services",
            "AuthService7 running on Amazon AWS infrastructure",
            "AuthService7 hosted on Amazon Web Services"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5205.211877822876,
          "generation_latency_ms": 4774.688959121704,
          "scoring_latency_ms": 2842.717409133911,
          "total_latency_ms": 12822.618246078491
        },
        {
          "probe_id": "declarative_reasoning-baseline_factual_recall-4",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What is the name of the pet belonging to the Backend Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "Sophia holds role backend lead",
            "Olivia holds role backend lead",
            "Olivia member of backend leads"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6237.903356552124,
          "generation_latency_ms": 2738.6269569396973,
          "scoring_latency_ms": 2733.5739135742188,
          "total_latency_ms": 11710.10422706604
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user ask to set a reminder for their mom's birthday before or after the reminder for dry cleaning?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "dry cleaning pickup reminder scheduled for 5 PM",
            "dry cleaning pickup reminder scheduled for one hour after 5 PM on January 7, 2026",
            "user requested coffee reminder in ten minutes"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5624.050617218018,
          "generation_latency_ms": 3311.955690383911,
          "scoring_latency_ms": 2886.59405708313,
          "total_latency_ms": 11822.600364685059
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-6",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What specific complaint did the user make about the coffee in session 23?",
          "answer_type": "short_answer",
          "gold_answer": "Tastes like battery acid",
          "predicted_answer": "Terrible as usual.",
          "retrieved_context": [
            "coffee belongs to user",
            "user requested coffee reminder in ten minutes",
            "user requested coffee reminder in ten minutes"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5803.968906402588,
          "generation_latency_ms": 2807.803153991699,
          "scoring_latency_ms": 2851.337194442749,
          "total_latency_ms": 11463.109254837036
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the morning sessions, what beverage does the user consistently require before working?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "coffee belongs to user",
            "user requested coffee reminder in ten minutes",
            "user requested coffee reminder in ten minutes"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6052.024126052856,
          "generation_latency_ms": 4071.342945098877,
          "scoring_latency_ms": 2739.598512649536,
          "total_latency_ms": 12862.96558380127
        },
        {
          "probe_id": "preference_learning-explicit_preferences-8",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "At what time did the user specifically request to be reminded to call their mom?",
          "answer_type": "short_answer",
          "gold_answer": "6 PM",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user requested coffee reminder in ten minutes",
            "user requested coffee reminder in ten minutes",
            "dentist call reminder scheduled for 2 PM"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4793.872594833374,
          "generation_latency_ms": 4374.3109703063965,
          "scoring_latency_ms": 2985.589027404785,
          "total_latency_ms": 12153.772592544556
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific version number is running on the LoadBalancer4 service?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "LoadBalancer4 running on Azure environment",
            "LoadBalancer4 hosted on Microsoft Azure",
            "AuthService2 running alongside LoadBalancer4"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5903.741836547852,
          "generation_latency_ms": 4271.183252334595,
          "scoring_latency_ms": 2714.4675254821777,
          "total_latency_ms": 12889.392614364624
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who is the specific team lead for the DevOps engineers Emma and Mia?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Emma member of DevOps engineers",
            "Emma member of DevOps team",
            "Mia member of DevOps engineers"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5235.386848449707,
          "generation_latency_ms": 4594.824552536011,
          "scoring_latency_ms": 2635.334014892578,
          "total_latency_ms": 12465.545415878296
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-11",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "When the user references the 'Microsoft cloud', which specific load balancer identifier is relevant?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer4",
          "predicted_answer": "LoadBalancer4",
          "retrieved_context": [
            "LoadBalancer4 hosted on Microsoft Azure",
            "LoadBalancer4 running on Azure environment",
            "AuthService2 located in same region as LoadBalancer4"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4871.90842628479,
          "generation_latency_ms": 3531.529664993286,
          "scoring_latency_ms": 2740.3407096862793,
          "total_latency_ms": 11143.778800964355
        },
        {
          "probe_id": "procedural_knowledge-task_state_tracking-12",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "How did the user categorize the state of the deployment on the AWS auth service in the final session?",
          "answer_type": "short_answer",
          "gold_answer": "Stuck deployment",
          "predicted_answer": "stuck deployment",
          "retrieved_context": [
            "AuthService7 deployed on AWS",
            "seventh auth service instance hosted on Amazon Web Services",
            "DevOps team manages deployment of AuthService7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6200.320720672607,
          "generation_latency_ms": 2929.8110008239746,
          "scoring_latency_ms": 2843.0190086364746,
          "total_latency_ms": 11973.150730133057
        }
      ],
      "summary": {
        "overall_accuracy": 0.75,
        "total_score": 9,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 7,
            "count": 10,
            "accuracy": 0.7
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_047.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 30,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 165.67154145240784,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which individual is the user referring to when mentioning the 'cofounder' who texted late at night about bills?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Elijah",
          "retrieved_context": [
            "cofounder attended strategy session",
            "cofounder made call quarterly projections call",
            "Alex attending tech stack budget meeting"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8593.315601348877,
          "generation_latency_ms": 5255.430698394775,
          "scoring_latency_ms": 3167.490243911743,
          "total_latency_ms": 17016.236543655396
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which specific infrastructure services are currently hosted on the Amazon platform?",
          "answer_type": "short_answer",
          "gold_answer": "PrimaryDB4 and CacheLayer7",
          "predicted_answer": "PrimaryDB4, CacheLayer7",
          "retrieved_context": [
            "PrimaryDB4 hosted on AWS infrastructure",
            "multi-cloud strategy includes AWS infrastructure",
            "9485a527-75ad-4492-9cd5-cdb2d865b615 includes cost item Amazon bill"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4496.618270874023,
          "generation_latency_ms": 4121.155261993408,
          "scoring_latency_ms": 2975.0609397888184,
          "total_latency_ms": 11592.83447265625
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Product Designer",
          "predicted_answer": "Product Designer",
          "retrieved_context": [
            "Luna owned by Noah",
            "Noah owns Luna",
            "Noah has pet Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4485.893726348877,
          "generation_latency_ms": 3559.0195655822754,
          "scoring_latency_ms": 2964.3044471740723,
          "total_latency_ms": 11009.217739105225
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-4",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Despite the dashboard displaying v1.2.0, what version do the logs suggest PrimaryDB4 is actually running?",
          "answer_type": "short_answer",
          "gold_answer": "v2.0.0-beta",
          "predicted_answer": "v2.0.0-beta",
          "retrieved_context": [
            "PrimaryDB4 logs show version v1.2.0",
            "PrimaryDB4 logs show version v2 beta",
            "PrimaryDB4 running version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5350.183010101318,
          "generation_latency_ms": 5121.556758880615,
          "scoring_latency_ms": 3277.3969173431396,
          "total_latency_ms": 13749.136686325073
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user complain about the two-hour 'quick sync' before or after asking to clear their schedule to review hosting costs?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex preparing for executive sync",
            "4503290b-d257-47f0-899a-1e9963d7c568 focused on AWS expenses",
            "813ae35c-ab40-466e-83f3-b55852b07aee left item in conference room"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6440.868854522705,
          "generation_latency_ms": 4706.91990852356,
          "scoring_latency_ms": 2933.5739612579346,
          "total_latency_ms": 14081.3627243042
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-6",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why is the CEO specifically concerned about the cost of the authentication service compared to the rest of the stack?",
          "answer_type": "short_answer",
          "gold_answer": "It is isolated on Azure",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "multi-cloud strategy includes service AuthService5",
            "multi-cloud strategy includes hosting of AuthService5",
            "4503290b-d257-47f0-899a-1e9963d7c568 focused on AWS expenses"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5936.958312988281,
          "generation_latency_ms": 5518.268823623657,
          "scoring_latency_ms": 3014.1525268554688,
          "total_latency_ms": 14469.379663467407
        },
        {
          "probe_id": "preference_learning-explicit_preferences-7",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "How does the user's cofounder feel about ambiguity in status reports?",
          "answer_type": "short_answer",
          "gold_answer": "He hates it",
          "predicted_answer": "Critically concerned",
          "retrieved_context": [
            "user has upcoming meeting with cofounder in ten minutes",
            "user has upcoming meeting with cofounder in ten minutes",
            "cofounder made call quarterly projections call"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5238.130807876587,
          "generation_latency_ms": 4939.069747924805,
          "scoring_latency_ms": 3131.270170211792,
          "total_latency_ms": 13308.470726013184
        },
        {
          "probe_id": "preference_learning-preference_scope-8",
          "pillar": "preference_learning",
          "subpillar": "preference_scope",
          "question": "Does the CEO's concern about overpaying apply to the AWS services or the Azure service?",
          "answer_type": "short_answer",
          "gold_answer": "Azure service",
          "predicted_answer": "AWS services",
          "retrieved_context": [
            "tech stack budget meeting focused on AWS expenses",
            "68893fc6-286d-48bb-9816-88b9be59c466 billed for AWS",
            "multi-cloud strategy includes service AuthService5"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5477.55765914917,
          "generation_latency_ms": 5393.014669418335,
          "scoring_latency_ms": 3119.0383434295654,
          "total_latency_ms": 13989.61067199707
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of Oliver's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Oliver does not have pet",
            "user plans to ping Oliver",
            "user plans to ping Oliver"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4807.486057281494,
          "generation_latency_ms": 3923.5198497772217,
          "scoring_latency_ms": 3213.6309146881104,
          "total_latency_ms": 11944.636821746826
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "Does the assistant have visual confirmation of how big Noah's cat has grown?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Noah has pet Luna",
            "Noah shares pictures in channel",
            "Noah expert on collar for Luna"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 8702.1644115448,
          "generation_latency_ms": 5182.529449462891,
          "scoring_latency_ms": 3037.6126766204834,
          "total_latency_ms": 16922.306537628174
        },
        {
          "probe_id": "procedural_knowledge-task_state_tracking-11",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "Who is currently responsible for handling the backend logic of the infrastructure migration?",
          "answer_type": "short_answer",
          "gold_answer": "Sophia",
          "predicted_answer": "Sophia",
          "retrieved_context": [
            "Sophia responsible for migration path of PrimaryDB4",
            "backend team responsible for PrimaryDB4",
            "backend team responsible for CacheLayer7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7184.262752532959,
          "generation_latency_ms": 3879.1463375091553,
          "scoring_latency_ms": 2866.7588233947754,
          "total_latency_ms": 13930.16791343689
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-12",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "Based on the user's interactions, what specific database issue creates a risk of confusing the CEO?",
          "answer_type": "short_answer",
          "gold_answer": "Version ambiguity",
          "predicted_answer": "Database version conflict",
          "retrieved_context": [
            "dashboard loading times issue suspected cause PrimaryDB4",
            "Sophia concerned about PrimaryDB4",
            "primary database versioning check needs to perform user"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 7042.162179946899,
          "generation_latency_ms": 3271.3398933410645,
          "scoring_latency_ms": 3313.6653900146484,
          "total_latency_ms": 13627.167463302612
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 10,
            "accuracy": 0.5
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_048.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 28,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 171.8122022151947,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user referring to when they mention their 'cofounder' who is stressing about platform stability?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "Liam",
          "retrieved_context": [
            "cofounder meeting with user",
            "Alex has cofounder cofounder",
            "cofounder requested status report from Alex"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6384.371280670166,
          "generation_latency_ms": 4937.6540184021,
          "scoring_latency_ms": 3181.363582611084,
          "total_latency_ms": 14503.38888168335
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which employee is the owner of the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Emma",
          "predicted_answer": "Emma",
          "retrieved_context": [
            "Luna belongs to Emma",
            "Luna wears Luna's collar",
            "Luna has vet appointment"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5513.733386993408,
          "generation_latency_ms": 3038.174867630005,
          "scoring_latency_ms": 2794.179677963257,
          "total_latency_ms": 11346.08793258667
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service running the 'v2.0.0-beta' hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "v2.0.0-beta hosted in Azure environment",
            "Second auth service running version version 2.0.0-beta",
            "Second auth service hosted on Microsoft Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5845.785617828369,
          "generation_latency_ms": 4803.633689880371,
          "scoring_latency_ms": 2824.629068374634,
          "total_latency_ms": 13474.048376083374
        },
        {
          "probe_id": "declarative_reasoning-baseline_factual_recall-4",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "Which two individuals currently hold the role of Backend Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Oliver and Charlotte",
          "predicted_answer": "Oliver and Charlotte",
          "retrieved_context": [
            "Oliver holds role Backend Lead",
            "Oliver member of Backend Leads",
            "Oliver co-leading backend Charlotte"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5746.7286586761475,
          "generation_latency_ms": 4221.5416431427,
          "scoring_latency_ms": 3239.767074584961,
          "total_latency_ms": 13208.037376403809
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What personal task did the user ask to be reminded of during the conversation about Oliver and Charlotte's argument?",
          "answer_type": "short_answer",
          "gold_answer": "Pick up dry cleaning",
          "predicted_answer": "pick up my dry cleaning",
          "retrieved_context": [
            "Oliver collaborating with Charlotte",
            "Alex plans to contact Oliver",
            "Alex plans to contact Charlotte"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6320.701837539673,
          "generation_latency_ms": 4958.04238319397,
          "scoring_latency_ms": 2805.2918910980225,
          "total_latency_ms": 14084.036111831665
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-6",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "According to the session history, why did the user describe the game match as 'intense'?",
          "answer_type": "short_answer",
          "gold_answer": "It went into overtime",
          "predicted_answer": "It went into overtime.",
          "retrieved_context": [
            "Mia complained about latency due to PrimaryDB3",
            "cofounder meeting with user",
            "Oliver stressed about main database latency"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 9748.219013214111,
          "generation_latency_ms": 3766.2956714630127,
          "scoring_latency_ms": 2813.7354850769043,
          "total_latency_ms": 16328.250169754028
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What is the CEO's primary motivation for pushing infrastructure consolidation?",
          "answer_type": "short_answer",
          "gold_answer": "Bottom line",
          "predicted_answer": "Addressing the complexities inherent in multi-cloud environments",
          "retrieved_context": [
            "c16a5c7b-fafd-418f-9156-48b90a065fe5 status report requested by cofounder",
            "Liam pressuring about Multi-cloud mess",
            "Alex discussing infrastructure audit"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 6470.242500305176,
          "generation_latency_ms": 5364.485740661621,
          "scoring_latency_ms": 2787.0209217071533,
          "total_latency_ms": 14621.74916267395
        },
        {
          "probe_id": "preference_learning-preference_scope-8",
          "pillar": "preference_learning",
          "subpillar": "preference_scope",
          "question": "Which specific individual is concerned about the 'Azure spend'?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "Liam",
          "retrieved_context": [
            "Second auth service part of service running on Azure",
            "Second auth service hosted on Microsoft Azure",
            "CacheLayer5 hosted in Azure environment"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5872.0762729644775,
          "generation_latency_ms": 3392.9126262664795,
          "scoring_latency_ms": 2761.064052581787,
          "total_latency_ms": 12026.052951812744
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What version of software is the system 'primarydb_3' currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB3 hosted on Google Cloud",
            "PrimaryDB3 hosted on Google Cloud Platform",
            "CacheLayer5 different provider than PrimaryDB3"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5099.36261177063,
          "generation_latency_ms": 4285.169363021851,
          "scoring_latency_ms": 2741.0640716552734,
          "total_latency_ms": 12125.596046447754
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Data Scientist's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Mia makes data requests",
            "Mia to confirm dataset readiness",
            "PrimaryDB3 hosted on Google Cloud"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6194.874048233032,
          "generation_latency_ms": 5223.646879196167,
          "scoring_latency_ms": 2821.117877960205,
          "total_latency_ms": 14239.638805389404
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-11",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What technical configuration issue was identified as the cause of the version flapping on the Azure auth service?",
          "answer_type": "short_answer",
          "gold_answer": "Configuration drift",
          "predicted_answer": "Configuration drift",
          "retrieved_context": [
            "AuthService2 experiencing version flapping",
            "Second auth service part of service running on Azure",
            "other backend lead working on Azure authentication service"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 11230.402708053589,
          "generation_latency_ms": 5346.801519393921,
          "scoring_latency_ms": 3011.9948387145996,
          "total_latency_ms": 19589.19906616211
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-12",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "Based on the identified configuration drift, was the traffic split on AuthService2 considered intentional?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "multi-cloud latency issue caused by AuthService2",
            "PrimaryDB3 causes cross cloud latency with AuthService2",
            "Second auth service currently in Transition state of second auth service"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 10371.017217636108,
          "generation_latency_ms": 2948.1241703033447,
          "scoring_latency_ms": 2922.14035987854,
          "total_latency_ms": 16241.281747817993
        }
      ],
      "summary": {
        "overall_accuracy": 0.9166666666666666,
        "total_score": 11,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 8,
            "count": 9,
            "accuracy": 0.8888888888888888
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "boolean": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_049.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 175.52690076828003,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which specific system is the user's cofounder concerned about regarding version ambiguity?",
          "answer_type": "short_answer",
          "gold_answer": "PrimaryDB7",
          "predicted_answer": "PrimaryDB7",
          "retrieved_context": [
            "versioning issue on PrimaryDB7 system shows version v1.2.0",
            "versioning issue on PrimaryDB7 headers show version v2.0.0-beta",
            "PrimaryDB7 indicates version v2.0.0-beta"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4864.406585693359,
          "generation_latency_ms": 4973.23203086853,
          "scoring_latency_ms": 2854.891777038574,
          "total_latency_ms": 12692.530393600464
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Who is the DevOps lead responsible for the recent beta deployment on the Google Cloud database?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Elijah",
          "retrieved_context": [
            "2ddbeb07-1c1f-4cf5-beee-7882d0045e86 hosted on Google Cloud Platform",
            "PrimaryDB7 hosted on GCP",
            "PrimaryDB7 hosted on Google's platform"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8182.394027709961,
          "generation_latency_ms": 4836.7414474487305,
          "scoring_latency_ms": 2668.0080890655518,
          "total_latency_ms": 15687.143564224243
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "The database hosted on AWS runs alongside which other system on the same cloud provider?",
          "answer_type": "short_answer",
          "gold_answer": "AnalyticsEngine6",
          "predicted_answer": "AnalyticsEngine6",
          "retrieved_context": [
            "PrimaryDB3 hosted on AWS",
            "PrimaryDB3 hosted on Amazon Web Services",
            "65996f7d-494b-47bb-8cd7-8b75da3ce8ba operating normally for user"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 7721.404552459717,
          "generation_latency_ms": 4457.367897033691,
          "scoring_latency_ms": 3133.6934566497803,
          "total_latency_ms": 15312.465906143188
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What versions are currently active on PrimaryDB7 according to the latest system checks?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "versioning issue on PrimaryDB7 system shows version v1.2.0",
            "PrimaryDB7 has active version v1.2.0",
            "PrimaryDB7 running version v1.2.0"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6799.619913101196,
          "generation_latency_ms": 4709.376573562622,
          "scoring_latency_ms": 8529.698848724365,
          "total_latency_ms": 20038.695335388184
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why was the DevOps lead unavailable to immediately fix the database conflict in the morning?",
          "answer_type": "short_answer",
          "gold_answer": "Taking cat to vet",
          "predicted_answer": "Emergency with his cat, Luna",
          "retrieved_context": [
            "Elijah absent for AWS infrastructure review",
            "391f34bb-5a6e-4852-8dff-b1cf596a150c owns Luna",
            "Luna steals spotlight during DevOps updates"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 9340.992212295532,
          "generation_latency_ms": 4477.5567054748535,
          "scoring_latency_ms": 3102.710247039795,
          "total_latency_ms": 16921.25916481018
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the discussion about the AWS bill happen before or after the strategy sync meeting was mentioned?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "After",
          "retrieved_context": [
            "Alex organizes and attends strategy sync meeting",
            "Oliver attends strategy sync meeting",
            "Sophia attends strategy sync meeting"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5795.579195022583,
          "generation_latency_ms": 4962.889909744263,
          "scoring_latency_ms": 2770.859479904175,
          "total_latency_ms": 13529.32858467102
        },
        {
          "probe_id": "procedural_knowledge-task_state_tracking-6",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "What item is currently on the user's shopping list based on recent requests?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee beans",
          "predicted_answer": "milk, cat food, coffee beans, a gift for niece, flowers",
          "retrieved_context": [
            "reminder to pick up a gift for niece set by user",
            "Alex intends to buy milk",
            "buy coffee beans to do for user"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6582.155704498291,
          "generation_latency_ms": 5127.432823181152,
          "scoring_latency_ms": 2719.682216644287,
          "total_latency_ms": 14429.27074432373
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-7",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "Which two frontend leads did the user decide to involve to verify feasibility?",
          "answer_type": "short_answer",
          "gold_answer": "Charlotte and Sophia",
          "predicted_answer": "Charlotte and Sophia",
          "retrieved_context": [
            "frontend team led by Charlotte",
            "frontend team led by Sophia",
            "frontend team leads includes Sophia"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5267.101526260376,
          "generation_latency_ms": 3427.0479679107666,
          "scoring_latency_ms": 2865.346908569336,
          "total_latency_ms": 11559.496402740479
        },
        {
          "probe_id": "preference_learning-preference_induction-8",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's repeated checks, which infrastructure component requires the most monitoring attention?",
          "answer_type": "short_answer",
          "gold_answer": "PrimaryDB7",
          "predicted_answer": "PrimaryDB7",
          "retrieved_context": [
            "Elijah investigating deployment logs",
            "AuthService4 causes latency with PrimaryDB7",
            "e84847e9-2c3f-41d0-ac4d-57046cf05214 communicates with AnalyticsEngine6"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6171.608209609985,
          "generation_latency_ms": 5566.973924636841,
          "scoring_latency_ms": 2886.2006664276123,
          "total_latency_ms": 14624.782800674438
        },
        {
          "probe_id": "preference_learning-explicit_preferences-9",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What specific aspect of the company does Oliver usually focus on?",
          "answer_type": "short_answer",
          "gold_answer": "Financial overview",
          "predicted_answer": "Cloud bills",
          "retrieved_context": [
            "68dd038f-8845-4bc9-87b5-7d4bec8a0b0d attends strategy sync meeting",
            "Oliver interested in Microsoft costs breakdown request",
            "Oliver cofounder of Nebula Corp"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5568.240404129028,
          "generation_latency_ms": 3978.444814682007,
          "scoring_latency_ms": 2878.0741691589355,
          "total_latency_ms": 12424.75938796997
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the user's gym?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "a7836865-c494-4d70-bd4e-176e6921cf1f manages PrimaryDB7",
            "PrimaryDB7 hosted on Google's platform",
            "a7836865-c494-4d70-bd4e-176e6921cf1f questioned reason for hosting on AuthService4"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 8560.372829437256,
          "generation_latency_ms": 4219.620227813721,
          "scoring_latency_ms": 2884.763717651367,
          "total_latency_ms": 15664.756774902344
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-11",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who holds the role of Backend Lead at the company?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Charlotte holds title Frontend Lead",
            "frontend team led by Sophia",
            "frontend team led by Charlotte"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 6000.875473022461,
          "generation_latency_ms": 3763.3626461029053,
          "scoring_latency_ms": 2854.590654373169,
          "total_latency_ms": 12618.828773498535
        }
      ],
      "summary": {
        "overall_accuracy": 0.8333333333333334,
        "total_score": 10,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 8,
            "count": 10,
            "accuracy": 0.8
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_050.json",
      "adapter_type": "NebulaAdapter",
      "num_sessions": 25,
      "num_probes": 9,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 109.09515070915222,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user referring to when they mention their 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Noah",
          "predicted_answer": "Noah",
          "retrieved_context": [
            "cofounder worried about infrastructure costs",
            "user holds role CTO",
            "user preparing for Nebula Corp all-hands meeting"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5052.651643753052,
          "generation_latency_ms": 3204.0750980377197,
          "scoring_latency_ms": 2911.149501800537,
          "total_latency_ms": 11167.876243591309
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Who is the Frontend Lead responsible for the React migration?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "James holds role Frontend Lead",
            "Liam holds role Product Designer",
            "Will holds role Product Designer"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4361.538648605347,
          "generation_latency_ms": 3461.376190185547,
          "scoring_latency_ms": 2673.4938621520996,
          "total_latency_ms": 10496.408700942993
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which cloud provider hosts the authentication service that is currently experiencing a stuck blue-green deployment?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "AuthService8 hosted on Google Cloud Platform",
            "multi-cloud strategy includes AuthService8",
            "multi-cloud strategy includes AuthService9"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4141.538858413696,
          "generation_latency_ms": 4974.860668182373,
          "scoring_latency_ms": 3143.2766914367676,
          "total_latency_ms": 12259.676218032837
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What versions of the software are currently detected running on AuthService8?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0, v2.0.0-beta",
          "retrieved_context": [
            "authentication services includes AuthService8",
            "authentication services includes AuthService9",
            "AuthService8 hosted on Google Cloud Platform"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 5775.078773498535,
          "generation_latency_ms": 3413.221836090088,
          "scoring_latency_ms": 2728.657007217407,
          "total_latency_ms": 11916.95761680603
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why is the user concerned about egress fees regarding the load balancer hosted on AWS?",
          "answer_type": "short_answer",
          "gold_answer": "It routes traffic to GCP",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "LoadBalancer2 hosted on AWS",
            "multi-cloud strategy includes LoadBalancer3",
            "multi-cloud strategy includes LoadBalancer2"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4458.376884460449,
          "generation_latency_ms": 3873.4984397888184,
          "scoring_latency_ms": 2671.1435317993164,
          "total_latency_ms": 11003.018856048584
        },
        {
          "probe_id": "preference_learning-preference_induction-5",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "How does the CEO prefer infrastructure cost reports to be formatted?",
          "answer_type": "short_answer",
          "gold_answer": "Detailed",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "24a78645-f014-4328-a5fe-20d3e0290370 includes AuthService8",
            "24a78645-f014-4328-a5fe-20d3e0290370 includes AuthService9",
            "24a78645-f014-4328-a5fe-20d3e0290370 includes LoadBalancer3"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 4071.77734375,
          "generation_latency_ms": 9238.072395324707,
          "scoring_latency_ms": 2807.2433471679688,
          "total_latency_ms": 16117.093086242676
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-6",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What kind of pet does Will own?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Will holds role Product Designer",
            "Liam owns Luna",
            "Liam holds role Product Designer"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4636.300802230835,
          "generation_latency_ms": 3615.3876781463623,
          "scoring_latency_ms": 3051.3288974761963,
          "total_latency_ms": 11303.017377853394
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-7",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific roast of coffee beans did the user ask to be added to the shopping list?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user considering assigning ui mockups to Will",
            "user decided to assign ui mockups to Liam",
            "user set reminder for dry cleaning reminder"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 4123.425722122192,
          "generation_latency_ms": 4746.796369552612,
          "scoring_latency_ms": 2708.6102962493896,
          "total_latency_ms": 11578.832387924194
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-8",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What does the user identify as the number one priority when dealing with the executive team?",
          "answer_type": "short_answer",
          "gold_answer": "Keeping them happy",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "user preparing for Nebula Corp all-hands meeting",
            "user holds role CTO",
            "user decided to assign ui mockups to Liam"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 5679.867267608643,
          "generation_latency_ms": 4661.586761474609,
          "scoring_latency_ms": 2897.0649242401123,
          "total_latency_ms": 13238.518953323364
        }
      ],
      "summary": {
        "overall_accuracy": 0.4444444444444444,
        "total_score": 4,
        "count": 9,
        "by_answer_type": {
          "short_answer": {
            "total": 2,
            "count": 7,
            "accuracy": 0.2857142857142857
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    }
  ]
}