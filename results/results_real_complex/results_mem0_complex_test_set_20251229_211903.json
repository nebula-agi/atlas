{
  "generated_at": "2025-12-29T22:07:54.238028",
  "adapter_type": "Mem0Adapter",
  "num_benchmarks": 50,
  "total_probes": 503,
  "overall_summary": {
    "overall_accuracy": 0.47514910536779326,
    "total_score": 239,
    "count": 503,
    "by_answer_type": {
      "short_answer": {
        "total": 162,
        "count": 408,
        "accuracy": 0.39705882352941174
      },
      "boolean": {
        "total": 7,
        "count": 18,
        "accuracy": 0.3888888888888889
      },
      "abstain": {
        "total": 70,
        "count": 73,
        "accuracy": 0.958904109589041
      },
      "verbatim": {
        "total": 0,
        "count": 2,
        "accuracy": 0.0
      },
      "generation": {
        "total": 0,
        "count": 2,
        "accuracy": 0.0
      }
    },
    "by_pillar": {
      "world_modeling": {
        "total": 46,
        "count": 85,
        "accuracy": 0.5411764705882353
      },
      "declarative_reasoning": {
        "total": 40,
        "count": 95,
        "accuracy": 0.42105263157894735
      },
      "temporal_episodic": {
        "total": 18,
        "count": 83,
        "accuracy": 0.21686746987951808
      },
      "preference_learning": {
        "total": 37,
        "count": 75,
        "accuracy": 0.49333333333333335
      },
      "knowledge_boundaries": {
        "total": 80,
        "count": 90,
        "accuracy": 0.8888888888888888
      },
      "procedural_knowledge": {
        "total": 18,
        "count": 75,
        "accuracy": 0.24
      }
    }
  },
  "stored_memories": [],
  "benchmark_summaries": [
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_001.json",
      "accuracy": 0.4166666666666667,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 74.06861805915833
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_002.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 83.17501902580261
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_003.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 67.54220747947693
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_004.json",
      "accuracy": 0.6666666666666666,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 70.8852972984314
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_005.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 80.57599782943726
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_006.json",
      "accuracy": 0.36363636363636365,
      "num_probes": 11,
      "ingestion_time_s": 0.0,
      "eval_time_s": 67.22431969642639
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_007.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 74.77313160896301
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_008.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 74.5204689502716
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_009.json",
      "accuracy": 0.5833333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 71.0006959438324
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_010.json",
      "accuracy": 0.4166666666666667,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 68.67827272415161
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_011.json",
      "accuracy": 0.42857142857142855,
      "num_probes": 7,
      "ingestion_time_s": 0.0,
      "eval_time_s": 38.19324541091919
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_012.json",
      "accuracy": 1.0,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 9.972140550613403
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_013.json",
      "accuracy": 1.0,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 9.580780506134033
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_014.json",
      "accuracy": 1.0,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 10.275998592376709
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_015.json",
      "accuracy": 0.18181818181818182,
      "num_probes": 11,
      "ingestion_time_s": 0.0,
      "eval_time_s": 66.64568018913269
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_016.json",
      "accuracy": 0.38461538461538464,
      "num_probes": 13,
      "ingestion_time_s": 0.0,
      "eval_time_s": 75.06032609939575
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_017.json",
      "accuracy": 0.75,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 67.62503480911255
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_018.json",
      "accuracy": 0.4166666666666667,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 70.07631373405457
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_019.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 68.62913298606873
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_020.json",
      "accuracy": 0.3333333333333333,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 74.00274062156677
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_021.json",
      "accuracy": 0.3333333333333333,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 72.17392659187317
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_022.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 69.9001932144165
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_023.json",
      "accuracy": 0.5,
      "num_probes": 8,
      "ingestion_time_s": 0.0,
      "eval_time_s": 43.905922174453735
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_024.json",
      "accuracy": 0.6,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "eval_time_s": 53.866021156311035
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_025.json",
      "accuracy": 0.7,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "eval_time_s": 56.92814755439758
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_026.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 67.17261695861816
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_027.json",
      "accuracy": 1.0,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 11.709226131439209
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_028.json",
      "accuracy": 0.3333333333333333,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 69.41692042350769
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_029.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 66.57342886924744
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_030.json",
      "accuracy": 0.5,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 9.28494668006897
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_031.json",
      "accuracy": 0.0,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 11.518900632858276
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_032.json",
      "accuracy": 0.5,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "eval_time_s": 56.31493043899536
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_033.json",
      "accuracy": 0.3333333333333333,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 68.7511556148529
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_034.json",
      "accuracy": 0.3333333333333333,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 65.50291514396667
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_035.json",
      "accuracy": 0.6,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "eval_time_s": 54.24059200286865
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_036.json",
      "accuracy": 0.36363636363636365,
      "num_probes": 11,
      "ingestion_time_s": 0.0,
      "eval_time_s": 59.89019012451172
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_037.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 72.88689756393433
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_038.json",
      "accuracy": 0.3333333333333333,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 70.34549450874329
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_039.json",
      "accuracy": 0.5,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "eval_time_s": 11.841014623641968
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_040.json",
      "accuracy": 0.4166666666666667,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 74.41433429718018
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_041.json",
      "accuracy": 0.5,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 69.14024019241333
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_042.json",
      "accuracy": 0.3333333333333333,
      "num_probes": 9,
      "ingestion_time_s": 0.0,
      "eval_time_s": 54.087132930755615
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_043.json",
      "accuracy": 0.4166666666666667,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 68.51058387756348
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_044.json",
      "accuracy": 0.6666666666666666,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 68.10545253753662
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_045.json",
      "accuracy": 0.4,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "eval_time_s": 58.58711004257202
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_046.json",
      "accuracy": 0.6666666666666666,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 65.16195273399353
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_047.json",
      "accuracy": 0.4166666666666667,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 67.22401666641235
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_048.json",
      "accuracy": 0.4166666666666667,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 69.64392685890198
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_049.json",
      "accuracy": 0.5833333333333334,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "eval_time_s": 65.82032227516174
    },
    {
      "file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_050.json",
      "accuracy": 0.4444444444444444,
      "num_probes": 9,
      "ingestion_time_s": 0.0,
      "eval_time_s": 53.09941554069519
    }
  ],
  "detailed_results": [
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_001.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 74.06861805915833,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who deployed the analytics engine situated on Google Cloud Platform?",
          "answer_type": "short_answer",
          "gold_answer": "Lucas",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know where analytics engines are hosted.",
            "User asks if AnalyticsEngine2 is the only isolated instance on Google Cloud.",
            "User thought we had an analytics service on Google Cloud."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 359.03215408325195,
          "generation_latency_ms": 4333.21738243103,
          "total_latency_ms": 4692.249536514282
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the job title of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Data Scientist",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User acknowledges cat's name is Luna.",
            "User's cat is sleeping on keyboard and is the real boss",
            "User wants to know how Luna is doing; Luna was sick last week."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 741.051197052002,
          "generation_latency_ms": 4421.145915985107,
          "total_latency_ms": 5162.197113037109
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which cloud provider hosts the service that is currently reporting conflicting version numbers?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "User asks if the instance is still in Microsoft cloud.",
            "User always forgets which cloud the engines are on.",
            "User will have Lucas investigate version conflicts; Lucas handles deployment pipelines."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 637.4149322509766,
          "generation_latency_ms": 3028.8846492767334,
          "total_latency_ms": 3666.29958152771
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What specific versions are currently being flagged by the primary database according to the latest logs and config?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "User wants clarification on conflicting status of the main database",
            "User wants a quick status check on PrimaryDB7.",
            "User wants to know the version of PrimaryDB7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 641.613245010376,
          "generation_latency_ms": 2447.35050201416,
          "total_latency_ms": 3088.963747024536
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-0",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "During the conversation about consolidating analytics services, what personal appointment was the user reminded of?",
          "answer_type": "short_answer",
          "gold_answer": "Dentist appointment",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User plans to schedule a sync with Lucas to talk about consolidating",
            "User wants analytics engines running smoothly for Will's models today.",
            "User needs to summarize information for cofounder before strategy sync later today."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 349.4453430175781,
          "generation_latency_ms": 3748.224973678589,
          "total_latency_ms": 4097.670316696167
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Was the reminder to call mom set for 5 PM before or after the user discussed the CEO's memo?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants reminder to call mom at 6 PM tonight.",
            "User wants reminder to call mom at 5 PM today",
            "User wants reminder to email cofounder before EOD."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 581.9978713989258,
          "generation_latency_ms": 2828.3653259277344,
          "total_latency_ms": 3410.36319732666
        },
        {
          "probe_id": "preference_learning-preference_drift-0",
          "pillar": "preference_learning",
          "subpillar": "preference_drift",
          "question": "What is the most recently requested time for the user's reminder to call their mom?",
          "answer_type": "short_answer",
          "gold_answer": "6 PM",
          "predicted_answer": "6 PM tonight",
          "retrieved_context": [
            "User wants reminder to call mom at 5 PM today",
            "User wants reminder to call mom at 6 PM tonight.",
            "User wants a reminder to grab a latte before the meeting starts."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 605.372428894043,
          "generation_latency_ms": 2911.970853805542,
          "total_latency_ms": 3517.343282699585
        },
        {
          "probe_id": "preference_learning-explicit_preferences-1",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Did the user specify a particular topic to discuss during the call with their mom?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know what Noah is up to.",
            "User asks if they have meeting with cofounder this afternoon",
            "User needs to have serious talk with Lucas"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 548.8417148590088,
          "generation_latency_ms": 2758.166790008545,
          "total_latency_ms": 3307.0085048675537
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What version is the AnalyticsEngine2 currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know where analytics engines are hosted.",
            "User asks if AnalyticsEngine2 is the only isolated instance on Google Cloud.",
            "Lucas deployed AnalyticsEngine2 for specific ML tools in a different provider"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 351.78518295288086,
          "generation_latency_ms": 2758.1887245178223,
          "total_latency_ms": 3109.973907470703
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Product Designer's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to grab the designer",
            "User is considering something for the cat",
            "User's cofounder wants an update on product designs Noah is drafting."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 431.13088607788086,
          "generation_latency_ms": 4384.233713150024,
          "total_latency_ms": 4815.364599227905
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "How did the assistant determine the version conflict on the Azure-hosted database?",
          "answer_type": "short_answer",
          "gold_answer": "Comparing logs and config",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Lucas mentioned a version mismatch on Azure database.",
            "User wants clarification on conflicting status of the main database",
            "Lucas is wrestling with the Azure deployment for the main database."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 648.2157707214355,
          "generation_latency_ms": 3546.8239784240723,
          "total_latency_ms": 4195.039749145508
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-1",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What technical task is the DevOps lead currently struggling with?",
          "answer_type": "short_answer",
          "gold_answer": "Azure deployment",
          "predicted_answer": "Failed blue-green deployment",
          "retrieved_context": [
            "User says not to bother the DevOps lead yet.",
            "User says Lucas is in DevOps",
            "Lucas is the best DevOps guy the user has for this sort of thing."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 632.6131820678711,
          "generation_latency_ms": 4124.504804611206,
          "total_latency_ms": 4757.117986679077
        }
      ],
      "summary": {
        "overall_accuracy": 0.4166666666666667,
        "total_score": 5,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 3,
            "count": 9,
            "accuracy": 0.3333333333333333
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_002.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 83.17501902580261,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the person referred to as the user's 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Charlotte",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder is CEO.",
            "User wants to know who is leading the frontend team.",
            "User believes beta code in production was Noah's doing"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 753.4809112548828,
          "generation_latency_ms": 2195.33634185791,
          "total_latency_ms": 2948.817253112793
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which DevOps team member is associated with a cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Noah",
          "predicted_answer": "Noah",
          "retrieved_context": [
            "User wants to identify the DevOps engineer who has a cat",
            "Noah's cat Luna walked on his keyboard this morning",
            "User wants a message drafted to the person with cat named Luna and his teammate."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 289.8428440093994,
          "generation_latency_ms": 2858.3059310913086,
          "total_latency_ms": 3148.148775100708
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service currently reporting a conflict between v1.2.0 and v2.0.0-beta hosted?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "GCP",
          "retrieved_context": [
            "User questions whether the beta version was deployed.",
            "User acknowledges at least one cloud is behaving.",
            "User is hearing reports of a version mismatch"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 615.5819892883301,
          "generation_latency_ms": 2639.9850845336914,
          "total_latency_ms": 3255.5670738220215
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-1",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "What two specific versions are simultaneously reported as active on AuthService7?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "1.2.0 and 2.0 beta",
          "retrieved_context": [
            "Metadata for AuthService7 shows version v1.2.0.",
            "User is viewing AuthService7.",
            "User requests deployment status of AuthService7"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 363.1141185760498,
          "generation_latency_ms": 2412.1861457824707,
          "total_latency_ms": 2775.3002643585205
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-0",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific event involving a pet did the user speculate might have caused the canary deployment issues?",
          "answer_type": "short_answer",
          "gold_answer": "Luna walking on keyboard",
          "predicted_answer": "Noah's cat causing havoc in Noah's home office yesterday",
          "retrieved_context": [
            "User started a canary deployment yesterday.",
            "Noah is messing with a canary deployment",
            "User feels the canary deployment didn't clean up properly."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 443.5737133026123,
          "generation_latency_ms": 3994.908332824707,
          "total_latency_ms": 4438.482046127319
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-1",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "Immediately after mentioning the strategy session with Charlotte, what personal task did the user request a reminder for?",
          "answer_type": "short_answer",
          "gold_answer": "Pick up dry cleaning",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User had a long strategy session with Charlotte.",
            "User has a strategy meeting with Charlotte later and needs to prep for quarterly projections.",
            "User will update Charlotte on the situation"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 639.4312381744385,
          "generation_latency_ms": 4305.795431137085,
          "total_latency_ms": 4945.226669311523
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of Emma's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Emma is going to lose it.",
            "Emma is the Frontend Lead",
            "User asks if Emma has pushed new dashboard widgets."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 573.30322265625,
          "generation_latency_ms": 3482.6858043670654,
          "total_latency_ms": 4055.9890270233154
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "On which cloud platform is the 'PaymentGateway' service hosted?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to look at auth services on Google's cloud",
            "User is inquiring about the location of auth services relative to the load balancer.",
            "User is inquiring about the legacy authentication service and the load balancer."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 659.8577499389648,
          "generation_latency_ms": 3224.5988845825195,
          "total_latency_ms": 3884.4566345214844
        },
        {
          "probe_id": "preference_learning-explicit_preferences-0",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "At what time does the user repeatedly request to be reminded to pick up dry cleaning?",
          "answer_type": "short_answer",
          "gold_answer": "5 PM",
          "predicted_answer": "5 PM",
          "retrieved_context": [
            "User wants a reminder to pick up dry cleaning at 5 PM",
            "User wants a reminder to pick up dry cleaning on the way home.",
            "User needs to pick up dry cleaning at 5 PM."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 725.0313758850098,
          "generation_latency_ms": 2670.6106662750244,
          "total_latency_ms": 3395.642042160034
        },
        {
          "probe_id": "preference_learning-preference_scope-1",
          "pillar": "preference_learning",
          "subpillar": "preference_scope",
          "question": "Has the user expressed a preference for which cloud provider to use for new services?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User acknowledges multi-cloud strategy",
            "We are using every provider under the sun",
            "User acknowledges at least one cloud is behaving."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 296.8003749847412,
          "generation_latency_ms": 12169.970512390137,
          "total_latency_ms": 12466.770887374878
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What administrative action did the assistant take to ensure the version discrepancy was addressed during the user's sync with Charlotte?",
          "answer_type": "short_answer",
          "gold_answer": "Added a note",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User will have Charlotte follow up with Emma during the executive sync.",
            "User will update Charlotte on the situation",
            "User wants a note to bring up the stability issue in the next sync"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 603.2943725585938,
          "generation_latency_ms": 4303.363561630249,
          "total_latency_ms": 4906.657934188843
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "Which two team members did the assistant suggest contacting to handle an infrastructure rollback?",
          "answer_type": "short_answer",
          "gold_answer": "Ava or Noah",
          "predicted_answer": "Ava and Noah",
          "retrieved_context": [
            "User intends to check in with infrastructure team.",
            "User wants to dive into infrastructure mess.",
            "User does not want to explain downtime to cofounder."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 602.0011901855469,
          "generation_latency_ms": 5372.289657592773,
          "total_latency_ms": 5974.29084777832
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 9,
            "accuracy": 0.4444444444444444
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_003.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 27,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 67.54220747947693,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual identified as the user's cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "Liam",
          "retrieved_context": [
            "User has a sync with a cofounder later",
            "User's cofounder asked about the cloud footprint.",
            "User will ask cofounder if he authorized the beta rollout."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 589.7817611694336,
          "generation_latency_ms": 2310.666561126709,
          "total_latency_ms": 2900.4483222961426
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which employee is associated with the pet named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Ava",
          "predicted_answer": "Ava",
          "retrieved_context": [
            "User remembers Luna was worried about the vet visit.",
            "User asks whether Ava is bringing Luna to the office today.",
            "User promised to bring cat treats for Luna, Ava's cat."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 277.27746963500977,
          "generation_latency_ms": 3534.929037094116,
          "total_latency_ms": 3812.206506729126
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Is the service currently running the v2.0.0-beta version hosted on the same cloud provider as LoadBalancer2?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks if LoadBalancer2 is still on legacy setup.",
            "User asks whether the service is in the same environment as the load balancer.",
            "User is asking whether LoadBalancer2 is on Azure."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 816.425085067749,
          "generation_latency_ms": 3808.4256649017334,
          "total_latency_ms": 4624.850749969482
        },
        {
          "probe_id": "declarative_reasoning-verbatim_recall-3",
          "pillar": "declarative_reasoning",
          "subpillar": "verbatim_recall",
          "question": "What exact phrase did the user use to describe their low energy level in Session 23?",
          "answer_type": "verbatim",
          "gold_answer": "I am dragging today",
          "predicted_answer": "running on fumes today",
          "retrieved_context": [
            "User is almost out of coffee beans.",
            "User feels like running on fumes today",
            "Liam is pestering user about quarterly numbers."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 634.1469287872314,
          "generation_latency_ms": 2386.4710330963135,
          "total_latency_ms": 3020.617961883545
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-4",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the request to text Ava occur before or after the discussion about the Azure bill?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User chatted with Ava earlier.",
            "User wants a reminder to text Ava later",
            "User says Ava is in and out."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 368.52025985717773,
          "generation_latency_ms": 3225.996255874634,
          "total_latency_ms": 3594.5165157318115
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What specific time slot was secured for the meeting with the CEO regarding the data team?",
          "answer_type": "short_answer",
          "gold_answer": "2 PM",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to book a meeting to discuss the data team, noting Sophia and Will are doing great work but more hands may be needed.",
            "User will inform the data team during the standup",
            "User reports that cofounder is asking for a progress report on the AI stack for the board meeting."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 616.5246963500977,
          "generation_latency_ms": 3036.600112915039,
          "total_latency_ms": 3653.1248092651367
        },
        {
          "probe_id": "preference_learning-explicit_preferences-6",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Which specific service did the user explicitly instruct to exclude from the Azure cost report?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer2",
          "predicted_answer": "load balancer",
          "retrieved_context": [
            "User asks whether all analytics services are on Azure.",
            "User wants to add \"Review Azure spend\" to to-do list for weekend",
            "User needs to consolidate cloud spend."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 629.5256614685059,
          "generation_latency_ms": 2368.0052757263184,
          "total_latency_ms": 2997.530937194824
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "When asking for system status for the investor call, what level of detail did the user prefer?",
          "answer_type": "short_answer",
          "gold_answer": "High level",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to review system status",
            "User wants to check what version AnalyticsEngine2 is reporting.",
            "Alex requests current status for the analytics cluster."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 293.3943271636963,
          "generation_latency_ms": 2717.707633972168,
          "total_latency_ms": 3011.1019611358643
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the specific version number currently running on AuthService4?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know where AuthService4 and AnalyticsEngine9 are hosted.",
            "User asks if AuthService4 is hosted on Azure same as analytics infrastructure.",
            "AuthService4 has been acting up"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 351.1018753051758,
          "generation_latency_ms": 2702.5229930877686,
          "total_latency_ms": 3053.6248683929443
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who is the current Product Manager at Nebula?",
          "answer_type": "abstain",
          "gold_answer": "Not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is looking at the infrastructure for Nebula",
            "User confirms Ava is the Product Designer.",
            "User wants to know who is on the data science team"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 340.13843536376953,
          "generation_latency_ms": 3161.1857414245605,
          "total_latency_ms": 3501.32417678833
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What habit of Will's is believed to be the cause of the version conflicts on the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "Testing in prod",
          "predicted_answer": "tinkering with the main analytics node",
          "retrieved_context": [
            "Sophia and Will think there's a version mismatch on AnalyticsEngine2",
            "Sophia and Will are debating the versioning on the second analytics engine.",
            "User is asking whether Will deployed new code to AnalyticsEngine2."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 716.5873050689697,
          "generation_latency_ms": 2792.3102378845215,
          "total_latency_ms": 3508.897542953491
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-11",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What logic was applied to exclude LoadBalancer2 from the Azure spend report?",
          "answer_type": "short_answer",
          "gold_answer": "Hosted on GCP",
          "predicted_answer": "It is hosted on Google Cloud.",
          "retrieved_context": [
            "The load balancer is hosted on Google Cloud and should be excluded from the Azure report",
            "User is asking whether LoadBalancer2 is on Azure.",
            "User wants to verify which cloud provider is used for the second load balancer and feels it is the odd one out."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 351.12953186035156,
          "generation_latency_ms": 4242.612361907959,
          "total_latency_ms": 4593.741893768311
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 8,
            "accuracy": 0.5
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "verbatim": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_004.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 70.8852972984314,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user planning to discuss quarterly goals with?",
          "answer_type": "short_answer",
          "gold_answer": "Mia",
          "predicted_answer": "Mia",
          "retrieved_context": [
            "Mia wants to chat about the quarterly goals.",
            "User needs quarterly projections.",
            "User wants to know if cofounder mentioned sales meeting time."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 627.1238327026367,
          "generation_latency_ms": 2488.0313873291016,
          "total_latency_ms": 3115.1552200317383
        },
        {
          "probe_id": "world_modeling-relationship_mapping-0",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which member of the sales team is the owner of Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Lucas",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User expresses sympathy for Luna",
            "Luna is getting massive.",
            "User has heard enough stories about Luna."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 380.27167320251465,
          "generation_latency_ms": 3197.040796279907,
          "total_latency_ms": 3577.312469482422
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What cloud provider hosts the load balancer that the DevOps lead was worried about?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google's cloud",
          "retrieved_context": [
            "User talked to DevOps guy Liam about changes to load balancer on Google's cloud",
            "Liam is currently checking the load balancer hosted on Google's infrastructure.",
            "LoadBalancer8 is fine and staying on GCP."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 852.2548675537109,
          "generation_latency_ms": 2971.298933029175,
          "total_latency_ms": 3823.5538005828857
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-0",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "According to the conflicting system logs, which two cloud providers are reportedly hosting CacheLayer3?",
          "answer_type": "short_answer",
          "gold_answer": "GCP and Azure",
          "predicted_answer": "Google Cloud and Azure",
          "retrieved_context": [
            "User is unsure if the third cache layer migrated to Google's cloud or is still elsewhere.",
            "User is concerned about CacheLayer3 metrics.",
            "CacheLayer3 is the caching service."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 866.7268753051758,
          "generation_latency_ms": 2252.9661655426025,
          "total_latency_ms": 3119.6930408477783
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-0",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What ongoing activity explains why CacheLayer3 is reporting two different software versions simultaneously?",
          "answer_type": "short_answer",
          "gold_answer": "Update migration",
          "predicted_answer": "Migration",
          "retrieved_context": [
            "User wants to know the version of CacheLayer3.",
            "CacheLayer3 is running v1.2.0 in some spots but logs show v2.0.0-beta in others.",
            "User wants to know if CacheLayer6 has version issue."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 291.9290065765381,
          "generation_latency_ms": 4576.119661331177,
          "total_latency_ms": 4868.048667907715
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-0",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "During the strategy meeting, what specific event interrupted the Sales Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Luna jumped on keyboard",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User had a long strategy sync with cofounder and sales leads.",
            "User wants to know if cofounder mentioned sales meeting time.",
            "User is worried about the sales department."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 787.2798442840576,
          "generation_latency_ms": 2879.0860176086426,
          "total_latency_ms": 3666.3658618927
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What beverage does the user frequently consume to cope with work exhaustion?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "User is on third cup of coffee",
            "User needs to grab coffee before the board meeting.",
            "User is struggling today because the office coffee machine is broken."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 492.7651882171631,
          "generation_latency_ms": 3207.2930335998535,
          "total_latency_ms": 3700.0582218170166
        },
        {
          "probe_id": "preference_learning-explicit_preferences-0",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What item did the user explicitly ask to be added to their shopping list?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee beans",
          "predicted_answer": "buy coffee beans",
          "retrieved_context": [
            "User wants to add 'buy coffee beans' to their shopping list.",
            "User wants to add 'buy espresso beans' to their personal to-do list.",
            "User wants reminder to buy coffee beans later"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 819.0324306488037,
          "generation_latency_ms": 2665.2472019195557,
          "total_latency_ms": 3484.2796325683594
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Backend Lead's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants backend lead to take a look",
            "User does not want Backend Lead yelling at them today.",
            "Charlotte, the backend lead, is stressing about the main database connection and will figure out the issue."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 364.7918701171875,
          "generation_latency_ms": 2969.548225402832,
          "total_latency_ms": 3334.3400955200195
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the 'auth_service'?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User thought everything moved to one provider",
            "User asks if main database is hosted solely on Azure.",
            "CacheLayer3 is reporting active instances on both Google Cloud and Azure."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 520.7157135009766,
          "generation_latency_ms": 3773.4527587890625,
          "total_latency_ms": 4294.168472290039
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What two specific data sources does the assistant cite when analyzing the version conflict on CacheLayer3?",
          "answer_type": "short_answer",
          "gold_answer": "Response headers and heartbeats",
          "predicted_answer": "running instances and logs",
          "retrieved_context": [
            "User wants to know the version of CacheLayer3.",
            "Charlotte was asking about the versioning on CacheLayer3.",
            "User wants to know if CacheLayer6 has version issue."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 657.2144031524658,
          "generation_latency_ms": 2521.280288696289,
          "total_latency_ms": 3178.494691848755
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-0",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "Based on previous checks, what is the expected stability status of CacheLayer3?",
          "answer_type": "short_answer",
          "gold_answer": "Unstable",
          "predicted_answer": "Issues/Not stable",
          "retrieved_context": [
            "User is asking if CacheLayer3 is fully migrated.",
            "User wants to check cache layer 3.",
            "User wants to know the version of CacheLayer3."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 368.70622634887695,
          "generation_latency_ms": 4167.900800704956,
          "total_latency_ms": 4536.607027053833
        }
      ],
      "summary": {
        "overall_accuracy": 0.6666666666666666,
        "total_score": 8,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 10,
            "accuracy": 0.6
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_005.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 80.57599782943726,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which executive is repeatedly referred to as the user's 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Mia",
          "predicted_answer": "Mia",
          "retrieved_context": [
            "User had a sync with cofounder",
            "User's cofounder is breathing down their neck for the infra summary",
            "User's cofounder loves using the buzzword 'multi-cloud' in investor updates."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 854.5589447021484,
          "generation_latency_ms": 3112.0924949645996,
          "total_latency_ms": 3966.651439666748
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which specific service is co-located on the Google Cloud Platform alongside the main database?",
          "answer_type": "short_answer",
          "gold_answer": "CacheLayer4",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks about Google Cloud environment.",
            "PrimaryDB3 is located on GCP.",
            "Authentication service is running on Azure while the main database is on Google Cloud, and they are on different cloud providers, causing latency."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 601.8257141113281,
          "generation_latency_ms": 3938.223361968994,
          "total_latency_ms": 4540.049076080322
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "The Backend Lead set up a specific caching layer. Which cloud platform is that layer hosted on?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Will's backend team is running secondary cache on Amazon.",
            "Caching layers are split between providers, with the fourth cache layer located on GCP and the legacy cache located on AWS.",
            "User is looking at latency logs for the backend and wants to know where caching layers are located."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 580.5506706237793,
          "generation_latency_ms": 3976.60493850708,
          "total_latency_ms": 4557.155609130859
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What two software versions is AuthService7 currently reporting in the logs?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to check the version of AuthService7.",
            "User is observing AuthService7",
            "User reports an issue with AuthService7 and asks if it is running the beta version."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 728.3079624176025,
          "generation_latency_ms": 4217.1831130981445,
          "total_latency_ms": 4945.491075515747
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-1",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "In the most recent interaction, what reason was given for the Sales Lead being inactive or late?",
          "answer_type": "short_answer",
          "gold_answer": "Luna was sick",
          "predicted_answer": "useless today",
          "retrieved_context": [
            "Sales lead forgets to update CRM",
            "James is Sales Lead",
            "User is asking for main point of contact for sales team."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 590.8739566802979,
          "generation_latency_ms": 4209.981679916382,
          "total_latency_ms": 4800.85563659668
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user request a reminder for concert tickets before or after the reminder for the team lunch pizza?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Before",
          "retrieved_context": [
            "User wants a reminder to buy concert tickets at noon.",
            "User thanks for reminder.",
            "User wants a reminder to pick up a sandwich at noon."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 679.7542572021484,
          "generation_latency_ms": 3026.5352725982666,
          "total_latency_ms": 3706.289529800415
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "When offered the option to filter the Sales Lead's distracting messages, what was the user's decision?",
          "answer_type": "short_answer",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User thanks assistant for keeping them on track",
            "User wants to stay in the loop in case James closes a deal.",
            "Sales lead forgets to update CRM"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 565.5810832977295,
          "generation_latency_ms": 3632.6968669891357,
          "total_latency_ms": 4198.277950286865
        },
        {
          "probe_id": "preference_learning-constraint_hierarchy-1",
          "pillar": "preference_learning",
          "subpillar": "constraint_hierarchy",
          "question": "Why did the user choose not to filter James's messages despite the distractions?",
          "answer_type": "short_answer",
          "gold_answer": "To stay in the loop",
          "predicted_answer": "To stay in the loop in case James closes a deal.",
          "retrieved_context": [
            "User wants to stay in the loop in case James closes a deal.",
            "User heard meowing in background during James's call",
            "User says James is spamming general channel with photos of his new pet."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 843.0328369140625,
          "generation_latency_ms": 4701.934099197388,
          "total_latency_ms": 5544.96693611145
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the 'PaymentGateway' service?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is asking if authentication service is on Google or Amazon.",
            "User asks about Google Cloud environment.",
            "User wants to look at Microsoft-hosted services first."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 543.0071353912354,
          "generation_latency_ms": 3046.6370582580566,
          "total_latency_ms": 3589.644193649292
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "What is the name of the Backend Lead's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "James is Sales Lead",
            "Sales lead talks about cat Luna",
            "User asks if backend lead figured out why AWS instance is lagging"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 854.9575805664062,
          "generation_latency_ms": 3287.020444869995,
          "total_latency_ms": 4141.978025436401
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What recurring weekly event does the user repeatedly ask the assistant to help prepare for?",
          "answer_type": "short_answer",
          "gold_answer": "Sync with Mia",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User thanks assistant for keeping them on track",
            "User wants a reminder to buy concert tickets at noon.",
            "User is asking if Mia put anything on calendar."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 666.163444519043,
          "generation_latency_ms": 3628.7841796875,
          "total_latency_ms": 4294.947624206543
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-1",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "Is the service managed by the Backend Lead hosted on the same platform as the Analytics Engine?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "User wants to know where AnalyticsEngine9 is hosted on Azure.",
            "User wants to know if the analytics engine is affected.",
            "User wants to know about the analytics engine"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 781.5537452697754,
          "generation_latency_ms": 4565.104007720947,
          "total_latency_ms": 5346.657752990723
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 3,
            "count": 9,
            "accuracy": 0.3333333333333333
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "boolean": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 3,
            "accuracy": 0.3333333333333333
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_006.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 11,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 67.22431969642639,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the 'Backend Lead' investigating the database discrepancies?",
          "answer_type": "short_answer",
          "gold_answer": "Sophia",
          "predicted_answer": "Sophia",
          "retrieved_context": [
            "User wants to know identity of backend lead.",
            "Sophia leads the backend team.",
            "User needs backend lead to investigate latency"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 693.1211948394775,
          "generation_latency_ms": 3328.047275543213,
          "total_latency_ms": 4021.1684703826904
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the organizational role of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales team",
          "retrieved_context": [
            "User says Luna the cat is basically the mascot of the sales team.",
            "James's cat Luna has a birthday",
            "User thinks James's cat is named Luna"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 652.836799621582,
          "generation_latency_ms": 3430.631160736084,
          "total_latency_ms": 4083.467960357666
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which cloud provider hosts the service associated with the CEO's login errors?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder had trouble logging in earlier.",
            "User thought Azure instance was killed",
            "User is seeing weird logs from auth service."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 635.2617740631104,
          "generation_latency_ms": 3491.5308952331543,
          "total_latency_ms": 4126.792669296265
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Is the primary database currently confirmed to be hosted in a single environment?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is referring to the primary database.",
            "User wants to know where the main database is currently sitting.",
            "User hopes we aren't paying for PrimaryDB8 on both clouds right now."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 793.8244342803955,
          "generation_latency_ms": 3782.6526165008545,
          "total_latency_ms": 4576.47705078125
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific activity caused the user's lack of sleep before the auth service check?",
          "answer_type": "short_answer",
          "gold_answer": "quarterly strategy call",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is seeing weird logs from auth service.",
            "User's cofounder had trouble logging in earlier.",
            "User wants to check AuthService7 and keep an eye on beta traffic for it, and Sophia is worried that beta traffic might break the backend API."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 587.193489074707,
          "generation_latency_ms": 2664.3154621124268,
          "total_latency_ms": 3251.508951187134
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What item did the user ask to be reminded to buy while checking the load balancer logs?",
          "answer_type": "short_answer",
          "gold_answer": "coffee beans",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to pull logs for the load balancer to check traffic spikes from this morning.",
            "User wants reminder to check analytics engine throughput when back.",
            "User is seeing inconsistent logs in the dashboard."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 358.288049697876,
          "generation_latency_ms": 3041.810989379883,
          "total_latency_ms": 3400.099039077759
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "When reviewing the CEO's agendas, which department's representation does the user explicitly prioritize?",
          "answer_type": "short_answer",
          "gold_answer": "engineering",
          "predicted_answer": "engineering",
          "retrieved_context": [
            "User is checking the timeline proposed by cofounder",
            "User will review agenda",
            "Will, the user's cofounder, keeps pinging the user about hosting bills and is worried about overspending on the CEO budget."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 653.0447006225586,
          "generation_latency_ms": 3911.240816116333,
          "total_latency_ms": 4564.285516738892
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-7",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the user's mechanic?",
          "answer_type": "short_answer",
          "gold_answer": "unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is inquiring about the authentication module.",
            "James kept User on a call for hours",
            "User will ping Sophia"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 617.2225475311279,
          "generation_latency_ms": 2820.2714920043945,
          "total_latency_ms": 3437.4940395355225
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific version number is the Analytics Engine currently running?",
          "answer_type": "short_answer",
          "gold_answer": "unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants verification of analytics engine host.",
            "User wants reminder to check analytics engine throughput when back.",
            "User's cofounder was asking about analytics engine."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 359.663724899292,
          "generation_latency_ms": 3625.945568084717,
          "total_latency_ms": 3985.609292984009
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-9",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What technical configuration is suspected to be the cause of the cofounder's login errors?",
          "answer_type": "short_answer",
          "gold_answer": "beta version traffic",
          "predicted_answer": "version mismatch",
          "retrieved_context": [
            "User's cofounder had trouble logging in earlier.",
            "User believes Sophia might have upgraded the authentication module.",
            "User is seeing weird logs from auth service."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 715.7490253448486,
          "generation_latency_ms": 2643.9208984375,
          "total_latency_ms": 3359.6699237823486
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-10",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What action did the user plan to take regarding the product roadmap agenda sent by the CEO?",
          "answer_type": "generation",
          "gold_answer": "review for engineering representation",
          "predicted_answer": "review agenda",
          "retrieved_context": [
            "User is checking the timeline proposed by cofounder",
            "User's cofounder wants the new feature rollout accelerated.",
            "User had a strategy meeting with cofounder earlier"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 383.4078311920166,
          "generation_latency_ms": 3261.869192123413,
          "total_latency_ms": 3645.2770233154297
        }
      ],
      "summary": {
        "overall_accuracy": 0.36363636363636365,
        "total_score": 4,
        "count": 11,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 9,
            "accuracy": 0.4444444444444444
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "generation": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_007.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 74.77313160896301,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the 'cofounder' that the user reviewed the infrastructure bill with?",
          "answer_type": "short_answer",
          "gold_answer": "Will",
          "predicted_answer": "Will",
          "retrieved_context": [
            "Alex is preparing for an infra review with their cofounder later",
            "User was reviewing the infrastructure bill with their cofounder and noted that cross-cloud costs are getting ridiculous.",
            "User's cofounder wants a full infrastructure audit before the board meeting."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 593.8546657562256,
          "generation_latency_ms": 2558.086395263672,
          "total_latency_ms": 3151.9410610198975
        },
        {
          "probe_id": "world_modeling-category_membership-2",
          "pillar": "world_modeling",
          "subpillar": "type_category_membership",
          "question": "Which employees require access to the beta database for their data science models?",
          "answer_type": "short_answer",
          "gold_answer": "Lucas and James",
          "predicted_answer": "Lucas and James",
          "retrieved_context": [
            "User wants to ensure data science guys can access the database for their models.",
            "User feels Lucas and James will want to query GCP data for their models later",
            "Alex is asking how data scientists are doing with new models"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 337.92591094970703,
          "generation_latency_ms": 4103.653907775879,
          "total_latency_ms": 4441.579818725586
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the database that is running the v2.0.0-beta hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "User wants logs checked for Azure database running beta version",
            "User is asking if PrimaryDB6 is hosted on Azure.",
            "PrimaryDB7 is on Azure."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 682.793140411377,
          "generation_latency_ms": 3200.536012649536,
          "total_latency_ms": 3883.329153060913
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-4",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Despite earlier ambiguous logs, what version was PrimaryDB9 confirmed to be running during the final infrastructure audit?",
          "answer_type": "short_answer",
          "gold_answer": "v2.0.0-beta",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know what version PrimaryDB9 is running.",
            "User was looking at logs for PrimaryDB9 and is confused",
            "User is seeing weird logs on PrimaryDB9"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 607.8920364379883,
          "generation_latency_ms": 3583.146095275879,
          "total_latency_ms": 4191.038131713867
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-5",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific distraction caused the Product Designer to fail to deliver the UI assets on time?",
          "answer_type": "short_answer",
          "gold_answer": "His cat Luna",
          "predicted_answer": "Keeping the cat off the keyboard",
          "retrieved_context": [
            "User needs to fix issue fast",
            "Liam is the sales lead and is usually terrified of downtime.",
            "Liam gets nervous when the demo environment lags"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 626.1570453643799,
          "generation_latency_ms": 4380.219459533691,
          "total_latency_ms": 5006.376504898071
        },
        {
          "probe_id": "temporal_episodic-sequencing-6",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user ask for a reminder to buy cat treats before or after the final infrastructure audit?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants reminder to buy a lottery ticket later",
            "User wants a reminder to buy more coffee beans",
            "User wants to ask about the cat"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 636.6157531738281,
          "generation_latency_ms": 2942.5628185272217,
          "total_latency_ms": 3579.17857170105
        },
        {
          "probe_id": "preference_learning-induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What specific beverage does the user consistently consume before starting their morning work?",
          "answer_type": "short_answer",
          "gold_answer": "Espresso",
          "predicted_answer": "Espresso",
          "retrieved_context": [
            "User is on their third espresso.",
            "User wants to grab an extra espresso before the standup",
            "User wants a reminder to buy more coffee beans"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 636.7173194885254,
          "generation_latency_ms": 3710.0884914398193,
          "total_latency_ms": 4346.805810928345
        },
        {
          "probe_id": "preference_learning-explicit-8",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Does the user prefer to rollback the Azure database to v1.2.0 immediately following the audit?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to keep main Azure database on beta version unless alerts fire.",
            "User wants logs checked for Azure database running beta version",
            "User wants to check which version the main Azure database is running."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 684.2079162597656,
          "generation_latency_ms": 3111.5384101867676,
          "total_latency_ms": 3795.746326446533
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the current running version of the primary database hosted on GCP?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB6 is on GCP.",
            "User asks if Lucas and James are still running queries against GCP instance",
            "User wants to check PrimaryDB6 on GCP for cross-cloud latency issues."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 611.8760108947754,
          "generation_latency_ms": 3669.8946952819824,
          "total_latency_ms": 4281.770706176758
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Sales Lead's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Sales Lead gets stressed when smelling a big contract.",
            "User owes the sales lead lunch",
            "Sales Lead promised features that have not been built yet."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 796.5896129608154,
          "generation_latency_ms": 2811.1157417297363,
          "total_latency_ms": 3607.7053546905518
        },
        {
          "probe_id": "procedural_knowledge-task_tracking-11",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "What shopping task did the user ask the assistant to add to their list regarding the Product Designer's pet?",
          "answer_type": "short_answer",
          "gold_answer": "Buy treats for Luna",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to add 'buy milk' to their personal grocery list.",
            "User wants to ask about the cat",
            "User wants to add a task: Ask Oliver if he's bringing his cat to the office party."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 722.4998474121094,
          "generation_latency_ms": 3067.6350593566895,
          "total_latency_ms": 3790.134906768799
        },
        {
          "probe_id": "procedural_knowledge-task_tracking-12",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "What reminder did the user set for themselves before the standup meeting in the first recorded session?",
          "answer_type": "short_answer",
          "gold_answer": "Grab an extra espresso",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants reminder to grab lunch with Liam later to talk about quarterly targets.",
            "User wants a reminder to grab a sandwich before the 1 PM meeting.",
            "User wants a reminder to grab a coffee in 15 minutes."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 608.5307598114014,
          "generation_latency_ms": 3547.539234161377,
          "total_latency_ms": 4156.069993972778
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 9,
            "accuracy": 0.4444444444444444
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_008.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 74.5204689502716,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "What is the name of the individual referred to as the user's cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder asked about stability during the night.",
            "User's cofounder was asking about the analytics setup.",
            "User's cofounder is pushing hard for new reporting features."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 591.0446643829346,
          "generation_latency_ms": 3289.762496948242,
          "total_latency_ms": 3880.8071613311768
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which analytics service is hosted on a different cloud provider than the primary database?",
          "answer_type": "short_answer",
          "gold_answer": "AnalyticsEngine9",
          "predicted_answer": "AnalyticsEngine9",
          "retrieved_context": [
            "AnalyticsEngine9 is billed through a different provider than the rest of the stack",
            "User is asking whether the analytics setup is still multi-cloud.",
            "Alex wants to know where the analytics engines are hosted."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 570.8377361297607,
          "generation_latency_ms": 4259.485960006714,
          "total_latency_ms": 4830.323696136475
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud platform is the database instance that is signalling version v2.0.0-beta hosted?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is asking whether the beta instance runs in the same cloud environment as the load balancer.",
            "User is looking at the infrastructure dashboard for the main database and sees two different version numbers.",
            "User wants to be pinged if database version conflict causes latency on prod"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 604.30908203125,
          "generation_latency_ms": 4227.759122848511,
          "total_latency_ms": 4832.068204879761
        },
        {
          "probe_id": "declarative_reasoning-baseline_factual_recall-3",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What two specific version numbers are currently conflicting in the primary database logs?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User suspects a version mismatch in production database",
            "User is asking if the primary database is still version 1.2.0",
            "User is looking at the infrastructure dashboard for the main database and sees two different version numbers."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 840.3699398040771,
          "generation_latency_ms": 3540.0190353393555,
          "total_latency_ms": 4380.388975143433
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-4",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user mention fixing a leaky faucet before or after the discussion about Azure latency?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User has latency alert for analytics service on Microsoft Azure.",
            "Liam was complaining about latency in the multi-cloud split.",
            "User refers to Azure engine nine and notes that the local AWS engine is fast enough"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 580.8405876159668,
          "generation_latency_ms": 3621.9773292541504,
          "total_latency_ms": 4202.817916870117
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What domestic task did the user mention as the reason for their weekend feeling too short?",
          "answer_type": "short_answer",
          "gold_answer": "Fixing a leaky faucet",
          "predicted_answer": "fixing a leaky faucet",
          "retrieved_context": [
            "User spent half of the weekend fixing a leaky faucet.",
            "User was distracted for five minutes",
            "User needs to grab lunch soon."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 813.8201236724854,
          "generation_latency_ms": 2433.6371421813965,
          "total_latency_ms": 3247.457265853882
        },
        {
          "probe_id": "preference_learning-explicit_preferences-6",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "When requesting a reminder for coffee beans, what specific variety did the user specify?",
          "answer_type": "short_answer",
          "gold_answer": "Dark roast",
          "predicted_answer": "dark roast",
          "retrieved_context": [
            "User wants a reminder to pick up dark roast coffee beans on their way home tonight.",
            "User wants to buy dark roast coffee beans later",
            "User wants a reminder to grab a double espresso before the meeting"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 338.0017280578613,
          "generation_latency_ms": 2746.1819648742676,
          "total_latency_ms": 3084.183692932129
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "How does the user characterize the billing situation resulting from the multi-cloud setup?",
          "answer_type": "short_answer",
          "gold_answer": "Fragmented",
          "predicted_answer": "fragmented",
          "retrieved_context": [
            "User is asking whether the analytics setup is still multi-cloud.",
            "User is referring to a multi-cloud experiment",
            "User is questioning why billing is fragmented."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 533.4610939025879,
          "generation_latency_ms": 2433.701753616333,
          "total_latency_ms": 2967.162847518921
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the pet belonging to the Frontend Lead?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex asks who is leading the frontend team.",
            "User wants assistant to ping the Frontend Lead.",
            "Liam is in the middle of a frontend overhaul"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 496.9916343688965,
          "generation_latency_ms": 3237.5545501708984,
          "total_latency_ms": 3734.546184539795
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What version of software is the Load Balancer currently reporting?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants assistant to check current traffic on main load balancer",
            "User wants to know how the load balancer is handling the database glitch",
            "User is asking whether the beta instance runs in the same cloud environment as the load balancer."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 574.0396976470947,
          "generation_latency_ms": 3402.097702026367,
          "total_latency_ms": 3976.137399673462
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What structural factor did the assistant identify as the cause of the latency on the Azure instance?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-region calls",
          "predicted_answer": "multi-cloud split",
          "retrieved_context": [
            "User has latency alert for analytics service on Microsoft Azure.",
            "User refers to Azure engine nine and notes that the local AWS engine is fast enough",
            "Liam was complaining about latency in the multi-cloud split."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 576.7736434936523,
          "generation_latency_ms": 3013.7434005737305,
          "total_latency_ms": 3590.517044067383
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-11",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "What action did the assistant suggest to address the latency issues observed by the cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Draft migration plan",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder complained about latency.",
            "User's cofounder sent a message this morning about latency spikes.",
            "Alex needs to coordinate with the frontend team about latency."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 607.4566841125488,
          "generation_latency_ms": 4298.521518707275,
          "total_latency_ms": 4905.978202819824
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 10,
            "accuracy": 0.4
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_009.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 27,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 71.0006959438324,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual referred to by the user as 'my cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Lucas",
          "predicted_answer": "Lucas",
          "retrieved_context": [
            "Alex asks if cofounder is around.",
            "User's cofounder walked in looking frantic.",
            "User's cofounder is the CEO and is stressing about the quarterly board meeting."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 709.784984588623,
          "generation_latency_ms": 2630.5508613586426,
          "total_latency_ms": 3340.3358459472656
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which cloud provider hosts the database service that the Backend Lead named Oliver is concerned about?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "AWS",
          "retrieved_context": [
            "User says Oliver manages PrimaryDB7 and AuthService1 on Azure.",
            "User reports Liam is worried about the new database instance hosted on AWS.",
            "Alex asks if primary databases are on the same provider."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 667.1032905578613,
          "generation_latency_ms": 3165.790319442749,
          "total_latency_ms": 3832.8936100006104
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Identify the team member who holds the same job title as the owner of the cat named Luna.",
          "answer_type": "short_answer",
          "gold_answer": "Oliver",
          "predicted_answer": "Backend lead",
          "retrieved_context": [
            "Liam loves the cat Luna",
            "User saw a picture of a cat named Luna on the general Slack channel earlier.",
            "User's cat Luna is fine but tearing up furniture."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 595.7114696502686,
          "generation_latency_ms": 3835.890531539917,
          "total_latency_ms": 4431.602001190186
        },
        {
          "probe_id": "declarative_reasoning-state_tracking-2",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What two specific version numbers are currently detected running simultaneously on the AWS database?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "The database in AWS has weird versioning flags.",
            "AWS database reports version v1.2.0 and is testing v2.0.0-beta; dashboard reports PrimaryDB8 running v1.2.0.",
            "User believes the eighth primary database on AWS may be running stable 1.2.0 or beta."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 703.838586807251,
          "generation_latency_ms": 2597.6269245147705,
          "total_latency_ms": 3301.4655113220215
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Based on the user's schedule, which task occurs earlier in the day: approving the budget report or picking up dry cleaning?",
          "answer_type": "short_answer",
          "gold_answer": "Approving budget report",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "The user wants a reminder to pick up dry cleaning at 5 PM",
            "User wants to pull up their schedule for the afternoon.",
            "User wants a reminder to pick up dry cleaning at 6 PM."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 344.88964080810547,
          "generation_latency_ms": 3676.2239933013916,
          "total_latency_ms": 4021.113634109497
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-2",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What technical issue is identified as the cause of the latency on the PrimaryDB8 instance?",
          "answer_type": "short_answer",
          "gold_answer": "Conflicting versions",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB8 is experiencing lag on an Amazon-hosted instance.",
            "The user is seeing weird logs for PrimaryDB8",
            "User reports latency on the main database on Amazon."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 587.0852470397949,
          "generation_latency_ms": 2552.3688793182373,
          "total_latency_ms": 3139.454126358032
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's reaction to the beta push, do they currently prioritize rapid deployment or production stability?",
          "answer_type": "short_answer",
          "gold_answer": "Production stability",
          "predicted_answer": "Production stability",
          "retrieved_context": [
            "I told the team not to push the beta to prod yet.",
            "User intends to ask Lucas about beta deployment authorization.",
            "User believes the eighth primary database on AWS may be running stable 1.2.0 or beta."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 362.28179931640625,
          "generation_latency_ms": 3450.3133296966553,
          "total_latency_ms": 3812.5951290130615
        },
        {
          "probe_id": "preference_learning-explicit_preferences-2",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What beverage does the user explicitly rely on to 'wake up properly' in the morning?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "coffee",
          "retrieved_context": [
            "User is settling in with a coffee and trying to wake up properly.",
            "User hasn't had coffee yet.",
            "User has had third coffee of the day."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 675.0798225402832,
          "generation_latency_ms": 2483.5736751556396,
          "total_latency_ms": 3158.653497695923
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the specific running version number of the database hosted on Azure?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "AWS database reports version v1.2.0 and is testing v2.0.0-beta; dashboard reports PrimaryDB8 running v1.2.0.",
            "User wants to check the versions of the databases.",
            "User wants to know the status of the database hosted on AWS."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 357.58447647094727,
          "generation_latency_ms": 2738.5125160217285,
          "total_latency_ms": 3096.096992492676
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-2",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Product Designer's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know who is handling chief executive duties and who is owning product design.",
            "User will ask Emma about new product sketches.",
            "User asks if Emma sent new product sketches."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 330.1887512207031,
          "generation_latency_ms": 4331.831693649292,
          "total_latency_ms": 4662.020444869995
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What specific data does the user typically request to prepare for a strategy meeting with the CEO?",
          "answer_type": "short_answer",
          "gold_answer": "Latest metrics",
          "predicted_answer": "Quarterly projections.",
          "retrieved_context": [
            "User's cofounder is asking about quarterly projections.",
            "User's cofounder is the CEO and is stressing about the quarterly board meeting.",
            "User wants to get organized before the standup."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 596.099853515625,
          "generation_latency_ms": 3662.975788116455,
          "total_latency_ms": 4259.07564163208
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-2",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What was the user's explicit instruction regarding the deployment of the beta version to production?",
          "answer_type": "short_answer",
          "gold_answer": "Do not push",
          "predicted_answer": "Not to push the beta to prod yet.",
          "retrieved_context": [
            "I told the team not to push the beta to prod yet.",
            "User intends to ask Lucas about beta deployment authorization.",
            "User believes Oliver pushed the beta version by mistake."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 1095.6878662109375,
          "generation_latency_ms": 2510.4777812957764,
          "total_latency_ms": 3606.165647506714
        }
      ],
      "summary": {
        "overall_accuracy": 0.5833333333333334,
        "total_score": 7,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 10,
            "accuracy": 0.5
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_010.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 26,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 68.67827272415161,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which cloud provider hosts the service managed by the Backend Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to consolidate cloud infrastructure.",
            "User wants to start with backend team and asks if the lead is around.",
            "User says the Backend Lead is sharp"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 365.581750869751,
          "generation_latency_ms": 3605.2300930023193,
          "total_latency_ms": 3970.8118438720703
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Who is the cofounder concerned about the recent spike in cloud costs?",
          "answer_type": "short_answer",
          "gold_answer": "Charlotte",
          "predicted_answer": "User's cofounder",
          "retrieved_context": [
            "User's cofounder asked why cloud bill is fragmented.",
            "User's cofounder is asking why Azure bill spiked this month.",
            "User is concerned about multi-cloud headache"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 674.0243434906006,
          "generation_latency_ms": 2376.0504722595215,
          "total_latency_ms": 3050.074815750122
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Backend Lead",
          "predicted_answer": "Backend Lead",
          "retrieved_context": [
            "User asks if Elijah's cat is named Luna.",
            "Elijah's cat Luna jumped on his desk.",
            "User reports that Luna is fine but grumpy."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 388.22388648986816,
          "generation_latency_ms": 3960.822343826294,
          "total_latency_ms": 4349.046230316162
        },
        {
          "probe_id": "declarative_reasoning-state_tracking-1",
          "pillar": "declarative_reasoning",
          "subpillar": "task_state_tracking",
          "question": "Which two version numbers are simultaneously reported by the sixth cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know the current active version on the sixth cache layer",
            "User is looking at the dashboard for CacheLayer6 and notices version numbers look weird.",
            "User wants information about the sixth cache layer"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 644.3970203399658,
          "generation_latency_ms": 2559.643268585205,
          "total_latency_ms": 3204.040288925171
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-0",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What specific activity by the Data Scientist was identified as the cause of the Azure bill spike?",
          "answer_type": "short_answer",
          "gold_answer": "Running heavy models",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder is asking why Azure bill spiked this month.",
            "Will ran heavy models on Azure last week.",
            "User's cofounder asked why cloud bill is fragmented."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 666.6688919067383,
          "generation_latency_ms": 2559.2143535614014,
          "total_latency_ms": 3225.8832454681396
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-1",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "When the user requested a ticket be created regarding the deployment manifest, who was the intended recipient?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Elijah",
          "retrieved_context": [
            "User plans to have Elijah look at the deployment manifest.",
            "User was talking to the backend lead earlier who is convinced there is a deployment mismatch.",
            "User needs to pull Elijah into a sync with cofounder later regarding the roadmap."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 442.5380229949951,
          "generation_latency_ms": 2700.1736164093018,
          "total_latency_ms": 3142.711639404297
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What beverage does the user consistently request before morning meetings?",
          "answer_type": "short_answer",
          "gold_answer": "Espresso",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "User wants another espresso before morning standup.",
            "User needs to grab a coffee before falling asleep.",
            "User is grabbing a coffee before the standup."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 453.44996452331543,
          "generation_latency_ms": 4159.544229507446,
          "total_latency_ms": 4612.994194030762
        },
        {
          "probe_id": "preference_learning-belief_revision-1",
          "pillar": "preference_learning",
          "subpillar": "belief_revision",
          "question": "What is the final confirmed time for the dentist appointment, overriding the initially suggested time?",
          "answer_type": "short_answer",
          "gold_answer": "3 PM",
          "predicted_answer": "3 PM",
          "retrieved_context": [
            "User has a dentist appointment at 3 PM",
            "User wants a reminder set for dentist appointment at 3 PM",
            "User wants reminder to pick up sandwich before 1:00 PM meeting"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 561.5334510803223,
          "generation_latency_ms": 2811.1650943756104,
          "total_latency_ms": 3372.6985454559326
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific software version is CacheLayer3 currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is unsure whether CacheLayer6 is running the stable release or the beta.",
            "User is interested in CacheLayer1 and CacheLayer3.",
            "User wants to know if cache layers 1 and 3 are affected"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 341.34697914123535,
          "generation_latency_ms": 2569.0736770629883,
          "total_latency_ms": 2910.4206562042236
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who is the current Project Manager for the Nebula organization?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder wants to review quarterly roadmap",
            "User wants to start with backend team and asks if the lead is around.",
            "User asks if Noah sent updated wireframes"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 346.8585014343262,
          "generation_latency_ms": 3693.373203277588,
          "total_latency_ms": 4040.231704711914
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-0",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the discussion about the Azure bill spike occur before or after the user first noticed the version conflict on CacheLayer6?",
          "answer_type": "short_answer",
          "gold_answer": "After",
          "predicted_answer": "Before",
          "retrieved_context": [
            "User's cofounder is asking why Azure bill spiked this month.",
            "User feels the caching layers are split between AWS and Azure.",
            "User wants to check the new caching layer deployed to Azure running the beta version."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 614.3043041229248,
          "generation_latency_ms": 3033.3001613616943,
          "total_latency_ms": 3647.604465484619
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What action by the Backend Lead likely caused the split versioning on the Azure cache instance?",
          "answer_type": "short_answer",
          "gold_answer": "Leaving canary deployment active",
          "predicted_answer": "deployment mismatch",
          "retrieved_context": [
            "User feels the caching layers are split between AWS and Azure.",
            "User wants to check the new caching layer deployed to Azure running the beta version.",
            "AnalyticsEngine6 is next to CacheLayer3 in Azure cluster"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 584.7909450531006,
          "generation_latency_ms": 2883.8436603546143,
          "total_latency_ms": 3468.634605407715
        }
      ],
      "summary": {
        "overall_accuracy": 0.4166666666666667,
        "total_score": 5,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 3,
            "count": 10,
            "accuracy": 0.3
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_011.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 28,
      "num_probes": 7,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 38.19324541091919,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual referred to as the user's cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder is breathing down User's neck about reliability today.",
            "User's cofounder is pestering about the new beta.",
            "User is preparing for a sync with cofounder later."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 380.86748123168945,
          "generation_latency_ms": 2733.8786125183105,
          "total_latency_ms": 3114.74609375
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the name of the pet belonging to the engineer currently debugging the Amazon infrastructure?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Mia is debugging Amazon infrastructure",
            "User wants to check the health of the Amazon setup.",
            "DevOps lead mentioned taking cat Luna to the vet this morning"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 514.4863128662109,
          "generation_latency_ms": 2996.603488922119,
          "total_latency_ms": 3511.08980178833
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-2",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific missing asset is causing the Sales Lead to panic about the TechGlobal deal?",
          "answer_type": "short_answer",
          "gold_answer": "New dashboard",
          "predicted_answer": "new dashboard",
          "retrieved_context": [
            "The sales lead is worried",
            "Lucas is freaking out about closing the TechGlobal deal without the new dashboard",
            "User thinks Sales Lead will panic."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 686.1801147460938,
          "generation_latency_ms": 2626.0902881622314,
          "total_latency_ms": 3312.270402908325
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-3",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific task is the Data Scientist, Sophia, currently working on?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "data modeling",
          "retrieved_context": [
            "Sophia is deep in data modeling.",
            "User thinks Sophia might be running a data experiment on the load balancer",
            "User says User's Data Scientist takes time."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 291.95618629455566,
          "generation_latency_ms": 2322.0605850219727,
          "total_latency_ms": 2614.0167713165283
        },
        {
          "probe_id": "preference_learning-explicit_preferences-4",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What beverage does the user repeatedly request in the morning sessions?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "User needs a double shot of espresso this morning",
            "User needs another coffee because the weather is putting User to sleep.",
            "User wants to grab a coffee before falling asleep"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 288.5761260986328,
          "generation_latency_ms": 3208.165168762207,
          "total_latency_ms": 3496.74129486084
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-5",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What versions are currently conflicting on LoadBalancer8 according to the latest status check?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "stable v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "User wants to inspect LoadBalancer8 on Google's platform, which reports conflicting versions: stable v1.2.0 and v2.0.0-beta, and needs to determine if it is routing traffic correctly.",
            "User wants status on load balancer Mia was tweaking.",
            "User asks if the load balancer is finally updated."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 660.4881286621094,
          "generation_latency_ms": 2634.3722343444824,
          "total_latency_ms": 3294.860363006592
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-6",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What specific metric did the assistant check to verify the connection between the AWS auth service and the Google database?",
          "answer_type": "short_answer",
          "gold_answer": "Latency",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User has an authentication service running on Amazon and wants a quick look at it.",
            "User wants to check the connection between AuthService4 and the primary database.",
            "Mia needs to ensure they communicate with Google Cloud components correctly"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 393.5699462890625,
          "generation_latency_ms": 3764.0018463134766,
          "total_latency_ms": 4157.571792602539
        }
      ],
      "summary": {
        "overall_accuracy": 0.42857142857142855,
        "total_score": 3,
        "count": 7,
        "by_answer_type": {
          "short_answer": {
            "total": 3,
            "count": 6,
            "accuracy": 0.5
          },
          "abstain": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_012.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 28,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 9.972140550613403,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does system:cachelayer_8 hosted on?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google Cloud",
          "retrieved_context": [
            "User wants to know about caching layer 7 and 8 behavior, including latency between them, and that CacheLayer8 is on GCP.",
            "User wants to know if caching layer 7 still runs on old provider: it is staying on AWS and causing workflow slowdown for Sophia and Mia.",
            "User asks whether the rest of the stack is on Google Cloud, specifically cache layers, and that LoadBalancer6, AnalyticsEngine9, and CacheLayer8 are on Google Cloud."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 616.4031028747559,
          "generation_latency_ms": 2211.5273475646973,
          "total_latency_ms": 2827.930450439453
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User will grab a sandwich before next meeting.",
            "User asks if design team is free to chat",
            "User knows Noah said he was going to start the canary deployment this morning"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 637.3646259307861,
          "generation_latency_ms": 2130.6099891662598,
          "total_latency_ms": 2767.974615097046
        }
      ],
      "summary": {
        "overall_accuracy": 1.0,
        "total_score": 2,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_013.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 9.580780506134033,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does person:lucas has role?",
          "answer_type": "short_answer",
          "gold_answer": "Backend Lead",
          "predicted_answer": "backend lead",
          "retrieved_context": [
            "User is asking about Lucas's status",
            "Lucas is the backend lead.",
            "User talked to Lucas earlier"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 347.61691093444824,
          "generation_latency_ms": 2104.8126220703125,
          "total_latency_ms": 2452.4295330047607
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asked for a recipe yesterday.",
            "User asks if James checked in yet.",
            "User asks if Elijah has run new models yet."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 314.05186653137207,
          "generation_latency_ms": 2750.7033348083496,
          "total_latency_ms": 3064.7552013397217
        }
      ],
      "summary": {
        "overall_accuracy": 1.0,
        "total_score": 2,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_014.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 27,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 10.275998592376709,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does person:charlotte has role?",
          "answer_type": "short_answer",
          "gold_answer": "CEO",
          "predicted_answer": "CEO role",
          "retrieved_context": [
            "User had a call with Charlotte.",
            "Charlotte is leaning into the CEO role and wants everything faster.",
            "User says Charlotte wants to go over the quarterly goals."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 385.02979278564453,
          "generation_latency_ms": 2427.990674972534,
          "total_latency_ms": 2813.0204677581787
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks if it's raining outside.",
            "Alex is asking whether the recipe he requested yesterday was found.",
            "User wants reminder to ask Oliver about photo he posted on Slack"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 297.8980541229248,
          "generation_latency_ms": 2708.0729007720947,
          "total_latency_ms": 3005.9709548950195
        }
      ],
      "summary": {
        "overall_accuracy": 1.0,
        "total_score": 2,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_015.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 28,
      "num_probes": 11,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 66.64568018913269,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the team member responsible for the 'messy' deployment scripts mentioned by the user?",
          "answer_type": "short_answer",
          "gold_answer": "Lucas",
          "predicted_answer": "Lucas",
          "retrieved_context": [
            "User says Lucas was messing with deployment scripts",
            "User wants to ping Lucas, who is responsible for DevOps and likely triggered the update and forgot to clean it up.",
            "User will yell at the DevOps lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 628.4830570220947,
          "generation_latency_ms": 2688.82155418396,
          "total_latency_ms": 3317.3046112060547
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which cloud provider hosts the database service that is NOT co-located with the Auth service?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "User asks if auth service and second primary database are in same region as load balancer.",
            "The main load balancer and the auth service are in Google's cloud",
            "User wants to confirm where Auth Service 6 and DB 2 are located"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 990.2260303497314,
          "generation_latency_ms": 4055.837392807007,
          "total_latency_ms": 5046.063423156738
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Based on the user's diagnosis, which specific database service is likely contributing to the latency reported by the cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "PrimaryDB7",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User thinks cross-cloud latency hitting cache is cause of sales dashboard slowness.",
            "Sophia is breathing down User's neck about latency issues",
            "Lucas is stressed about latency between clouds"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 642.6889896392822,
          "generation_latency_ms": 3530.8473110198975,
          "total_latency_ms": 4173.53630065918
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-4",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What is the confirmed operational strategy for LoadBalancer9's versioning, clarifying the initial ambiguity?",
          "answer_type": "short_answer",
          "gold_answer": "Canary testing",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to check the version reported by LoadBalancer9 and feels an update might have been missed; User says the beta version was Lucas's experiment; User thinks the load balancer is the issue; Logs show conflicting version numbers; Lucas mentioned a version mismatch on the load balancer",
            "LoadBalancer9 is running a beta version in production.",
            "User asks what version of the load balancer we are on"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 619.1072463989258,
          "generation_latency_ms": 3803.597927093506,
          "total_latency_ms": 4422.705173492432
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the discussion about the hybrid cloud latency occur before or after the user asked to ping the DevOps lead regarding the alerts?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User feels latency related to hybrid cloud setup",
            "User wants a ticket drafted to investigate cross-cloud latency.",
            "Lucas is stressed about latency between clouds"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 696.6090202331543,
          "generation_latency_ms": 2893.8045501708984,
          "total_latency_ms": 3590.4135704040527
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-6",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific architectural factor did the user identify as the cause for the dashboard latency around 9 AM?",
          "answer_type": "short_answer",
          "gold_answer": "Hybrid cloud setup",
          "predicted_answer": "cross-cloud latency hitting cache",
          "retrieved_context": [
            "Sophia asked about dashboard latency earlier this morning",
            "Latency spiking mostly around 9 AM",
            "User believes the frontend team is enjoying the latency."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 537.4650955200195,
          "generation_latency_ms": 3411.1533164978027,
          "total_latency_ms": 3948.6184120178223
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-7",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific version number is the CacheLayer4 service currently running?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "CacheLayer4 is up.",
            "User wants to check Azure caching layer number four to ensure it is not cold.",
            "User asks if cache layer near Azure instance"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 648.8955020904541,
          "generation_latency_ms": 2987.071752548218,
          "total_latency_ms": 3635.967254638672
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Sales Lead's pet?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Frontend lead loves cat Luna.",
            "The sales lead is stressed",
            "User does not want to inform the Sales Lead yet"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 767.662525177002,
          "generation_latency_ms": 3469.766139984131,
          "total_latency_ms": 4237.428665161133
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-9",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What technical configuration has been identified as problematic for latency when running the primary database?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-cloud hosting",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Lucas is stressed about latency between clouds",
            "Alex is experiencing weird latency on LoadBalancer9",
            "Sophia is breathing down User's neck about latency issues"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 615.2019500732422,
          "generation_latency_ms": 3934.2403411865234,
          "total_latency_ms": 4549.442291259766
        },
        {
          "probe_id": "preference_learning-preference_drift-10",
          "pillar": "preference_learning",
          "subpillar": "preference_drift",
          "question": "At what time does the user currently want to be reminded about their dry cleaning, considering their most recent request?",
          "answer_type": "short_answer",
          "gold_answer": "5:30 PM",
          "predicted_answer": "5 PM",
          "retrieved_context": [
            "User wants a reminder to pick up dry cleaning at 5 PM",
            "Alex wants reminder to pick up dry cleaning at 5 PM",
            "User wants reminder to buy milk later."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 642.8463459014893,
          "generation_latency_ms": 2451.531410217285,
          "total_latency_ms": 3094.3777561187744
        },
        {
          "probe_id": "preference_learning-explicit_preferences-11",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "How does the user prefer the assistant to handle communication with the DevOps lead when he is offline?",
          "answer_type": "short_answer",
          "gold_answer": "Ping when active",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User will talk to DevOps guy about following protocol.",
            "User will yell at the DevOps lead",
            "User will catch DevOps lead at lunch."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 370.985746383667,
          "generation_latency_ms": 2688.4779930114746,
          "total_latency_ms": 3059.4637393951416
        }
      ],
      "summary": {
        "overall_accuracy": 0.18181818181818182,
        "total_score": 2,
        "count": 11,
        "by_answer_type": {
          "short_answer": {
            "total": 2,
            "count": 11,
            "accuracy": 0.18181818181818182
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_016.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 27,
      "num_probes": 13,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 75.06032609939575,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which specific system is the user referring to as the 'traffic manager in our Google environment'?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer2",
          "predicted_answer": "LoadBalancer2",
          "retrieved_context": [
            "Elijah and James report weird behavior with LoadBalancer2, the traffic manager in the Google environment.",
            "The user wants to look at load balancer on GCP.",
            "User thinks GCP ingress is having an identity crisis."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 287.52851486206055,
          "generation_latency_ms": 2517.5392627716064,
          "total_latency_ms": 2805.067777633667
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Who are the two individuals identified as arguing over the button push for the beta release?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah and James",
          "predicted_answer": "Elijah and James",
          "retrieved_context": [
            "User told Elijah not to push beta to prod yet and expects the system to be locked to the stable release, and will slack him.",
            "Elijah and James are arguing over who pushed the button.",
            "Elijah insisted on deploying v2.0.0-beta alongside v1.2.0, and the beta version was pushed."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 379.8692226409912,
          "generation_latency_ms": 2516.134262084961,
          "total_latency_ms": 2896.003484725952
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person who kept the leadership team late going over quarterly strategy?",
          "answer_type": "short_answer",
          "gold_answer": "CEO",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Noah kept the leadership team late last night going over the quarterly strategy.",
            "Cofounder is pacing around the office asking about uptime and stressing about the data pipeline for the board meeting.",
            "User has a cofounder who sent an email about quarterly targets"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 363.43884468078613,
          "generation_latency_ms": 2809.4494342803955,
          "total_latency_ms": 3172.8882789611816
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-4",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "On which cloud provider is the service hosted that the user described as the 'outlier on Microsoft's cloud'?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "Mia thinks issue might be with authentication service on Microsoft's cloud.",
            "User is concerned about cross-cloud latency issues between main database and authentication service",
            "Analytics engine and other load balancer are on Amazon."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 295.4864501953125,
          "generation_latency_ms": 2619.2891597747803,
          "total_latency_ms": 2914.775609970093
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-5",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What two specific software versions are currently conflicting on the GCP load balancer?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "User thinks there's a version conflict reported by the dashboard on the load balancer hosted on Google's cloud.",
            "User's LoadBalancer2 is hosted on GCP for a legacy reason.",
            "The user wants to look at load balancer on GCP."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 364.5670413970947,
          "generation_latency_ms": 2856.839418411255,
          "total_latency_ms": 3221.4064598083496
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-6",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "According to the infrastructure review discussion, why is latency expected between the primary database and the authentication service?",
          "answer_type": "short_answer",
          "gold_answer": "Hosted on different clouds",
          "predicted_answer": "Cross-cloud issues",
          "retrieved_context": [
            "User is concerned about cross-cloud latency issues between main database and authentication service",
            "Latency between Google front-end and primarydb3 is noticeable.",
            "User's primary DB is on Amazon's infrastructure and wants to ensure latency isn't spiking"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 379.2598247528076,
          "generation_latency_ms": 4224.569082260132,
          "total_latency_ms": 4603.828907012939
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-7",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What personal task did the user ask to be reminded of during the conversation about cross-cloud latency?",
          "answer_type": "short_answer",
          "gold_answer": "Call dentist",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is concerned about cross-cloud latency issues between main database and authentication service",
            "User's primary DB is on Amazon's infrastructure and wants to ensure latency isn't spiking",
            "The user is seeing weird latency."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 642.1298980712891,
          "generation_latency_ms": 3908.0986976623535,
          "total_latency_ms": 4550.228595733643
        },
        {
          "probe_id": "preference_learning-preference_induction-8",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the assistant's preparation for the meeting, what type of infrastructure breakdown does the cofounder usually prefer?",
          "answer_type": "short_answer",
          "gold_answer": "High-level summary",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is preparing for an infrastructure review with cofounder later today",
            "Cofounder is pacing around the office asking about uptime and stressing about the data pipeline for the board meeting.",
            "Noah is concerned about infrastructure costs."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 678.1303882598877,
          "generation_latency_ms": 3122.1492290496826,
          "total_latency_ms": 3800.2796173095703
        },
        {
          "probe_id": "preference_learning-preference_scope-9",
          "pillar": "preference_learning",
          "subpillar": "preference_scope",
          "question": "Does the user have a stated preference for which cloud provider to review first during infrastructure checks?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Noah is worried about multi-cloud sprawl",
            "User wants to check the cloud provider for LoadBalancer2.",
            "User is preparing for an infrastructure review with cofounder later today"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 546.2343692779541,
          "generation_latency_ms": 3459.0377807617188,
          "total_latency_ms": 4005.272150039673
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the current running version of the authentication service on Azure?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "LB8 is fine; AuthService3 is on Azure and is not working.",
            "Mia thinks issue might be with authentication service on Microsoft's cloud.",
            "The user wants a reminder to check the Azure bill for the auth service later."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 607.9483032226562,
          "generation_latency_ms": 3389.1947269439697,
          "total_latency_ms": 3997.143030166626
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-11",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who is the team lead for the Analytics Engine?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know where analytics engine is located",
            "AnalyticsEngine7 is hosted on Amazon",
            "primarydb3 and analyticsengine7 are sitting next to each other."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 600.4180908203125,
          "generation_latency_ms": 3012.7570629119873,
          "total_latency_ms": 3613.1751537323
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-12",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "What specific action did the assistant propose to help resolve the confusion while the DevOps team argued?",
          "answer_type": "short_answer",
          "gold_answer": "Flag the discrepancy",
          "predicted_answer": "Sync up on deployment schedules",
          "retrieved_context": [
            "User says DevOps guys usually catch that stuff.",
            "User wants to ping the DevOps crew and needs Elijah or James to look at the GCP box immediately.",
            "User plans to tell cofounder to relax."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 646.0058689117432,
          "generation_latency_ms": 4315.61279296875,
          "total_latency_ms": 4961.618661880493
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-13",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What is the user's routine for preparing for meetings with the cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Review infrastructure overview",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Cofounder is pacing around the office asking about uptime and stressing about the data pipeline for the board meeting.",
            "User is preparing for an infrastructure review with cofounder later today",
            "User plans to tell cofounder to relax."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 501.67202949523926,
          "generation_latency_ms": 3185.474395751953,
          "total_latency_ms": 3687.1464252471924
        }
      ],
      "summary": {
        "overall_accuracy": 0.38461538461538464,
        "total_score": 5,
        "count": 13,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 12,
            "accuracy": 0.4166666666666667
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 3,
            "accuracy": 0.6666666666666666
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_017.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 34,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 67.62503480911255,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual referred to as 'my cofounder' by the user?",
          "answer_type": "short_answer",
          "gold_answer": "Olivia",
          "predicted_answer": "Olivia",
          "retrieved_context": [
            "User says cofounder is asking about auth services 6 and 7",
            "User had a strategy session with cofounder",
            "User's cofounder asked about the cloud spread."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 516.5421962738037,
          "generation_latency_ms": 2892.418622970581,
          "total_latency_ms": 3408.9608192443848
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Who shares the Backend Lead responsibilities with the owner of the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "Luna is practically a mascot.",
            "User thinks being a backend lead is a headache.",
            "Will is one of the Backend Leads."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 351.0005474090576,
          "generation_latency_ms": 2751.230239868164,
          "total_latency_ms": 3102.2307872772217
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service hosted that is currently reporting conflicting versions v1.2.0 and v2.0.0-beta?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know the hosting location of AuthService6 and AuthService7.",
            "User knows that one authentication service is not on Amazon.",
            "User is asking whether the system is running on Google infrastructure."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 426.7089366912842,
          "generation_latency_ms": 2692.047119140625,
          "total_latency_ms": 3118.756055831909
        },
        {
          "probe_id": "declarative_reasoning-baseline_factual_recall-3",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "Which cloud provider hosts the primary database mentioned during the infrastructure map review?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "PrimaryDB5 is hosted on Azure to use Azure credits.",
            "User is asking whether PrimaryDB5 is still performing well on Microsoft's infrastructure.",
            "User is asking whether the system is running on Google infrastructure."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 357.9576015472412,
          "generation_latency_ms": 2933.4940910339355,
          "total_latency_ms": 3291.4516925811768
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "According to the user, what was the specific cause of Will's distraction during their earlier call?",
          "answer_type": "short_answer",
          "gold_answer": "Luna jumping on desk",
          "predicted_answer": "His cat",
          "retrieved_context": [
            "User was on a call with Will earlier.",
            "User attributes issue to Will, who was supposed to test upgrade, and believes he got distracted by cat.",
            "User needs to talk to Will about that"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 572.9959011077881,
          "generation_latency_ms": 2288.5074615478516,
          "total_latency_ms": 2861.5033626556396
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "During the conversation where the user requested a 'sanity check' on the infrastructure map, where did the assistant locate AuthService6 and AuthService7?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "AWS",
          "retrieved_context": [
            "User wants to know the hosting location of AuthService6 and AuthService7.",
            "User wants to check AuthService1.",
            "User acknowledges AuthService6 and AuthService7 are hosted on AWS."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 349.8680591583252,
          "generation_latency_ms": 3913.084030151367,
          "total_latency_ms": 4262.952089309692
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What beverage does the user imply they need before dealing with infrastructure latency or complex messes?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "User thinks James is complaining about latency.",
            "User is distracted by infrastructure mess",
            "Latency is problematic"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 1456.543207168579,
          "generation_latency_ms": 2873.544931411743,
          "total_latency_ms": 4330.088138580322
        },
        {
          "probe_id": "preference_learning-explicit_preferences-7",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Does the user explicitly state a preference for using GCP over AWS for authentication services?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "User is asking which auth service is on GCP.",
            "User knows that one authentication service is not on Amazon.",
            "User acknowledges AuthService6 and AuthService7 are hosted on AWS."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 374.0260601043701,
          "generation_latency_ms": 4234.8761558532715,
          "total_latency_ms": 4608.902215957642
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the final score of the game the user missed last night?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User fell asleep before the end of the game last night.",
            "User asks if the Giants won last night.",
            "User thinks James is complaining about latency."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 571.3744163513184,
          "generation_latency_ms": 2742.6726818084717,
          "total_latency_ms": 3314.04709815979
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the development environment for the Frontend Lead?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Frontend Lead is probably testing the beta integration today.",
            "User wants to know the hosting location of AuthService6 and AuthService7.",
            "User is asking whether the system is running on Google infrastructure."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 362.3342514038086,
          "generation_latency_ms": 3372.678279876709,
          "total_latency_ms": 3735.0125312805176
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What general observation did the assistant make about the difficulty of working from home when discussing Will's situation?",
          "answer_type": "short_answer",
          "gold_answer": "Challenging with a cat",
          "predicted_answer": "Will's cat kept walking on his keyboard this morning.",
          "retrieved_context": [
            "User attributes issue to Will, who was supposed to test upgrade, and believes he got distracted by cat.",
            "Will was supposed to handle the migration",
            "User is asking if Will is around."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 726.4404296875,
          "generation_latency_ms": 3130.664587020874,
          "total_latency_ms": 3857.105016708374
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-11",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What is the documented procedure for migrating AuthService1 from GCP to AWS?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User acknowledges AuthService6 and AuthService7 are hosted on AWS.",
            "User is asking which auth service is on GCP.",
            "AuthService1 is located in GCP."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 671.738862991333,
          "generation_latency_ms": 2399.834394454956,
          "total_latency_ms": 3071.573257446289
        }
      ],
      "summary": {
        "overall_accuracy": 0.75,
        "total_score": 9,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 8,
            "accuracy": 0.625
          },
          "boolean": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 3,
            "count": 3,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_018.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 28,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 70.07631373405457,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user's cofounder that was concerned about the AWS credits?",
          "answer_type": "short_answer",
          "gold_answer": "Charlotte",
          "predicted_answer": "CEO",
          "retrieved_context": [
            "User's cofounder was asking about AWS credits.",
            "User thinks cofounder is probably swamped with meetings",
            "User will handle cofounder"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 387.6967430114746,
          "generation_latency_ms": 3189.5313262939453,
          "total_latency_ms": 3577.22806930542
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the name of the pet belonging to the Frontend Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "User finds frontend lead obsessed with a pet.",
            "Lucas is the Frontend Lead and is always on camera.",
            "User asks if the frontend lead is available"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 716.439962387085,
          "generation_latency_ms": 2295.9377765655518,
          "total_latency_ms": 3012.3777389526367
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Does the service currently running v2.0.0-beta reside on the same cloud provider as PrimaryDB5?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants only PrimaryDB5",
            "User feels primary databases are hosted on a different provider.",
            "PrimaryDB5 and PrimaryDB8 are hosted on Google's cloud."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 408.0817699432373,
          "generation_latency_ms": 2825.3283500671387,
          "total_latency_ms": 3233.410120010376
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "According to the latest diagnostics, is CacheLayer7 running a single stable version?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants a quick status check of CacheLayer7 and to know which version it is running.",
            "User sees weird telemetry on CacheLayer7 and wants to know the live version on that box.",
            "User wants to review the seventh cache layer again."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 620.8832263946533,
          "generation_latency_ms": 4361.198902130127,
          "total_latency_ms": 4982.08212852478
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-0",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why was the Frontend Lead running late in the session where the user verified the database providers?",
          "answer_type": "short_answer",
          "gold_answer": "Cat knocked over monitor",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User believes the frontend lead was testing something and forgot to rollback.",
            "Lucas mentioned that frontend latency was spiking.",
            "User's cofounder was worried about latency in the Google-hosted databases"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 619.4818019866943,
          "generation_latency_ms": 3345.837354660034,
          "total_latency_ms": 3965.3191566467285
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user identify the conflicting versions on CacheLayer7 before or after learning about Lucas's monitor accident?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User thought CacheLayer7 update was frozen.",
            "User wants to review the seventh cache layer again.",
            "User asks if cache layers were moved"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 653.4559726715088,
          "generation_latency_ms": 4092.2062397003174,
          "total_latency_ms": 4745.662212371826
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's morning routine requests, what beverage do they frequently consume?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "User is asking if their morning schedule is clear.",
            "User is foggy before coffee",
            "User needs to grab coffee before 2 PM."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 622.5063800811768,
          "generation_latency_ms": 2627.826690673828,
          "total_latency_ms": 3250.333070755005
        },
        {
          "probe_id": "preference_learning-explicit_preferences-1",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Has the user explicitly requested to move the caching layers to GCP?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "User is asking if cache layers are still on Amazon's cloud.",
            "User asks if cache layers were moved",
            "User is concerned about the link between Amazon-hosted cache and database on Google cloud"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 396.381139755249,
          "generation_latency_ms": 3265.272617340088,
          "total_latency_ms": 3661.653757095337
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts PrimaryDB9?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB5 and PrimaryDB8 are hosted on Google's cloud.",
            "User feels primary databases are hosted on a different provider.",
            "User wants only PrimaryDB5"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 695.5986022949219,
          "generation_latency_ms": 3585.365056991577,
          "total_latency_ms": 4280.963659286499
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who holds the role of VP of Marketing?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know who is handling product design for the new dashboard.",
            "User is the CEO",
            "User identifies cofounder as CEO"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 683.32839012146,
          "generation_latency_ms": 3554.8791885375977,
          "total_latency_ms": 4238.207578659058
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What action does the assistant consistently take when the user mentions buying items like coffee beans or cat food?",
          "answer_type": "short_answer",
          "gold_answer": "Adds to shopping list",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants a reminder to buy coffee beans later",
            "User needs to make a coffee first.",
            "User needs to grab coffee before dealing with issue"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 709.8817825317383,
          "generation_latency_ms": 2850.588083267212,
          "total_latency_ms": 3560.46986579895
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What is the recurring cause of interruptions during the Frontend Lead's standups?",
          "answer_type": "short_answer",
          "gold_answer": "His cat Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "User believes the frontend lead was testing something and forgot to rollback.",
            "Lucas mentioned during frontend standup that his cat Luna unplugged his router again, causing frustration, and that Luna interrupted the last standup and makes frequent appearances.",
            "Lucas mentioned that frontend latency was spiking."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 352.60963439941406,
          "generation_latency_ms": 2597.994565963745,
          "total_latency_ms": 2950.604200363159
        }
      ],
      "summary": {
        "overall_accuracy": 0.4166666666666667,
        "total_score": 5,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 2,
            "count": 7,
            "accuracy": 0.2857142857142857
          },
          "boolean": {
            "total": 1,
            "count": 3,
            "accuracy": 0.3333333333333333
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_019.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 28,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 68.62913298606873,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user referring to when they mention their 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Emma",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User has a cofounder",
            "User asks if cofounder arrived yet.",
            "Alex wants to know if cofounder said anything about board meeting."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 324.30338859558105,
          "generation_latency_ms": 2304.647445678711,
          "total_latency_ms": 2628.950834274292
        },
        {
          "probe_id": "world_modeling-relationship_mapping-0",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which cloud platform hosts the database instance specifically used for legacy enterprise clients?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "PrimaryDB3 is hosted on Microsoft's cloud",
            "Alex wants status of main database hosted on Amazon.",
            "User asks if third primary DB is on Microsoft's cloud."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 415.39955139160156,
          "generation_latency_ms": 2496.3438510894775,
          "total_latency_ms": 2911.743402481079
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person responsible for the sales strategy?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales Lead",
          "retrieved_context": [
            "User is trying to remember who is leading the sales push this quarter.",
            "User needs to coordinate with Sales on that one",
            "Sales team is pushing for quarterly update."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 409.2600345611572,
          "generation_latency_ms": 4444.630146026611,
          "total_latency_ms": 4853.890180587769
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-0",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Does the user consider the conflicting version flags on PrimaryDB1 to be an error or an expected state?",
          "answer_type": "short_answer",
          "gold_answer": "Expected state",
          "predicted_answer": "Error",
          "retrieved_context": [
            "User is concerned about the main database node on Amazon's cloud, PrimaryDB1, because version reporting was acting up yesterday and wants to know its reported version: v1.2.0 and v2.0.0-beta simultaneously.",
            "User wants to confirm that the beta tag is showing up on PrimaryDB1.",
            "User reports weird latency on PrimaryDB1"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 640.7132148742676,
          "generation_latency_ms": 3196.418046951294,
          "total_latency_ms": 3837.1312618255615
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-0",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user explain the reason for the version conflict on PrimaryDB1 before or after adding coffee beans to their shopping list?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is tired from debugging PrimaryDB1 all night.",
            "User will inform her that the main database is on beta",
            "User wants to check PrimaryDB3."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 578.484058380127,
          "generation_latency_ms": 2926.687717437744,
          "total_latency_ms": 3505.171775817871
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-0",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What specific errand did the user ask to be reminded about for 5:30 PM?",
          "answer_type": "short_answer",
          "gold_answer": "Pick up dry cleaning",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks if they had a reminder set for 10 AM.",
            "User wants a reminder to grab coffee before the meeting.",
            "User wants a reminder to order lunch in an hour."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 450.85811614990234,
          "generation_latency_ms": 2759.239435195923,
          "total_latency_ms": 3210.097551345825
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What communication style does the user imply is preferred during early morning interactions before they have had caffeine?",
          "answer_type": "short_answer",
          "gold_answer": "Brief",
          "predicted_answer": "Quiet",
          "retrieved_context": [
            "User is going to grab another coffee before next meeting",
            "User is going to grab a coffee",
            "User wants a reminder to grab coffee before the meeting."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 342.78202056884766,
          "generation_latency_ms": 3173.881769180298,
          "total_latency_ms": 3516.6637897491455
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What beverage does the user imply is necessary for them to function effectively in the morning?",
          "answer_type": "short_answer",
          "gold_answer": "Espresso",
          "predicted_answer": "Coffee/Espresso",
          "retrieved_context": [
            "User is going to grab another coffee before next meeting",
            "User is going to grab a coffee",
            "User is going to grab lunch now"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 755.2928924560547,
          "generation_latency_ms": 2998.7542629241943,
          "total_latency_ms": 3754.047155380249
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who is the current VP of Engineering?",
          "answer_type": "abstain",
          "gold_answer": "not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Olivia is Product Design",
            "User is trying to remember who is leading the sales push this quarter.",
            "Luna is mascot of design team"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 587.3973369598389,
          "generation_latency_ms": 2924.536943435669,
          "total_latency_ms": 3511.934280395508
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts PrimaryDB2?",
          "answer_type": "abstain",
          "gold_answer": "not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User confirms PrimaryDB9 is on AWS, the same provider as PrimaryDB1.",
            "PrimaryDB3 is hosted on Microsoft's cloud",
            "User asks if third primary DB is on Microsoft's cloud."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 345.7357883453369,
          "generation_latency_ms": 3452.6407718658447,
          "total_latency_ms": 3798.3765602111816
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-0",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What technical process explains why a database might report two different versions simultaneously according to the user?",
          "answer_type": "short_answer",
          "gold_answer": "Blue-green deployment",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is concerned about the main database node on Amazon's cloud, PrimaryDB1, because version reporting was acting up yesterday and wants to know its reported version: v1.2.0 and v2.0.0-beta simultaneously.",
            "User asks whether the version upgrade on the first database was finalized.",
            "User will ask Sophia to hold off on UI updates until database versioning is fixed"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 885.8883380889893,
          "generation_latency_ms": 3269.3235874176025,
          "total_latency_ms": 4155.211925506592
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "Who does the user identify as the point of contact for UI issues caused by API changes?",
          "answer_type": "short_answer",
          "gold_answer": "Sophia",
          "predicted_answer": "Sophia",
          "retrieved_context": [
            "User believes Sophia might notice frontend issues if the API changed",
            "User will ask Sophia to hold off on UI updates until database versioning is fixed",
            "User needs to ping Olivia about new dashboard designs"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 730.621337890625,
          "generation_latency_ms": 2439.3606185913086,
          "total_latency_ms": 3169.9819564819336
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 10,
            "accuracy": 0.4
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_020.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 28,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 74.00274062156677,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who did the user plan to meet for coffee prior to the board meeting?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "cofounder",
          "retrieved_context": [
            "User needs to grab lunch before next meeting",
            "User thought they had a strategy sync with their cofounder this morning",
            "User wants to know which team members are focusing on what today before attending an executive sync with a cofounder."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 346.82726860046387,
          "generation_latency_ms": 2334.9883556365967,
          "total_latency_ms": 2681.8156242370605
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which cloud provider hosts the cache instance identified as causing the cross-cloud hop latency?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "The main cache layer hosted on AWS is experiencing jitter",
            "User believes caching layers are split between Azure and AWS.",
            "LoadBalancer1 is holding up and is in the same AWS region as cache number 7."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 353.6105155944824,
          "generation_latency_ms": 3916.8150424957275,
          "total_latency_ms": 4270.42555809021
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales Lead",
          "retrieved_context": [
            "James's cat Luna walked across his keyboard during the standup.",
            "James loves Luna the cat.",
            "User heard Luna had a vet appointment"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 684.1042041778564,
          "generation_latency_ms": 4020.914077758789,
          "total_latency_ms": 4705.0182819366455
        },
        {
          "probe_id": "declarative_reasoning-state_tracking-3",
          "pillar": "declarative_reasoning",
          "subpillar": "task_state_tracking",
          "question": "Which two software versions were detected running simultaneously on the AWS cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and a new beta",
          "retrieved_context": [
            "User reports logs for cache layer 7 show two different versions responding simultaneously.",
            "The main cache layer hosted on AWS is experiencing jitter",
            "User believes caching layers are split between Azure and AWS."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 583.3330154418945,
          "generation_latency_ms": 2225.6929874420166,
          "total_latency_ms": 2809.026002883911
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What architectural configuration did the user identify as the primary cause of backend latency?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-cloud hop",
          "predicted_answer": "latency between the primary traffic distributor and the newest cache layer",
          "retrieved_context": [
            "User is seeing weird latency in the logs",
            "User's cofounder is stressing out about the latency spikes seen this morning",
            "The cofounder asked about latency between the primary traffic distributor and the newest cache layer earlier this morning."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 300.6939888000488,
          "generation_latency_ms": 4069.997787475586,
          "total_latency_ms": 4370.691776275635
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user notice the deployment glitch on CacheLayer7 before or after the discussion about the board meeting?",
          "answer_type": "short_answer",
          "gold_answer": "After",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User inquires about the behavior of the seventh cache layer.",
            "User wants the assistant to look at CacheLayer7",
            "User reports logs for cache layer 7 show two different versions responding simultaneously."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 681.5555095672607,
          "generation_latency_ms": 3452.834129333496,
          "total_latency_ms": 4134.389638900757
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's complaints about latency, which infrastructure setup do they appear to dislike?",
          "answer_type": "short_answer",
          "gold_answer": "Hybrid setup",
          "predicted_answer": "Split caching layers between Azure and AWS",
          "retrieved_context": [
            "User has time to look into infrastructure issues",
            "User's cofounder is stressing out about the latency spikes seen this morning",
            "User is seeing weird latency in the logs"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 573.3561515808105,
          "generation_latency_ms": 3409.9175930023193,
          "total_latency_ms": 3983.27374458313
        },
        {
          "probe_id": "preference_learning-explicit_preferences-7",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Why did the user explicitly state they wanted to buy a toy for Luna?",
          "answer_type": "short_answer",
          "gold_answer": "To please James",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to pick up a toy for Luna later",
            "User heard Luna had a vet appointment",
            "User heard all about Luna this morning."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 563.0505084991455,
          "generation_latency_ms": 3028.7609100341797,
          "total_latency_ms": 3591.811418533325
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Data Scientist's pet?",
          "answer_type": "abstain",
          "gold_answer": "Not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User has a data scientist.",
            "User wants to get the data scientist to analyze traffic patterns.",
            "User intends to sync with data scientist to investigate analytics pipeline impact."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 826.6777992248535,
          "generation_latency_ms": 3656.851291656494,
          "total_latency_ms": 4483.529090881348
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the database layer?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User believes caching layers are split between Azure and AWS.",
            "The main cache layer hosted on AWS is experiencing jitter",
            "User needs to check if behavior matches sixth layer cache on Microsoft's platform, which is on Azure while the load balancer is on AWS, and Liam doesn't understand."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 640.2077674865723,
          "generation_latency_ms": 3498.0225563049316,
          "total_latency_ms": 4138.230323791504
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What risk did the assistant identify regarding the concurrent execution of two versions on the same instance?",
          "answer_type": "short_answer",
          "gold_answer": "Data inconsistency",
          "predicted_answer": "Latency",
          "retrieved_context": [
            "User's cofounder was worried about version mismatches causing latency",
            "User reports logs for cache layer 7 show two different versions responding simultaneously.",
            "User wants focus on version mismatch."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 654.2215347290039,
          "generation_latency_ms": 4319.566249847412,
          "total_latency_ms": 4973.787784576416
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-11",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "How did the assistant verify the status of the traffic distributor on Amazon?",
          "answer_type": "short_answer",
          "gold_answer": "Pulled up metrics",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants metrics for main traffic distributor hosted on Amazon.",
            "User's cofounder is asking for a report on the load balancer status.",
            "User's cofounder is worried about traffic routing."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 556.2231540679932,
          "generation_latency_ms": 3321.141242980957,
          "total_latency_ms": 3877.36439704895
        }
      ],
      "summary": {
        "overall_accuracy": 0.3333333333333333,
        "total_score": 4,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 2,
            "count": 10,
            "accuracy": 0.2
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_021.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 28,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 72.17392659187317,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the 'cofounder' that requested a status update on the production environment?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder is asking for a status update on the production environment.",
            "User has a cofounder",
            "User has a sync with cofounder later"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 559.1006278991699,
          "generation_latency_ms": 2299.825429916382,
          "total_latency_ms": 2858.9260578155518
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the job title of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Backend Lead",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Luna is a cat that was taken to the vet.",
            "User wants to buy cat treats for Luna.",
            "Will has a cat named Luna who was sick."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 453.3376693725586,
          "generation_latency_ms": 2811.126470565796,
          "total_latency_ms": 3264.4641399383545
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service managed by the Data Scientist hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know who the Data Scientist is.",
            "Sophia manages data science models",
            "User has enough issues with auth service, asks if it is strictly on Azure, and wants to know if it is split across clouds."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 352.25486755371094,
          "generation_latency_ms": 3145.9403038024902,
          "total_latency_ms": 3498.195171356201
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Which two versions of the analytics engine are currently reporting conflicting signals in the logs?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and a newer version",
          "retrieved_context": [
            "Will mentioned that the analytics engine deployment is acting up",
            "User is seeing weird logs on analytics service versions.",
            "User is seeing weird telemetry from the analytics engine"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 701.3475894927979,
          "generation_latency_ms": 4123.349666595459,
          "total_latency_ms": 4824.697256088257
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why was the Backend Lead exhausted during the conversation by the coffee machine?",
          "answer_type": "short_answer",
          "gold_answer": "His cat kept him awake",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "The main backend guy is out",
            "User wants to sync with Charlotte about backend load later, and suggests checking with Charlotte, who shares backend lead role and might know what's up.",
            "User needs a second coffee before tackling the incident queue today"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 601.759672164917,
          "generation_latency_ms": 4100.132465362549,
          "total_latency_ms": 4701.892137527466
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "In the same conversation where the user asked for a reminder to call their mom, what was the status of the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "Mixed signals",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants a reminder to call mom at 6 PM today.",
            "User wants to check the status of the analytics engine.",
            "User wants analytics engine version numbers logged in report."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 707.9286575317383,
          "generation_latency_ms": 3508.938789367676,
          "total_latency_ms": 4216.867446899414
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's reaction to the logs, which version of the analytics engine do they prefer to be active in production?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants analytics engine version numbers logged in report.",
            "User is referring to AnalyticsEngine1 instance and is unsure if deployment went through; wants to know its version, investigate version mismatch, confirm it is still on Azure, and wants to check the current live version of the analytics engine.",
            "User wants to check the status of the analytics engine."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 640.1681900024414,
          "generation_latency_ms": 4411.619424819946,
          "total_latency_ms": 5051.787614822388
        },
        {
          "probe_id": "preference_learning-explicit_preferences-7",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Has the user explicitly requested to filter the Auth Service logs to a single cloud provider?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "User has enough issues with auth service, asks if it is strictly on Azure, and wants to know if it is split across clouds.",
            "User asks where the auth service is hosted.",
            "User wants to check status of auth service."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 654.8993587493896,
          "generation_latency_ms": 3226.41658782959,
          "total_latency_ms": 3881.3159465789795
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific version number is the Load Balancer currently running?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to check the health of the load balancer",
            "User wants load balancer status on Google side.",
            "User asks about the load balancer."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 745.6185817718506,
          "generation_latency_ms": 3791.064977645874,
          "total_latency_ms": 4536.683559417725
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "Is the Auth Service currently hosted exclusively on Azure?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "User has enough issues with auth service, asks if it is strictly on Azure, and wants to know if it is split across clouds.",
            "User asks where the auth service is hosted.",
            "Second auth service is now hosted on GCP alongside LoadBalancer4"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 840.0554656982422,
          "generation_latency_ms": 3214.6522998809814,
          "total_latency_ms": 4054.7077655792236
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "Who should be contacted regarding discrepancies in the data science model deployments?",
          "answer_type": "short_answer",
          "gold_answer": "Sophia",
          "predicted_answer": "Sophia",
          "retrieved_context": [
            "Sophia manages data science models",
            "Sophia is always trying to get the latest models running for the data science team",
            "User wants to know who the Data Scientist is."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 605.0164699554443,
          "generation_latency_ms": 2696.6371536254883,
          "total_latency_ms": 3301.6536235809326
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-11",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What routine action does the user typically take before starting the daily triage?",
          "answer_type": "short_answer",
          "gold_answer": "Grab coffee",
          "predicted_answer": "Finishing coffee",
          "retrieved_context": [
            "User wants help sorting alerts before finishing coffee.",
            "User needs a second coffee before tackling the incident queue today",
            "User finds the situation annoying."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 414.5193099975586,
          "generation_latency_ms": 3013.935089111328,
          "total_latency_ms": 3428.4543991088867
        }
      ],
      "summary": {
        "overall_accuracy": 0.3333333333333333,
        "total_score": 4,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 2,
            "count": 10,
            "accuracy": 0.2
          },
          "boolean": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_022.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 30,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 69.9001932144165,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user referring to when they mention their 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Elijah",
          "retrieved_context": [
            "User thinks cofounder is moving fast.",
            "User's cofounder will be happy to hear that.",
            "User is CTO"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 586.1451625823975,
          "generation_latency_ms": 2982.149124145508,
          "total_latency_ms": 3568.2942867279053
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the name of the pet belonging to the Sales Lead who is known for watching the dashboards?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks about the rest of the sales leads.",
            "User asks whether Ava or Sophia mentioned sales dashboard lagging",
            "Oliver always watches dashboards."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 635.5061531066895,
          "generation_latency_ms": 2898.742198944092,
          "total_latency_ms": 3534.2483520507812
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service running conflicting versions v1.2.0 and v2.0.0-beta hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "User believes LoadBalancer3 should not be running both versions.",
            "User thinks cross-cloud latency between GCP and Azure might be an issue.",
            "User wants a quick status on Nebula Corp's Azure-hosted services."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 394.39845085144043,
          "generation_latency_ms": 3534.3844890594482,
          "total_latency_ms": 3928.7829399108887
        },
        {
          "probe_id": "declarative_reasoning-composition-4",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which specific service is hosted on the same cloud platform as 'AnalyticsEngine9'?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer3",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know if Azure side only has analytics engine.",
            "User wants to know if the analytics engine is behaving.",
            "User asks if analytics engine is sitting with the first load balancer."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 663.7473106384277,
          "generation_latency_ms": 4104.7844886779785,
          "total_latency_ms": 4768.531799316406
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What item did the user ask to be reminded to buy immediately after discussing Elijah's confusion about the load balancer's location?",
          "answer_type": "short_answer",
          "gold_answer": "Milk",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User recalls debating pushing an update to the load balancer.",
            "Elijah was convinced LoadBalancer3 was on Google.",
            "User intends to tell Elijah that they are optimizing"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 670.5269813537598,
          "generation_latency_ms": 3911.0889434814453,
          "total_latency_ms": 4581.615924835205
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-6",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user ask to be reminded about 'dry cleaning' before or after they asked to be reminded about 'milk'?",
          "answer_type": "short_answer",
          "gold_answer": "After",
          "predicted_answer": "After",
          "retrieved_context": [
            "User wants reminder to pick up milk on way home",
            "User wants reminder to pick up dry cleaning on way home",
            "User wants reminder to pick up something for Luna later"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 597.7914333343506,
          "generation_latency_ms": 2519.091844558716,
          "total_latency_ms": 3116.8832778930664
        },
        {
          "probe_id": "preference_learning-explicit_preferences-7",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What consumable item does the user explicitly state is their 'first priority' before they can function?",
          "answer_type": "short_answer",
          "gold_answer": "Caffeine",
          "predicted_answer": "double shot of espresso",
          "retrieved_context": [
            "User needs another coffee before looking at a screen today.",
            "User needs a double shot of espresso to function today",
            "User needs to grab lunch before meeting."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 439.58520889282227,
          "generation_latency_ms": 3598.8247394561768,
          "total_latency_ms": 4038.409948348999
        },
        {
          "probe_id": "preference_learning-preference_induction-8",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Regarding the conflicting versions on LoadBalancer3, does the user prefer to keep the beta percentage high or low?",
          "answer_type": "short_answer",
          "gold_answer": "Low",
          "predicted_answer": "low",
          "retrieved_context": [
            "User is referring to LoadBalancer3.",
            "User believes LoadBalancer3 should not be running both versions.",
            "User thinks LoadBalancer3 is acting up."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 687.1902942657471,
          "generation_latency_ms": 2267.0931816101074,
          "total_latency_ms": 2954.2834758758545
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider is 'CacheLayer9' hosted on?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to check cache layers 5 and 7 and asks if they are on Azure",
            "User wonders why CacheLayer5 is on GCP while the analytics engine is on Azure.",
            "User is asking if caching layer in Google Cloud environment is stable."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 400.5587100982666,
          "generation_latency_ms": 2374.2570877075195,
          "total_latency_ms": 2774.815797805786
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "What specific version number is System:LoadBalancer_7 currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know the version of LoadBalancer3.",
            "User thinks the load balancer version is locked to v1.2.0.",
            "User believes LoadBalancer3 should not be running both versions."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 301.0518550872803,
          "generation_latency_ms": 2355.9203147888184,
          "total_latency_ms": 2656.9721698760986
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-11",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "What specific action did the user decide to take to resolve the jitter caused by the split configuration on LoadBalancer3?",
          "answer_type": "short_answer",
          "gold_answer": "Manually kill the beta instance",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User thinks LoadBalancer3 is acting up.",
            "User recalls debating pushing an update to the load balancer.",
            "User is seeing oscillating metrics on the third load balancer."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 361.13810539245605,
          "generation_latency_ms": 4229.571104049683,
          "total_latency_ms": 4590.709209442139
        },
        {
          "probe_id": "procedural_knowledge-task_state_tracking-12",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "What is the current versioning state of the load balancer hosted on Azure?",
          "answer_type": "short_answer",
          "gold_answer": "Conflicting versions",
          "predicted_answer": "Locked to v1.2.0.",
          "retrieved_context": [
            "User wants to know if LoadBalancer3 is fully migrated to Azure.",
            "User wants a quick status check on the environment and traffic on the new load balancer deployment.",
            "User wants to know the version of LoadBalancer3."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 626.0473728179932,
          "generation_latency_ms": 3689.5625591278076,
          "total_latency_ms": 4315.609931945801
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 10,
            "accuracy": 0.4
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_023.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 27,
      "num_probes": 8,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 43.905922174453735,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the 'cofounder' the user intends to sync with regarding the cloud footprint?",
          "answer_type": "short_answer",
          "gold_answer": "Mia",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is mapping out the current cloud footprint for a board meeting with a cofounder before noon",
            "User has a cofounder",
            "User needs to sync with the UI team later."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 592.8521156311035,
          "generation_latency_ms": 2414.052963256836,
          "total_latency_ms": 3006.9050788879395
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which team member is associated with the pet named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Charlotte",
          "predicted_answer": "Charlotte",
          "retrieved_context": [
            "The cat is the team mascot",
            "User was told that Luna was knocking things off shelves all night",
            "Charlotte is going to the vet with Luna."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 391.7555809020996,
          "generation_latency_ms": 2433.561325073242,
          "total_latency_ms": 2825.316905975342
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which cloud provider hosts the database that the user described as an 'outlier'?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "PrimaryDB3 is isolated on Azure while everything else is on Google's infrastructure",
            "PrimaryDB3 is on Azure.",
            "PrimaryDB6 is on GCP, same as the analytics engines"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 364.04943466186523,
          "generation_latency_ms": 2643.645763397217,
          "total_latency_ms": 3007.695198059082
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What two conflicting versions is AnalyticsEngine3 currently reporting?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User thought AnalyticsEngine3 upgrade was finalized but logs look weird, and is reviewing the current versioning of AnalyticsEngine3 and notes inconsistent headers in its logs.",
            "User is seeing features that shouldn't be there if the third analytics engine is on v1.2.0",
            "User is asking whether analytics engine 3 is on the old stable version."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 574.4669437408447,
          "generation_latency_ms": 3267.7767276763916,
          "total_latency_ms": 3842.2436714172363
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What external factor did the Data Scientist blame for the model latency issues?",
          "answer_type": "short_answer",
          "gold_answer": "Her cat",
          "predicted_answer": "Her cat walking on the keyboard",
          "retrieved_context": [
            "Elijah complained about latency on sales dashboards yesterday.",
            "Charlotte complained about latency for her models yesterday, blaming it on her cat walking on the keyboard",
            "User suspects a data scientist toggled a flag to test new models."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 610.3684902191162,
          "generation_latency_ms": 2847.92423248291,
          "total_latency_ms": 3458.2927227020264
        },
        {
          "probe_id": "preference_learning-explicit_preferences-1",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What specific item did the user request a reminder to purchase on the way home?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee beans",
          "predicted_answer": "coffee beans, milk, dry cleaning",
          "retrieved_context": [
            "The user wants a reminder to buy coffee beans on their way home",
            "User wants a reminder to buy milk on the way home later.",
            "User wants reminder to buy cat treats later."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 347.41687774658203,
          "generation_latency_ms": 2523.6072540283203,
          "total_latency_ms": 2871.0241317749023
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the Sales Lead's infrastructure?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "PrimaryDB3 is isolated on Azure while everything else is on Google's infrastructure",
            "User wants to know which cloud the instance is on.",
            "PrimaryDB3 is on Azure."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 354.35009002685547,
          "generation_latency_ms": 3569.430112838745,
          "total_latency_ms": 3923.7802028656006
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-1",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "Who did the assistant plan to contact regarding the UI glitches caused by the engine version conflict?",
          "answer_type": "short_answer",
          "gold_answer": "Sophia and Ava",
          "predicted_answer": "Data Scientist",
          "retrieved_context": [
            "User intends to ping Data Scientist to investigate the version conflict.",
            "User remembers seeing mixed reports on dashboard about version of AnalyticsEngine3, which has a version conflict causing weird latency, and the frontend team triggered a deployment.",
            "User recalls that they were pushing an update to the third analytics engine."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 616.7287826538086,
          "generation_latency_ms": 3340.2023315429688,
          "total_latency_ms": 3956.9311141967773
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 4,
        "count": 8,
        "by_answer_type": {
          "short_answer": {
            "total": 3,
            "count": 7,
            "accuracy": 0.42857142857142855
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_024.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 29,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 53.866021156311035,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which individual is identified as the user's cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Elijah",
          "retrieved_context": [
            "Elijah is the CEO and cofounder",
            "User wants to know who is handling the UI team.",
            "User asks if cofounder knows cost of complexity."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 571.199893951416,
          "generation_latency_ms": 2262.377977371216,
          "total_latency_ms": 2833.577871322632
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the name of the pet belonging to the person who shares the Sales Lead role with Oliver?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Oliver and Mia are the Sales Leads",
            "User wants to know who is heading sales team leads.",
            "User asks whether Oliver is also doing demos"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 300.7183074951172,
          "generation_latency_ms": 2963.1640911102295,
          "total_latency_ms": 3263.8823986053467
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service hosted that the user described as 'sitting all alone'?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is looking at the database hosted on Microsoft's cloud.",
            "User says multi-cloud setup is a nightmare.",
            "User's multi-cloud bill is causing headache"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 301.2423515319824,
          "generation_latency_ms": 2644.6051597595215,
          "total_latency_ms": 2945.847511291504
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-1",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "Which specific database resource is hosted on the platform provided by Microsoft?",
          "answer_type": "short_answer",
          "gold_answer": "PrimaryDB7",
          "predicted_answer": "PrimaryDB7",
          "retrieved_context": [
            "User is looking at the database hosted on Microsoft's cloud.",
            "The database is hosted on Azure",
            "User needs to look into Azure database instance."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 377.93421745300293,
          "generation_latency_ms": 2463.6495113372803,
          "total_latency_ms": 2841.583728790283
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who is currently designated as the Backend Lead?",
          "answer_type": "abstain",
          "gold_answer": "unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know who is heading sales team leads.",
            "User wants to know who is handling the UI team.",
            "User wants to inform Frontend Leads Olivia and Noah that backend is fluctuating before they push changes."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 443.7389373779297,
          "generation_latency_ms": 3019.55509185791,
          "total_latency_ms": 3463.29402923584
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What software version is currently running on AuthService1?",
          "answer_type": "abstain",
          "gold_answer": "unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User notes that AuthService1 is isolated on Google Cloud.",
            "User wants to ensure AuthService1 is syncing correctly with others.",
            "User asks if AuthService1 on GCP is showing latency."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 359.75193977355957,
          "generation_latency_ms": 2624.04465675354,
          "total_latency_ms": 2983.7965965270996
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-0",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "During the conversation about the 'multi-cloud mess', what item did the user ask to be reminded to buy?",
          "answer_type": "short_answer",
          "gold_answer": "Milk",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants a quick summary of the multi-cloud mess",
            "User's multi-cloud bill is causing headache",
            "User says multi-cloud setup is a nightmare."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 319.2415237426758,
          "generation_latency_ms": 2642.2293186187744,
          "total_latency_ms": 2961.47084236145
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user request a reminder to call their mom before or after requesting a reminder for espresso pods?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Before",
          "retrieved_context": [
            "User wants a reminder to grab a latte in ten minutes.",
            "User wants a reminder to buy coffee beans before the shop closes.",
            "User wants reminder to call mom at 5 PM"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 288.7589931488037,
          "generation_latency_ms": 2571.585178375244,
          "total_latency_ms": 2860.344171524048
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's greetings in the session logs, at what time of day do they typically discuss infrastructure status?",
          "answer_type": "short_answer",
          "gold_answer": "Morning",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to review infrastructure status",
            "User had a phone call with cofounder who wants a status update on the infrastructure migration by end of day.",
            "User wants to get a handle on infrastructure spread before the weekly sync."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 414.44945335388184,
          "generation_latency_ms": 3353.4674644470215,
          "total_latency_ms": 3767.9169178009033
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-0",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "Which two cloud providers does the user repeatedly confuse regarding service locations?",
          "answer_type": "short_answer",
          "gold_answer": "Azure and GCP",
          "predicted_answer": "Google Cloud, Microsoft's cloud",
          "retrieved_context": [
            "User says multi-cloud setup is a nightmare.",
            "User's multi-cloud bill is causing headache",
            "User is looking at the database hosted on Microsoft's cloud."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 545.8753108978271,
          "generation_latency_ms": 4877.417802810669,
          "total_latency_ms": 5423.293113708496
        }
      ],
      "summary": {
        "overall_accuracy": 0.6,
        "total_score": 6,
        "count": 10,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 8,
            "accuracy": 0.5
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_025.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 27,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 56.92814755439758,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which individual is identified as the user's cofounder who worries about stability?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "User's cofounder",
          "retrieved_context": [
            "User's cofounder is worried about the stability of the authentication service.",
            "User's cofounder is paranoid about uptime for the demo",
            "User's cofounder is stressing about quarterly goals"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 583.1167697906494,
          "generation_latency_ms": 2573.6217498779297,
          "total_latency_ms": 3156.738519668579
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the name of the pet belonging to the DevOps engineer who works alongside Lucas?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "Oliver and Lucas are on rotation and handle the ops side of things, and Lucas is handling DevOps tickets today.",
            "User says Lucas is doing a canary deployment without telling them.",
            "User asks who is on shift between Oliver and Lucas"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 326.2982368469238,
          "generation_latency_ms": 2636.878728866577,
          "total_latency_ms": 2963.176965713501
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service hosted that is currently experiencing a version mismatch with a beta release?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google Cloud",
          "retrieved_context": [
            "User finds the multi-cloud setup a headache.",
            "AuthService 7 is running version v2.0.0-beta on Google Cloud.",
            "User is concerned that AuthService7 deployment may have drifted again."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 662.9667282104492,
          "generation_latency_ms": 3396.929979324341,
          "total_latency_ms": 4059.89670753479
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which analytics engine is deployed on the same cloud platform as the authentication service?",
          "answer_type": "short_answer",
          "gold_answer": "AnalyticsEngine3",
          "predicted_answer": "AnalyticsEngine3",
          "retrieved_context": [
            "AnalyticsEngine3 is hosted on GCP, is with the auth service, and is stable.",
            "User wants to see where analytics engines are located.",
            "User is asking if the analytics stack is split across different clouds."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 524.5561599731445,
          "generation_latency_ms": 2496.046543121338,
          "total_latency_ms": 3020.6027030944824
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why was Oliver distracted during the standup meeting mentioned in the session where the user discussed quarterly goals?",
          "answer_type": "short_answer",
          "gold_answer": "Luna knocked over water",
          "predicted_answer": "Luna knocked over Oliver's water",
          "retrieved_context": [
            "Oliver was distracted during the standup because Luna knocked over Oliver's water",
            "User asks whether Oliver managed to consolidate anything yet.",
            "User is trying to track down Oliver"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 479.25305366516113,
          "generation_latency_ms": 3557.342529296875,
          "total_latency_ms": 4036.595582962036
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-1",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "In the conversation where the user complained about paying invoices to every cloud provider, where was AnalyticsEngine5 stated to be hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "User wants to see where analytics engines are located.",
            "User wants assistant to keep an eye on AnalyticsEngine5",
            "User wants to know status of AnalyticsEngine5 on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 859.1928482055664,
          "generation_latency_ms": 2869.5313930511475,
          "total_latency_ms": 3728.724241256714
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's comments about the infrastructure map, how do they feel about the current multi-cloud setup?",
          "answer_type": "short_answer",
          "gold_answer": "dislikes it",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User finds the multi-cloud setup a headache.",
            "User's cofounder is asking for a status update on the infrastructure.",
            "User believes infrastructure is becoming a mess"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 417.45710372924805,
          "generation_latency_ms": 4117.655277252197,
          "total_latency_ms": 4535.112380981445
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific software version is AnalyticsEngine6 currently running?",
          "answer_type": "abstain",
          "gold_answer": "unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know status of AnalyticsEngine6",
            "User wants to know location of AnalyticsEngine6",
            "User wants to check AnalyticsEngine3 specifically"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 578.6552429199219,
          "generation_latency_ms": 2608.187437057495,
          "total_latency_ms": 3186.842679977417
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-2",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who holds the role of CFO at Nebula Corp?",
          "answer_type": "abstain",
          "gold_answer": "unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder is worried about the AWS bill this month",
            "User says cofounder needs to sign off on cloud budget before approving invoices.",
            "Oliver manages the pipeline"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 298.74539375305176,
          "generation_latency_ms": 4057.81888961792,
          "total_latency_ms": 4356.564283370972
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-1",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What specific action did the assistant perform when the user requested to be prompted about calling the dentist?",
          "answer_type": "short_answer",
          "gold_answer": "set a reminder",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants a reminder to call dentist at 2 PM",
            "User wants a reminder at 5 PM to call the dentist.",
            "User needs to hop on a call with cofounder first"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 957.1077823638916,
          "generation_latency_ms": 2760.6821060180664,
          "total_latency_ms": 3717.789888381958
        }
      ],
      "summary": {
        "overall_accuracy": 0.7,
        "total_score": 7,
        "count": 10,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 8,
            "accuracy": 0.625
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_026.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 31,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 67.17261695861816,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the owner of the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Will",
          "predicted_answer": "Will",
          "retrieved_context": [
            "The cat Luna knocked over a plant this morning.",
            "Will's cat Luna unplugged Will's router earlier",
            "User forgot that Luna was sick."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 1056.9028854370117,
          "generation_latency_ms": 3777.315616607666,
          "total_latency_ms": 4834.218502044678
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which cloud provider hosts the load balancer that is currently running a beta version?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks which load balancers are on Google's cloud",
            "LoadBalancer4 is hosted on Google's infrastructure.",
            "Load balancers are split between Amazon and Google"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 639.880895614624,
          "generation_latency_ms": 2956.0346603393555,
          "total_latency_ms": 3595.9155559539795
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person who had to take their pet to the vet?",
          "answer_type": "short_answer",
          "gold_answer": "DevOps",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User notes that Will was taking Luna to the vet.",
            "User thinks DevOps lead's cat walked on keyboard.",
            "User has a cat"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 391.34669303894043,
          "generation_latency_ms": 3950.012445449829,
          "total_latency_ms": 4341.3591384887695
        },
        {
          "probe_id": "declarative_reasoning-baseline_factual_recall-3",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "Which specific service is hosted on the Azure platform?",
          "answer_type": "short_answer",
          "gold_answer": "AuthService9",
          "predicted_answer": "Auth service 9",
          "retrieved_context": [
            "User asks how auth service on Azure is holding up.",
            "Auth service 9 is on Azure",
            "User's organization is still paying for Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 667.0949459075928,
          "generation_latency_ms": 2660.3376865386963,
          "total_latency_ms": 3327.432632446289
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What event caused the DevOps lead to be delayed in starting his work day?",
          "answer_type": "short_answer",
          "gold_answer": "Vet visit",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User will have DevOps lead fix that tomorrow",
            "User needs to ping DevOps lead.",
            "User thinks DevOps lead's cat walked on keyboard."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 394.0584659576416,
          "generation_latency_ms": 3609.4558238983154,
          "total_latency_ms": 4003.514289855957
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "In the most recent infrastructure review, which load balancer was confirmed to still be running on AWS?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer8",
          "predicted_answer": "LoadBalancer8",
          "retrieved_context": [
            "Service 8 is on AWS and refers to the AWS load balancer",
            "User has two active load balancers on Google's cloud.",
            "User asks which load balancers are on Google's cloud"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 701.5316486358643,
          "generation_latency_ms": 2389.6236419677734,
          "total_latency_ms": 3091.1552906036377
        },
        {
          "probe_id": "preference_learning-explicit_preferences-6",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What specific beverage does the user require before they can focus on infrastructure or meetings?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Double espresso",
          "retrieved_context": [
            "User needs a double espresso before thinking about the board meeting",
            "User needs a distraction before the status meeting",
            "User will grab a coffee before diving in."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 362.87951469421387,
          "generation_latency_ms": 2587.151288986206,
          "total_latency_ms": 2950.03080368042
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's initial request in Session 25, which cloud provider's resources do they prioritize reviewing first?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google Cloud",
          "retrieved_context": [
            "User wants to start with Google Cloud resources",
            "User wants to check other clouds",
            "User needs to check cloud spend"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 300.66800117492676,
          "generation_latency_ms": 2095.515489578247,
          "total_latency_ms": 2396.183490753174
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What software version is currently running on LoadBalancer8?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks where LoadBalancer8 is running.",
            "LoadBalancer4 has conflicting version reports: one dashboard says v1.2.0 and another says v2.0.0-beta, and User needs details about conflicting load balancer versions, recalling seeing weird versioning logs earlier for LoadBalancer4",
            "User wants current status of LoadBalancer4."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 276.03626251220703,
          "generation_latency_ms": 2285.917043685913,
          "total_latency_ms": 2561.95330619812
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of Lucas's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to include Lucas and Noah",
            "User wants to know what Lucas and Noah have been working on.",
            "User asks if Will is still obsessed with the new kitten."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 287.59264945983887,
          "generation_latency_ms": 3091.723918914795,
          "total_latency_ms": 3379.316568374634
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "If a load balancer flags two different versions simultaneously, what type of deployment does the user identify this as?",
          "answer_type": "short_answer",
          "gold_answer": "Canary deployment",
          "predicted_answer": "Upgrade",
          "retrieved_context": [
            "Alex hears conflicting reports about the live version on load balancer 4.",
            "LoadBalancer4 has conflicting version reports: one dashboard says v1.2.0 and another says v2.0.0-beta, and User needs details about conflicting load balancer versions, recalling seeing weird versioning logs earlier for LoadBalancer4",
            "User thinks load balancer number 4 was being upgraded"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 492.68436431884766,
          "generation_latency_ms": 3329.8568725585938,
          "total_latency_ms": 3822.5412368774414
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-11",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What specific state configuration indicated to the assistant that a canary deployment was active on LoadBalancer4?",
          "answer_type": "short_answer",
          "gold_answer": "Two different versions",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks where LoadBalancer8 is running.",
            "User wants current status of LoadBalancer4.",
            "User needs to figure out what's going on with LoadBalancer4."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 590.5332565307617,
          "generation_latency_ms": 3945.11342048645,
          "total_latency_ms": 4535.646677017212
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 10,
            "accuracy": 0.4
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_027.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 11.709226131439209,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does system:loadbalancer_2 running version?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0",
          "predicted_answer": "v1.2.0",
          "retrieved_context": [
            "Dashboard reports second load balancer version v1.2.0.",
            "User wants to know which load balancer handles the Google side of things and wants to check the version on the second GCP load balancer.",
            "User wants specs for load balancers."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 756.8221092224121,
          "generation_latency_ms": 4053.9097785949707,
          "total_latency_ms": 4810.731887817383
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know if Oliver has reviewed quarterly goals.",
            "User asks if it's raining outside.",
            "User asks which designer talked about a new kitten yesterday"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 531.7344665527344,
          "generation_latency_ms": 2535.7441902160645,
          "total_latency_ms": 3067.478656768799
        }
      ],
      "summary": {
        "overall_accuracy": 1.0,
        "total_score": 2,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_028.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 69.41692042350769,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which cloud provider hosts the service where the Product Designer requires write access?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User states that the rest of services are on Amazon.",
            "The seventh primary DB and AuthService9 are hosted on AWS.",
            "User has a hybrid cloud setup."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 350.1107692718506,
          "generation_latency_ms": 3532.4416160583496,
          "total_latency_ms": 3882.5523853302
        },
        {
          "probe_id": "world_modeling-category_membership-1",
          "pillar": "world_modeling",
          "subpillar": "type_category_membership",
          "question": "Which specific infrastructure services are currently confirmed to be running on the Google Cloud Platform?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer4 and AnalyticsEngine1",
          "predicted_answer": "Data pipeline, LoadBalancer4, AnalyticsEngine1",
          "retrieved_context": [
            "User wants to know if analytics and the fourth load balancer are on Google cloud.",
            "Data pipeline and LoadBalancer4 are hosted on GCP.",
            "Alex wants current infrastructure status for Nebula"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 1030.6651592254639,
          "generation_latency_ms": 2492.0129776000977,
          "total_latency_ms": 3522.6781368255615
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the professional role of the individual who owns a cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Someone who does client pitches",
          "retrieved_context": [
            "User wants to buy cat treats for Luna.",
            "Luna is a cat getting huge",
            "Charlotte has a cat named Luna."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 446.78807258605957,
          "generation_latency_ms": 4617.4890995025635,
          "total_latency_ms": 5064.277172088623
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "According to the latest system logs discussed, what is the version status of the second primary database?",
          "answer_type": "short_answer",
          "gold_answer": "Split between v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta are being flagged in logs due to a version mismatch.",
          "retrieved_context": [
            "User wants status of PrimaryDB2 cluster, wants info about the second primary database that was being patched, will manually rollback the second primary database, is unsure if the upgrade on the second primary database was finalized, and needs to fix the database upgrade manually.",
            "Alex wants to know the version of PrimaryDB2.",
            "User asks if PrimaryDB2 is running the beta."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 1004.6038627624512,
          "generation_latency_ms": 3315.0274753570557,
          "total_latency_ms": 4319.631338119507
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific technical issue is causing the user's cofounder to worry about the platform's stability?",
          "answer_type": "short_answer",
          "gold_answer": "Version mismatch on PrimaryDB2",
          "predicted_answer": "New beta version acting up",
          "retrieved_context": [
            "User's cofounder is breathing down user's neck about uptime.",
            "User's cofounder is worried about the upcoming launch.",
            "User's cofounder asked about reliability earlier."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 587.6727104187012,
          "generation_latency_ms": 3225.212574005127,
          "total_latency_ms": 3812.885284423828
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "In the conversation regarding the stuck migration, did the user complain about the coffee before or after requesting permission updates for Liam and Charlotte?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Migration is stuck.",
            "User notes that Liam complained about login issues.",
            "User's cofounder asked if the update went through this morning."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 647.1660137176514,
          "generation_latency_ms": 2654.4320583343506,
          "total_latency_ms": 3301.598072052002
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's reaction to the office machine, what is their implied preference regarding coffee strength?",
          "answer_type": "short_answer",
          "gold_answer": "Strong coffee",
          "predicted_answer": "Stronger coffee",
          "retrieved_context": [
            "User is going to finish coffee before it gets cold",
            "User needs a double shot of espresso before looking at a screen today",
            "User needs to grab coffee before diving deeper."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 325.78396797180176,
          "generation_latency_ms": 3991.5390014648438,
          "total_latency_ms": 4317.3229694366455
        },
        {
          "probe_id": "preference_learning-constraint_hierarchy-7",
          "pillar": "preference_learning",
          "subpillar": "constraint_hierarchy",
          "question": "What specific access level constraint did the user define for the Sales Leads regarding the authentication service?",
          "answer_type": "short_answer",
          "gold_answer": "Read access only",
          "predicted_answer": "read access",
          "retrieved_context": [
            "Sales leads need read access.",
            "User wonders about the auth service.",
            "Alex is asking whether auth service is down"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 592.7069187164307,
          "generation_latency_ms": 2612.5457286834717,
          "total_latency_ms": 3205.2526473999023
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider is the company's email server hosted on?",
          "answer_type": "short_answer",
          "gold_answer": "not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User has a hybrid cloud setup.",
            "User states that the rest of services are on Amazon.",
            "User wants to double-check hosting situation for main databases"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 389.61100578308105,
          "generation_latency_ms": 2610.820770263672,
          "total_latency_ms": 3000.431776046753
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the pet owned by the Sales Lead named Liam?",
          "answer_type": "short_answer",
          "gold_answer": "not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex mentions Liam as a sales lead",
            "Liam and Charlotte make a good sales team",
            "Liam works together with Charlotte on leads"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 405.0025939941406,
          "generation_latency_ms": 3588.47713470459,
          "total_latency_ms": 3993.4797286987305
        },
        {
          "probe_id": "procedural_knowledge-task_state_tracking-10",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "What follow-up action did the assistant commit to regarding the Product Designer's mockups?",
          "answer_type": "short_answer",
          "gold_answer": "Ping him",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Oliver has been chasing user about new product mockups.",
            "User will review mockups with Mia later if she's free",
            "User asks if Oliver uploaded new mockups."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 588.0458354949951,
          "generation_latency_ms": 2307.708978652954,
          "total_latency_ms": 2895.754814147949
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-11",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What specific system mechanism does the assistant use to verify permissions for services hosted on AWS?",
          "answer_type": "short_answer",
          "gold_answer": "IAM roles",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User states that the rest of services are on Amazon.",
            "Alex believes auth service and primary databases are on AWS.",
            "User can breathe as long as the AWS environment is stable"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 264.1434669494629,
          "generation_latency_ms": 3103.5914421081543,
          "total_latency_ms": 3367.734909057617
        }
      ],
      "summary": {
        "overall_accuracy": 0.3333333333333333,
        "total_score": 4,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 12,
            "accuracy": 0.3333333333333333
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_029.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 26,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 66.57342886924744,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the 'cofounder' that the user mentions is paranoid about vendor lock-in?",
          "answer_type": "short_answer",
          "gold_answer": "Mia",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex's cofounder asks why we don't use a single provider.",
            "User's cofounder has been dragging them through strategy meetings all morning.",
            "User's cofounder is worried about multi-cloud costs."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 282.7293872833252,
          "generation_latency_ms": 4086.639642715454,
          "total_latency_ms": 4369.369029998779
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "On which cloud provider's infrastructure are the databases PrimaryDB6 and PrimaryDB7 hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "PrimaryDB7 and PrimaryDB6 are struggling under load",
            "PrimaryDB6 is on Azure.",
            "PrimaryDB7 is on Azure."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 771.3351249694824,
          "generation_latency_ms": 2347.123146057129,
          "total_latency_ms": 3118.4582710266113
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which specific service hosted on AWS is currently reporting conflicting version headers?",
          "answer_type": "short_answer",
          "gold_answer": "CacheLayer4",
          "predicted_answer": "main AWS cache service",
          "retrieved_context": [
            "User is seeing weird behavior on the caching service hosted on AWS.",
            "User wants to check the cache service on AWS",
            "User notes that the user was supposed to test a new version on the AWS box"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 362.123966217041,
          "generation_latency_ms": 3441.469669342041,
          "total_latency_ms": 3803.593635559082
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-1",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "The user implies a hard constraint against running which software version in the production environment?",
          "answer_type": "short_answer",
          "gold_answer": "v2.0.0-beta",
          "predicted_answer": "beta version",
          "retrieved_context": [
            "User wants confirmation that the beta version is not running in production.",
            "User says beta in production is risky.",
            "User expects the system to be locked on version 1.2.0."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 494.6141242980957,
          "generation_latency_ms": 2757.4477195739746,
          "total_latency_ms": 3252.0618438720703
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "In the session immediately following the discussion about the failed blue-green deployment, what personal task did the user ask to be reminded of?",
          "answer_type": "short_answer",
          "gold_answer": "Pick up dry cleaning",
          "predicted_answer": "to pick up espresso beans later",
          "retrieved_context": [
            "User thinks the issue is a failed blue-green deployment.",
            "User wants a reminder to update their cofounder on infrastructure spend later",
            "User will ping DevOps lead about the dashboard flickering."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 356.30106925964355,
          "generation_latency_ms": 4181.130170822144,
          "total_latency_ms": 4537.431240081787
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What deployment strategy did the user suspect caused the split-brain situation on the cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "Blue-green deployment",
          "predicted_answer": "failed blue-green deployment",
          "retrieved_context": [
            "User observes a split-brain situation with versioning on the caching service.",
            "User thinks the issue is a split-brain problem",
            "User is worried about the cache layer"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 831.7444324493408,
          "generation_latency_ms": 2214.022636413574,
          "total_latency_ms": 3045.767068862915
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's repeated requests across sessions, what specific beverage is essential to their morning routine?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Double espresso",
          "retrieved_context": [
            "User wants a reminder to pick up espresso beans later.",
            "User has a double espresso.",
            "User wants a reminder to grab a double espresso in about ten minutes."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 303.39503288269043,
          "generation_latency_ms": 4075.923442840576,
          "total_latency_ms": 4379.318475723267
        },
        {
          "probe_id": "preference_learning-explicit_preferences-1",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Does the user approve of running the beta version of the cache layer in the production environment?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "The beta version of the cache service was not supposed to hit production",
            "User is worried about the cache layer",
            "User wants confirmation that the beta version is not running in production."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 629.5425891876221,
          "generation_latency_ms": 2274.897813796997,
          "total_latency_ms": 2904.440402984619
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific software version is PrimaryDB2 currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Latency between PrimaryDB7 and PrimaryDB6 is weird.",
            "PrimaryDB7 and PrimaryDB6 are struggling under load",
            "Alex wants confirmation of where primary databases are hosted."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 351.4518737792969,
          "generation_latency_ms": 2615.138292312622,
          "total_latency_ms": 2966.590166091919
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-2",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Sales Lead's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks about Ava's cat.",
            "User believes the DevOps lead is already looking at it or is distracted by her cat.",
            "User will ask Ava to look into the issue, provided Ava is not distracted by her pet."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 295.46117782592773,
          "generation_latency_ms": 3103.6934852600098,
          "total_latency_ms": 3399.1546630859375
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "Which team lead was identified as requiring the beta version of the cache layer for a new UI?",
          "answer_type": "short_answer",
          "gold_answer": "Olivia",
          "predicted_answer": "Olivia",
          "retrieved_context": [
            "The beta version of the cache service was not supposed to hit production",
            "User asks about cache layer version mismatch mentioned by Elijah.",
            "User is worried about the cache layer"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 761.833906173706,
          "generation_latency_ms": 2396.9156742095947,
          "total_latency_ms": 3158.749580383301
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-1",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "When the user requested a health check on the 'databases hosted on Azure', which specific system identifiers did the assistant report on?",
          "answer_type": "short_answer",
          "gold_answer": "PrimaryDB7 and PrimaryDB6",
          "predicted_answer": "PrimaryDB7, PrimaryDB6",
          "retrieved_context": [
            "User wants a quick health check on databases hosted on Azure.",
            "User wants to check Azure instances.",
            "PrimaryDB7 is on Azure."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 343.88208389282227,
          "generation_latency_ms": 2857.4461936950684,
          "total_latency_ms": 3201.3282775878906
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 3,
            "count": 9,
            "accuracy": 0.3333333333333333
          },
          "boolean": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_030.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 26,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 9.28494668006897,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does system:loadbalancer_3 hosted on?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User will get backend lead to look at the load balancer issue.",
            "User wants information on the load balancer on AWS.",
            "User is unsure if beta version was pushed to LoadBalancer7 on AWS"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 390.2571201324463,
          "generation_latency_ms": 2341.0897254943848,
          "total_latency_ms": 2731.346845626831
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User has a hike planned tomorrow.",
            "User asks if Sophia is free",
            "User is asking about the weather for this evening."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 363.1575107574463,
          "generation_latency_ms": 2297.001361846924,
          "total_latency_ms": 2660.15887260437
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 1,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_031.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 27,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 11.518900632858276,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does person:user has role?",
          "answer_type": "short_answer",
          "gold_answer": "CTO",
          "predicted_answer": "Grant full access to Google Cloud database",
          "retrieved_context": [
            "Will needs AuthService8 stable for his data science models today",
            "User is worried about AuthService8.",
            "User wants to check the Microsoft environment login service behavior."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 414.37363624572754,
          "generation_latency_ms": 3751.6684532165527,
          "total_latency_ms": 4166.04208946228
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "No",
          "retrieved_context": [
            "User asks if it's supposed to rain today.",
            "User wants a reminder to check the weather for Saturday because they are thinking about golfing.",
            "User is worried about cloud spend this month."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 627.1424293518066,
          "generation_latency_ms": 2658.1437587738037,
          "total_latency_ms": 3285.2861881256104
        }
      ],
      "summary": {
        "overall_accuracy": 0.0,
        "total_score": 0,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_032.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 29,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 56.31493043899536,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which individual is the user referring to when mentioning their 'cofounder' who is concerned about quarterly report data?",
          "answer_type": "short_answer",
          "gold_answer": "Oliver",
          "predicted_answer": "Oliver",
          "retrieved_context": [
            "User has a cofounder who was asking about new dashboard features.",
            "User is a founder.",
            "User has a sync later with the cofounder."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 478.37305068969727,
          "generation_latency_ms": 2662.1525287628174,
          "total_latency_ms": 3140.5255794525146
        },
        {
          "probe_id": "world_modeling-category_membership-2",
          "pillar": "world_modeling",
          "subpillar": "type_category_membership",
          "question": "Among the discussed systems, which service is the outlier regarding its hosting provider compared to the primary databases?",
          "answer_type": "short_answer",
          "gold_answer": "CacheLayer1",
          "predicted_answer": "cache layer",
          "retrieved_context": [
            "User says not all services have been migrated to AWS yet.",
            "Will is dealing with Amazon infrastructure for primary databases",
            "There are a couple of engines running on Bezos's servers"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 405.57074546813965,
          "generation_latency_ms": 3370.2404499053955,
          "total_latency_ms": 3775.811195373535
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the name of the pet belonging to the team member who holds the role of Product Designer?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "User has a pet.",
            "Olivia posted a photo of her pet sleeping on her keyboard during the design review",
            "User asks whether product designer sent new mockups."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 586.5228176116943,
          "generation_latency_ms": 3415.119409561157,
          "total_latency_ms": 4001.6422271728516
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-4",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "According to the system signals discussed in the latest sessions, which two versions of the analytics engine are running simultaneously?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "AnalyticsEngine3",
          "retrieved_context": [
            "User sees two different versions active for AnalyticsEngine3.",
            "User wants to check if update to AnalyticsEngine3 went through",
            "User's cofounder asked about the status of AnalyticsEngine3."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 621.9353675842285,
          "generation_latency_ms": 2329.4832706451416,
          "total_latency_ms": 2951.41863822937
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-5",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific event caused the delay in the Product Designer uploading the new assets?",
          "answer_type": "short_answer",
          "gold_answer": "Her cat knocked over a plant",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks whether product designer sent new mockups.",
            "User's cofounder was bugging about dashboard lag.",
            "User believes Will tried to sneak a beta test into production."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 368.61300468444824,
          "generation_latency_ms": 3567.638158798218,
          "total_latency_ms": 3936.251163482666
        },
        {
          "probe_id": "temporal_episodic-sequencing-6",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the discussion about the Google Cloud latency occur before or after the user first mentioned the dual-version issue with the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "After",
          "predicted_answer": "Before",
          "retrieved_context": [
            "There is a cache layer stranded on Google's cloud",
            "Liam hates the multi-cloud experiment setup because of latency.",
            "User asks if the cache layer is in the same region as the third analytics engine."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 610.0668907165527,
          "generation_latency_ms": 4405.655145645142,
          "total_latency_ms": 5015.722036361694
        },
        {
          "probe_id": "preference_learning-induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's complaints about the infrastructure, what architectural arrangement does the user implicitly dislike?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-cloud hosting",
          "predicted_answer": "Multi-cloud experiment setup",
          "retrieved_context": [
            "Liam hates the multi-cloud experiment setup because of latency.",
            "User feels hosting strategy is fragmented",
            "User is staring at the infrastructure map"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 600.4178524017334,
          "generation_latency_ms": 2202.8682231903076,
          "total_latency_ms": 2803.286075592041
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider is the company's email server hosted on?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User always mixes up AWS and GCP",
            "User wants to know if the box is still on Amazon's cloud.",
            "Will is dealing with Amazon infrastructure for primary databases"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 283.2446098327637,
          "generation_latency_ms": 3507.8368186950684,
          "total_latency_ms": 3791.081428527832
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the current VP of Marketing?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User has cofounder Oliver",
            "User asks whether product designer sent new mockups.",
            "User's cofounder asked about the status of AnalyticsEngine3."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 752.3579597473145,
          "generation_latency_ms": 2845.867872238159,
          "total_latency_ms": 3598.2258319854736
        },
        {
          "probe_id": "procedural_knowledge-task_state-10",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "Why is the DevOps lead currently unable to assist with migrating the cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "Swamped with deployment pipeline",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User has not migrated the cache layer yet.",
            "User may need Will to investigate migrating CacheLayer1.",
            "User forgot that cache layer and analytics engine are split."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 337.12029457092285,
          "generation_latency_ms": 2906.0680866241455,
          "total_latency_ms": 3243.1883811950684
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 5,
        "count": 10,
        "by_answer_type": {
          "short_answer": {
            "total": 3,
            "count": 8,
            "accuracy": 0.375
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_033.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 29,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 68.7511556148529,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user referring to when they mention their cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Ava",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder asked about latency.",
            "User identifies Mia as the DevOps person",
            "User asks if Lucas is the other DevOps person."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 456.1295509338379,
          "generation_latency_ms": 2466.4766788482666,
          "total_latency_ms": 2922.6062297821045
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "On which cloud provider is the service managed by the backend lead testing the beta version hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Microsoft",
          "retrieved_context": [
            "User asks whether the analytics module is hosted on AWS",
            "User follows a multi-cloud strategy",
            "User often mixes up which cloud auth service is on."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 292.64044761657715,
          "generation_latency_ms": 3394.878387451172,
          "total_latency_ms": 3687.518835067749
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the name of the pet belonging to the DevOps team member who was worried about the update?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Mia was worried the update didn't go through.",
            "User asks if Lucas is the other DevOps person.",
            "User wants to ping the DevOps team."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 803.9157390594482,
          "generation_latency_ms": 3147.23539352417,
          "total_latency_ms": 3951.151132583618
        },
        {
          "probe_id": "declarative_reasoning-verbatim_recall-3",
          "pillar": "declarative_reasoning",
          "subpillar": "verbatim_recall",
          "question": "What specific two-word phrase did the user use to describe the situation where the cache layer was reporting two different version headers?",
          "answer_type": "verbatim",
          "gold_answer": "split-brain situation",
          "predicted_answer": "Conflicting info",
          "retrieved_context": [
            "User is looking at logs for the cache layer and sees two different version headers.",
            "User believes version mismatch in CacheLayer5 is causing issues.",
            "User asks whether the cache layer is running the stable release or the beta build, and swears that User rolled back the beta yesterday, and it is showing two different versions."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 618.3047294616699,
          "generation_latency_ms": 4462.406873703003,
          "total_latency_ms": 5080.711603164673
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-4",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user ask for a reminder about the dentist appointment before or after asking for the dry cleaning reminder?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants a reminder to pick up dry cleaning later.",
            "User wants a reminder to call the dentist at 2 PM",
            "User wants a reminder to grab coffee in ten minutes"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 786.1371040344238,
          "generation_latency_ms": 3593.5044288635254,
          "total_latency_ms": 4379.641532897949
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-5",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why did the user suspect a version mismatch was causing issues with the dashboard?",
          "answer_type": "short_answer",
          "gold_answer": "Lag / Slowness",
          "predicted_answer": "User believes version mismatch in CacheLayer5 is causing issues.",
          "retrieved_context": [
            "User sees a version mismatch in the cluster",
            "Mia from the ops team thinks there is a version mismatch.",
            "User had a long strategy session with cofounder and is trying to figure out why dashboard is acting up."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 567.5745010375977,
          "generation_latency_ms": 2340.6059741973877,
          "total_latency_ms": 2908.1804752349854
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on previous orders, what food does the user prefer for team lunches?",
          "answer_type": "short_answer",
          "gold_answer": "Pizza",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to order pizza lunch for the team later.",
            "User wants to book a table for lunch tomorrow at an Italian place downtown.",
            "User wants lunch at 12:30."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 351.61900520324707,
          "generation_latency_ms": 2869.518280029297,
          "total_latency_ms": 3221.137285232544
        },
        {
          "probe_id": "preference_learning-explicit_preferences-7",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Does the user prefer to message Mia personally about the update or have the assistant do it?",
          "answer_type": "short_answer",
          "gold_answer": "Personally",
          "predicted_answer": "Personally",
          "retrieved_context": [
            "User will message Mia",
            "User wants a reminder to ask Mia how Luna is doing later",
            "User intends to contact Mia."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 363.22689056396484,
          "generation_latency_ms": 3193.934440612793,
          "total_latency_ms": 3557.161331176758
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of James's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User will tell James",
            "User thinks James is helping Lucas with the migration of the fourth primary database to Microsoft's cloud today",
            "James is asking about the auth service."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 867.6273822784424,
          "generation_latency_ms": 3337.4974727630615,
          "total_latency_ms": 4205.124855041504
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What version of software is running on the primary database hosted on Azure?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to check status of primary DB in Azure.",
            "User wants to know location of primary database not on Azure",
            "The third primary database is hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 615.6108379364014,
          "generation_latency_ms": 3797.853946685791,
          "total_latency_ms": 4413.464784622192
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-10",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "Who are the two individuals usually responsible for handling infrastructure tickets?",
          "answer_type": "short_answer",
          "gold_answer": "Mia and Lucas",
          "predicted_answer": "Mia and Lucas",
          "retrieved_context": [
            "Mia and Lucas are handling the infrastructure pipelines",
            "User wants to break down infrastructure map by provider",
            "User does not want to report an outage"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 672.9974746704102,
          "generation_latency_ms": 2681.515693664551,
          "total_latency_ms": 3354.513168334961
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-11",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "Who should be contacted regarding issues with the backend beta push?",
          "answer_type": "short_answer",
          "gold_answer": "Will",
          "predicted_answer": "DevOps team",
          "retrieved_context": [
            "User believes someone pushed beta to prod.",
            "User wants to ping the DevOps team.",
            "User pushed beta version of cache service to Microsoft environment recently."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 283.57768058776855,
          "generation_latency_ms": 2157.3562622070312,
          "total_latency_ms": 2440.9339427948
        }
      ],
      "summary": {
        "overall_accuracy": 0.3333333333333333,
        "total_score": 4,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 2,
            "count": 9,
            "accuracy": 0.2222222222222222
          },
          "verbatim": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_034.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 65.50291514396667,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual referred to as the user's 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Charlotte",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User identifies Sophia as the DevOps lead.",
            "User was on a call with cofounder until late",
            "User's cofounder will flip if login breaks during investor call."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 423.77471923828125,
          "generation_latency_ms": 2744.776964187622,
          "total_latency_ms": 3168.5516834259033
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which team member is the owner of the pet named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Mia",
          "predicted_answer": "Mia",
          "retrieved_context": [
            "User expresses sympathy for Luna.",
            "User is considering a toy for Luna.",
            "Mia won't stop talking about Luna."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 283.9066982269287,
          "generation_latency_ms": 2492.025375366211,
          "total_latency_ms": 2775.9320735931396
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which infrastructure component is hosted on a different cloud provider than the Primary Database and Cache Layer?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer8",
          "predicted_answer": "Load balancer",
          "retrieved_context": [
            "User is annoyed that the load balancer is stranded while primary database and cache layer are on GCP.",
            "User wants to see if cross-cloud latency is acting up again, and thinks traffic routing is messing up while the database and cache are fine on GCP, and notes that cross-cloud latency is affecting beta headers.",
            "User feels the setup is disjointed because main database and cache layer are on Google, and User thought the setup was split."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 386.78884506225586,
          "generation_latency_ms": 2802.8910160064697,
          "total_latency_ms": 3189.6798610687256
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Is the authentication service currently running a single version or multiple versions simultaneously?",
          "answer_type": "short_answer",
          "gold_answer": "Multiple versions",
          "predicted_answer": "Multiple versions simultaneously",
          "retrieved_context": [
            "User wants to know current live version of authentication service.",
            "User says that she is managing the mixed deployment for the auth service.",
            "User wants to verify that the canary deployment of the authentication service is working."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 385.4703903198242,
          "generation_latency_ms": 2438.71808052063,
          "total_latency_ms": 2824.188470840454
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "According to the production logs, what is the primary architectural cause of the observed latency?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-cloud hop",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is experiencing latency on the edge",
            "User wants a note to discuss cross-cloud latency during standup.",
            "User wants to see if cross-cloud latency is acting up again, and thinks traffic routing is messing up while the database and cache are fine on GCP, and notes that cross-cloud latency is affecting beta headers."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 336.5907669067383,
          "generation_latency_ms": 4233.154535293579,
          "total_latency_ms": 4569.745302200317
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did Luna knock over a plant before or after she was reported getting stuck in a box?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User says Mia told her that Luna knocked a coffee mug onto her laptop this morning",
            "Luna jumped onto Mia's keyboard during that video.",
            "User is considering a toy for Luna."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 651.9627571105957,
          "generation_latency_ms": 2604.8896312713623,
          "total_latency_ms": 3256.852388381958
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the frontend service?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Amazon",
          "retrieved_context": [
            "User wants confirmation of where the ingress point is hosted, and notes that ingress is problematic for AuthService5.",
            "User needs to explain why paying for AWS load balancer when the rest of the stack is on Google.",
            "LoadBalancer8 looks out of place to the user, and is hosted on AWS."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 530.0946235656738,
          "generation_latency_ms": 4112.418651580811,
          "total_latency_ms": 4642.513275146484
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-2",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the pet owned by the Sales Lead?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User says the Sales Lead wants the shiny new thing immediately.",
            "User identifies Sophia as the DevOps lead.",
            "User says the Sales Lead does not have to carry the pager."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 868.9966201782227,
          "generation_latency_ms": 2831.7923545837402,
          "total_latency_ms": 3700.788974761963
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Does the user prefer maintaining the current multi-cloud setup or consolidating the infrastructure?",
          "answer_type": "short_answer",
          "gold_answer": "Consolidating",
          "predicted_answer": "Consolidating the infrastructure",
          "retrieved_context": [
            "User believes they need to consolidate the stack.",
            "User needs to explain why paying for AWS load balancer when the rest of the stack is on Google.",
            "User remembers that one component is stranded on Amazon's cloud due to legacy configuration."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 297.88970947265625,
          "generation_latency_ms": 1934.401035308838,
          "total_latency_ms": 2232.290744781494
        },
        {
          "probe_id": "preference_learning-preference_induction-2",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "How does the user feel about the topology map showing the load balancer on AWS?",
          "answer_type": "short_answer",
          "gold_answer": "Annoyed",
          "predicted_answer": "Annoyed and it looks out of place.",
          "retrieved_context": [
            "User needs to explain why paying for AWS load balancer when the rest of the stack is on Google.",
            "LoadBalancer8 looks out of place to the user, and is hosted on AWS.",
            "User is annoyed that the load balancer is stranded while primary database and cache layer are on GCP."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 375.1351833343506,
          "generation_latency_ms": 2789.7090911865234,
          "total_latency_ms": 3164.844274520874
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What general observation did the assistant make regarding the nature of architectures that span AWS and GCP?",
          "answer_type": "short_answer",
          "gold_answer": "They can be complex",
          "predicted_answer": "Disjointed",
          "retrieved_context": [
            "User needs to explain why paying for AWS load balancer when the rest of the stack is on Google.",
            "User is concerned about cross-cloud latency, high latency on ingress point, and traffic ingress on Amazon while heavy lifting elsewhere causes lag, which is kept separate to avoid a single point of failure provider-wise, and notes that the cross-cloud hop is costing a few milliseconds.",
            "User is annoyed that the load balancer is stranded while primary database and cache layer are on GCP."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 333.12296867370605,
          "generation_latency_ms": 3739.023208618164,
          "total_latency_ms": 4072.14617729187
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-1",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "When the user mentioned buying treats for Luna, what action did the assistant confirm taking?",
          "answer_type": "short_answer",
          "gold_answer": "Added a reminder",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to pick up treats for Luna on their way home.",
            "User is considering a toy for Luna.",
            "User expresses sympathy for Luna."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 740.5052185058594,
          "generation_latency_ms": 2702.956199645996,
          "total_latency_ms": 3443.4614181518555
        }
      ],
      "summary": {
        "overall_accuracy": 0.3333333333333333,
        "total_score": 4,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 3,
            "count": 10,
            "accuracy": 0.3
          },
          "abstain": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_035.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 36,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 54.24059200286865,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user referring to when they mention a meeting with their cofounder?",
          "answer_type": "short_answer",
          "gold_answer": "Mia",
          "predicted_answer": "Mia",
          "retrieved_context": [
            "User's cofounder is running the meeting.",
            "User has a meeting with cofounder in an hour.",
            "User wants to inform cofounder that user is free after lunch."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 448.580265045166,
          "generation_latency_ms": 2913.5031700134277,
          "total_latency_ms": 3362.0834350585938
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the name of the pet belonging to the Sales Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "Sales Lead has a new cat named Luna who is tearing up furniture.",
            "User is asking whether the Sales Lead sent projections.",
            "User thinks the Sales team is taking a break."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 401.9138813018799,
          "generation_latency_ms": 2063.5268688201904,
          "total_latency_ms": 2465.4407501220703
        },
        {
          "probe_id": "preference_learning-preference_induction-3",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's morning routines, what beverage do they require to function properly?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "espresso",
          "retrieved_context": [
            "User needs another espresso before functioning properly today.",
            "User needs to grab coffee soon.",
            "User needs to grab lunch soon."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 375.1380443572998,
          "generation_latency_ms": 2623.077392578125,
          "total_latency_ms": 2998.215436935425
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-4",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "On which cloud provider is the primary database hosted?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User thinks cross-cloud latency might be the issue.",
            "CacheLayer6 is on Amazon's servers",
            "User was reviewing Nebula infrastructure and noticed something weird with the AWS cache service"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 365.0209903717041,
          "generation_latency_ms": 3532.2725772857666,
          "total_latency_ms": 3897.2935676574707
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-5",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "When the user requests the 'morning status checks', which service is verified immediately after the load balancers?",
          "answer_type": "short_answer",
          "gold_answer": "AuthService9",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to check status of load balancers on Google Cloud.",
            "User wants to pull up metrics for load balancers and feels latency is creeping up again.",
            "Latency between auth service and load balancers should be minimal because both are on Google's cloud and in the same region."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 611.2954616546631,
          "generation_latency_ms": 3506.6914558410645,
          "total_latency_ms": 4117.9869174957275
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-6",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "During the conversation where the user mentioned being 'barely awake', what specific data were they preparing to review with Mia?",
          "answer_type": "short_answer",
          "gold_answer": "Quarterly figures",
          "predicted_answer": "weird data on the UI",
          "retrieved_context": [
            "User has a meeting with Mia.",
            "User is asking if Mia has come in yet",
            "User is barely awake."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 542.5877571105957,
          "generation_latency_ms": 3740.501642227173,
          "total_latency_ms": 4283.089399337769
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-7",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "Given that the authentication service is co-located with the load balancers, which cloud provider hosts it?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google's cloud",
          "retrieved_context": [
            "Latency between auth service and load balancers should be minimal because both are on Google's cloud and in the same region.",
            "User needs to explain that load balancers and auth service are on Google's platform",
            "User asks if auth service on GCP is behaving."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 796.3807582855225,
          "generation_latency_ms": 2174.368381500244,
          "total_latency_ms": 2970.7491397857666
        },
        {
          "probe_id": "world_modeling-relationship_mapping-8",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the job title of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales Lead",
          "retrieved_context": [
            "Sales Lead has a new cat named Luna who is tearing up furniture.",
            "Olivia's cat Luna jumped on keyboard during client call",
            "User wants to see how Luna is doing after the vet visit."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 457.5221538543701,
          "generation_latency_ms": 3534.667491912842,
          "total_latency_ms": 3992.189645767212
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "What is the single definitive running version of CacheLayer6?",
          "answer_type": "short_answer",
          "gold_answer": "Ambiguous",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know what version CacheLayer6 is running.",
            "User wants to start with CacheLayer6.",
            "User is looking at the dashboard for CacheLayer6"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 582.5059413909912,
          "generation_latency_ms": 2243.5266971588135,
          "total_latency_ms": 2826.0326385498047
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-10",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "In the session where the user reviewed architecture diagrams, did they ask about the load balancers before or after asking for a lunch reminder?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Before",
          "retrieved_context": [
            "User is reviewing architecture diagrams before weekly sync with cofounder.",
            "User wants to pull up metrics for load balancers and feels latency is creeping up again.",
            "Oliver is asking whether load balancers are affected by cache issues"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 359.03143882751465,
          "generation_latency_ms": 3048.286199569702,
          "total_latency_ms": 3407.317638397217
        }
      ],
      "summary": {
        "overall_accuracy": 0.6,
        "total_score": 6,
        "count": 10,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 9,
            "accuracy": 0.5555555555555556
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_036.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 11,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 59.89019012451172,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual referred to by the user as 'my cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "User's cofounder was asking about the caching service earlier.",
            "User is the CTO.",
            "User's cofounder James dragged User into a strategy meeting first thing."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 379.5032501220703,
          "generation_latency_ms": 2698.93741607666,
          "total_latency_ms": 3078.4406661987305
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What professional role is shared by both Emma and Mia?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales efforts leader",
          "retrieved_context": [
            "Emma and Mia are handling client expectations.",
            "Emma and Mia have been complaining all week.",
            "User will chase Emma or Mia for quarterly figures."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 333.5151672363281,
          "generation_latency_ms": 2439.908742904663,
          "total_latency_ms": 2773.423910140991
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which two specific cloud providers are generating the high egress fees due to cross-cloud traffic?",
          "answer_type": "short_answer",
          "gold_answer": "Azure and AWS",
          "predicted_answer": "Azure and GCP",
          "retrieved_context": [
            "This setup is causing high egress fees.",
            "User is concerned about infrastructure costs due to paying for three different clouds.",
            "User is concerned about multi-cloud architecture."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 741.0140037536621,
          "generation_latency_ms": 3698.4996795654297,
          "total_latency_ms": 4439.513683319092
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-4",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "Which infrastructure component is violating the production stability constraint by running a beta version?",
          "answer_type": "short_answer",
          "gold_answer": "CacheLayer5",
          "predicted_answer": "Caching layer",
          "retrieved_context": [
            "User told them not to mix the beta in production yet.",
            "James is concerned about platform stability today.",
            "Cache fleet is split: some nodes on stable 1.2, others on 2.0 beta responding to requests."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 727.5328636169434,
          "generation_latency_ms": 2751.6942024230957,
          "total_latency_ms": 3479.227066040039
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What specific disruption involving a pet occurred during the frontend sync meeting?",
          "answer_type": "short_answer",
          "gold_answer": "Luna jumped on keyboard",
          "predicted_answer": "Luna jumped on Olivia's keyboard",
          "retrieved_context": [
            "User suspects frontend team pushed beta config by accident",
            "User wants to ask the frontend lead about a UI glitch.",
            "User needs to schedule a sync with frontend team later."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 344.0849781036377,
          "generation_latency_ms": 2496.509075164795,
          "total_latency_ms": 2840.5940532684326
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-6",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why is the user specifically worried about James discovering the current state of the cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "Testing beta in production",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Cache layer is weird.",
            "User will let James know about version mismatch on CacheLayer5.",
            "User is inspecting the caching layer."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 338.6094570159912,
          "generation_latency_ms": 3120.9681034088135,
          "total_latency_ms": 3459.5775604248047
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-7",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the company's email server?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks if the main database is on Amazon.",
            "User's main database is hosted on Azure.",
            "User finds managing credentials across clouds painful and asks why main database is on Microsoft's cloud."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 717.0312404632568,
          "generation_latency_ms": 2938.0276203155518,
          "total_latency_ms": 3655.0588607788086
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "What is the specific version number currently running on the PrimaryDB5 instance?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is worried about latency on PrimaryDB5.",
            "The latency on PrimaryDB5 is making the dashboard slow for the sales team.",
            "User wants to check the main database"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 568.7973499298096,
          "generation_latency_ms": 2945.6827640533447,
          "total_latency_ms": 3514.4801139831543
        },
        {
          "probe_id": "preference_learning-preference_induction-9",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "When the assistant offered to draft a message to James regarding the version mismatch, how did the user prefer to handle the communication?",
          "answer_type": "short_answer",
          "gold_answer": "Handle it personally",
          "predicted_answer": "User will handle James himself",
          "retrieved_context": [
            "User has a sync with cofounder James in an hour.",
            "User had a phone call with James, who is stressing about the quarterly board meeting and wants everything perfect.",
            "User will let James know about version mismatch on CacheLayer5."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 367.14744567871094,
          "generation_latency_ms": 2773.1640338897705,
          "total_latency_ms": 3140.3114795684814
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-10",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "According to the user's routine, what is the required duration for steeping tea?",
          "answer_type": "short_answer",
          "gold_answer": "Ten minutes",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User needs coffee before 9 AM.",
            "User's coffee hasn't kicked in yet",
            "User has a double espresso."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 371.86527252197266,
          "generation_latency_ms": 3341.9742584228516,
          "total_latency_ms": 3713.839530944824
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-11",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "Based on the user's discussions about the cloud bill, what architectural choice is identified as the primary cause of high costs?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-cloud data transfer",
          "predicted_answer": "Multi-cloud setup",
          "retrieved_context": [
            "User is concerned about infrastructure costs due to paying for three different clouds.",
            "User is concerned about multi-cloud architecture.",
            "User finds managing credentials across clouds painful and asks why main database is on Microsoft's cloud."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 652.4991989135742,
          "generation_latency_ms": 2831.95161819458,
          "total_latency_ms": 3484.4508171081543
        }
      ],
      "summary": {
        "overall_accuracy": 0.36363636363636365,
        "total_score": 4,
        "count": 11,
        "by_answer_type": {
          "short_answer": {
            "total": 2,
            "count": 9,
            "accuracy": 0.2222222222222222
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_037.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 28,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 72.88689756393433,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which specific individual is the user referring to as their 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "User has a cofounder",
            "User had a call with cofounder",
            "User had a long sync with cofounder James"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 310.04881858825684,
          "generation_latency_ms": 2314.2683506011963,
          "total_latency_ms": 2624.317169189453
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which team member flagged the latency issues on the database hosted on Google Cloud?",
          "answer_type": "short_answer",
          "gold_answer": "Olivia",
          "predicted_answer": "Olivia",
          "retrieved_context": [
            "Olivia, backend lead, flagged heavy latency on main database in Google Cloud environment.",
            "User is worried about database latency, specifically PrimaryDB7",
            "User reports that a load balancer hosted on Google Cloud was mentioned"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 337.2762203216553,
          "generation_latency_ms": 2347.651481628418,
          "total_latency_ms": 2684.9277019500732
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Despite earlier conflicting headers, what version is the GCP load balancer confirmed to be running after the update?",
          "answer_type": "short_answer",
          "gold_answer": "v2.0.0-beta",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is checking status of new GCP load balancer before grabbing second coffee.",
            "User feels there might be a version mismatch on GCP balancer",
            "LoadBalancer9 is on GCP."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 420.7758903503418,
          "generation_latency_ms": 3799.7961044311523,
          "total_latency_ms": 4220.571994781494
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-1",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the 'segregated' load balancer hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is focusing on the main load balancer in Google Cloud",
            "Other load balancer hasn't migrated from Microsoft's cloud yet",
            "User reports that a load balancer hosted on Google Cloud was mentioned"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 629.8580169677734,
          "generation_latency_ms": 3751.7120838165283,
          "total_latency_ms": 4381.570100784302
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific action taken by the DevOps lead caused LoadBalancer9 to switch to the beta version?",
          "answer_type": "short_answer",
          "gold_answer": "pushed an update",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Will deployed the beta version of LoadBalancer9 by accident.",
            "Olivia noticed a weird version mismatch on LoadBalancer9",
            "User wants to flag issue with LoadBalancer9 version."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 692.0578479766846,
          "generation_latency_ms": 4199.282169342041,
          "total_latency_ms": 4891.340017318726
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user request the reminder to water plants before or after the reminder to pick up dry cleaning mentioned in Session llm-22?",
          "answer_type": "short_answer",
          "gold_answer": "after",
          "predicted_answer": "Before",
          "retrieved_context": [
            "User wants reminder to pick up dry cleaning later",
            "User wants a reminder to water the plants in the office lobby later today.",
            "User wants a reminder to pick up dry cleaning at 5 PM."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 780.8318138122559,
          "generation_latency_ms": 3354.984760284424,
          "total_latency_ms": 4135.81657409668
        },
        {
          "probe_id": "preference_learning-explicit_preferences-1",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "When preparing reports for the CEO, what specific metric does he prefer to focus on?",
          "answer_type": "short_answer",
          "gold_answer": "uptime",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder is anxious about quarterly review",
            "User wants to provide an answer to cofounder about dashboard issue",
            "User had a sync with cofounder who is stressing about quarterly targets."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 578.8121223449707,
          "generation_latency_ms": 3630.777597427368,
          "total_latency_ms": 4209.589719772339
        },
        {
          "probe_id": "preference_learning-constraint_hierarchy-1",
          "pillar": "preference_learning",
          "subpillar": "constraint_hierarchy",
          "question": "The user is nervous about beta versions but accepts them under what condition?",
          "answer_type": "short_answer",
          "gold_answer": "Olivia signed off",
          "predicted_answer": "If Olivia signed off on backend",
          "retrieved_context": [
            "User is nervous about beta release but trusts it if Olivia signed off on backend.",
            "User's cofounder will flip if he sees the system is running a beta in the live environment",
            "Will will flip out if he finds out beta code hit production"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 964.5261764526367,
          "generation_latency_ms": 2276.310920715332,
          "total_latency_ms": 3240.8370971679688
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the pet belonging to the Product Designer named Lucas?",
          "answer_type": "short_answer",
          "gold_answer": "not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Lucas is obsessed with Luna",
            "Noah and Lucas are both handling product design.",
            "User says Lucas is covering the actual design work for the sprint"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 289.42394256591797,
          "generation_latency_ms": 4558.603763580322,
          "total_latency_ms": 4848.02770614624
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-2",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What software version is the Azure-hosted load balancer currently running?",
          "answer_type": "short_answer",
          "gold_answer": "not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex wants to know which load balancer is on Azure.",
            "User asks whether Azure load balancer shows similar version conflicts",
            "User asks which load balancer is currently in the Microsoft environment."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 689.4299983978271,
          "generation_latency_ms": 3878.024101257324,
          "total_latency_ms": 4567.454099655151
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What condition does the Backend Lead typically verify before allowing a rollout?",
          "answer_type": "short_answer",
          "gold_answer": "backend is solid",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User intends to loop in the backend lead to ensure APIs sync across clouds",
            "User needs to coordinate with the backend lead about discrepancies.",
            "User believes Olivia will be unhappy about a partial rollout and will flip if the backend gets unstable"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 616.0333156585693,
          "generation_latency_ms": 3437.913656234741,
          "total_latency_ms": 4053.9469718933105
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-1",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "How did the assistant determine the version conflict on LoadBalancer9?",
          "answer_type": "short_answer",
          "gold_answer": "checking logs",
          "predicted_answer": "Conflicting logs, conflicting headers, and dashboard indications.",
          "retrieved_context": [
            "User wants to know version of LoadBalancer9.",
            "User asks whether Azure load balancer shows similar version conflicts",
            "User wants to flag issue with LoadBalancer9 version."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 728.8932800292969,
          "generation_latency_ms": 3934.312343597412,
          "total_latency_ms": 4663.205623626709
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 12,
            "accuracy": 0.5
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_038.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 27,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 70.34549450874329,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which executive team member is reportedly concerned about the infrastructure costs?",
          "answer_type": "short_answer",
          "gold_answer": "Sophia",
          "predicted_answer": "Sophia, CEO, User's cofounder",
          "retrieved_context": [
            "Sophia is stressing about infrastructure costs",
            "Sophia will ask why infrastructure stability is wobbling.",
            "CEO is upset about the bill."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 609.1041564941406,
          "generation_latency_ms": 4018.559455871582,
          "total_latency_ms": 4627.663612365723
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which service is co-located on the same cloud provider as the system handling traffic flow?",
          "answer_type": "short_answer",
          "gold_answer": "CacheLayer3",
          "predicted_answer": "caching layer",
          "retrieved_context": [
            "User believes the service is hosted on Google Cloud Platform.",
            "User identifies bottleneck as hop from load balancer on Google's cloud",
            "User's services are split across different cloud providers and user knows hybrid setup will cause issues"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 617.0096397399902,
          "generation_latency_ms": 2633.714199066162,
          "total_latency_ms": 3250.7238388061523
        },
        {
          "probe_id": "declarative_reasoning-multi_hop-1",
          "pillar": "declarative_reasoning",
          "subpillar": "multi_hop_reasoning",
          "question": "The database connected to the Google-hosted load balancer is running on which infrastructure provider?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "Amazon Web Services",
          "retrieved_context": [
            "User states that the load balancer and caching layer are hosted on Google Cloud Platform",
            "User wants status of load balancer on Google's infrastructure",
            "User wants to cross-reference load balancer status with main database"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 352.1404266357422,
          "generation_latency_ms": 2477.191686630249,
          "total_latency_ms": 2829.332113265991
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What versions of the caching service are currently active according to the latest diagnostics?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to check the version of the cache service",
            "User wants status of the caching layer",
            "User will ask Elijah about cache service version"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 410.9477996826172,
          "generation_latency_ms": 2899.127721786499,
          "total_latency_ms": 3310.075521469116
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific deployment failure did the user identify as the cause of the cache latency spikes?",
          "answer_type": "short_answer",
          "gold_answer": "Stuck canary deployment",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User suspects latency is worse because database is not in same cloud environment as cache.",
            "User is seeing weird latency numbers on CacheLayer3 dashboard",
            "The third cache layer is misbehaving, is on Google's cloud, and has been experiencing weird latency all morning."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 364.7630214691162,
          "generation_latency_ms": 4181.62202835083,
          "total_latency_ms": 4546.385049819946
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user identify the stuck canary deployment before or after requesting a lunch reminder?",
          "answer_type": "short_answer",
          "gold_answer": "After",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User believes there is a stuck canary deployment",
            "User wants backend lead to confirm deployment status",
            "Elijah started a canary deployment without informing the user"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 619.1608905792236,
          "generation_latency_ms": 2649.2300033569336,
          "total_latency_ms": 3268.390893936157
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "How did the user respond to the assistant's offer to block calendar time for the hiking trip?",
          "answer_type": "short_answer",
          "gold_answer": "Deferred it",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants a reminder to ask Mia about latency between clouds later",
            "User hopes to go hiking this weekend",
            "User wants a reminder to buy coffee beans later."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 381.697416305542,
          "generation_latency_ms": 2988.5029792785645,
          "total_latency_ms": 3370.2003955841064
        },
        {
          "probe_id": "preference_learning-preference_induction-2",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What specific administrative action does the user consistently request across multiple sessions?",
          "answer_type": "short_answer",
          "gold_answer": "Setting reminders",
          "predicted_answer": "Investigate latency issues",
          "retrieved_context": [
            "User needs to investigate latency issues.",
            "User requests that the issue be flagged immediately for the backend team",
            "Mia needs to run heavy queries."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 390.14434814453125,
          "generation_latency_ms": 4235.631227493286,
          "total_latency_ms": 4625.775575637817
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the frontend application?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User believes the service is hosted on Google Cloud Platform.",
            "User believes the main database is hosted on Amazon Web Services.",
            "User states that the load balancer and caching layer are hosted on Google Cloud Platform"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 526.0317325592041,
          "generation_latency_ms": 3765.9552097320557,
          "total_latency_ms": 4291.98694229126
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-2",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the user's pet?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is asking about Noah's cat.",
            "User refers to Luna as a cat.",
            "User confirms cat Luna sleeping on keyboard"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 727.1275520324707,
          "generation_latency_ms": 2953.252077102661,
          "total_latency_ms": 3680.379629135132
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-1",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What method did the user employ to check for cross-cloud bottlenecks between GCP and AWS?",
          "answer_type": "short_answer",
          "gold_answer": "Cross-reference with database",
          "predicted_answer": "Looking at the GCP dashboard.",
          "retrieved_context": [
            "User identifies bottleneck as hop from load balancer on Google's cloud",
            "User states that the load balancer and caching layer are hosted on Google Cloud Platform",
            "User believes the service is hosted on Google Cloud Platform."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 406.7680835723877,
          "generation_latency_ms": 3674.0176677703857,
          "total_latency_ms": 4080.7857513427734
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What configuration state was determined to be the root cause of the conflicting signals in the cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "Split state",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User sees conflicting reports on versioning for CacheLayer3 and is questioning if caching layer is on the stable release agreed",
            "User is seeing weird latency numbers on CacheLayer3 dashboard",
            "User suspects latency is worse because database is not in same cloud environment as cache."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 731.9152355194092,
          "generation_latency_ms": 3322.2570419311523,
          "total_latency_ms": 4054.1722774505615
        }
      ],
      "summary": {
        "overall_accuracy": 0.3333333333333333,
        "total_score": 4,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 12,
            "accuracy": 0.3333333333333333
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_039.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 29,
      "num_probes": 2,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 11.841014623641968,
      "probe_results": [
        {
          "probe_id": "declarative_reasoning-factual_recall-0",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What does person:mia has role?",
          "answer_type": "short_answer",
          "gold_answer": "Frontend Lead",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Mia is working on the issue.",
            "User owes Mia a favor.",
            "User wants to check if Mia is online to ask her about UI components."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 648.9377021789551,
          "generation_latency_ms": 3245.694398880005,
          "total_latency_ms": 3894.63210105896
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-fallback",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Have I ever mentioned ski plans?",
          "answer_type": "abstain",
          "gold_answer": "No, not mentioned",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is mapping out the cloud footprint for a meeting with a cofounder later.",
            "User is asking whether cofounder said anything about board meeting.",
            "User's cofounder is concerned about cloud spend this month"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 630.1829814910889,
          "generation_latency_ms": 2718.468189239502,
          "total_latency_ms": 3348.651170730591
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 1,
        "count": 2,
        "by_answer_type": {
          "short_answer": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "declarative_reasoning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_040.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 31,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 74.41433429718018,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which cloud provider hosts the service that the Data Scientist complained about regarding latency?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "User says James was worried about latency on the Azure side.",
            "LoadBalancer1 is distributed across Google Cloud and Amazon Web Services.",
            "User thinks first load balancer was moved off Google Cloud."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 682.1763515472412,
          "generation_latency_ms": 4313.00163269043,
          "total_latency_ms": 4995.177984237671
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Who is the Backend Lead responsible for the service currently experiencing a version leak?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "User will grab James, who leads the backend team and knows if a deployment failed.",
            "Alex wants to know if backend lead finished migration for third auth service.",
            "User plans to ping Backend Lead about testing in prod."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 1566.5216445922852,
          "generation_latency_ms": 3081.693410873413,
          "total_latency_ms": 4648.215055465698
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the individual who set the Friday deadline for the visual language drafts?",
          "answer_type": "short_answer",
          "gold_answer": "CEO",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Emma wants drafts by Friday.",
            "Sophia and Will will handle the new visual language.",
            "Alex wants to review new mockups from design team."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 572.8158950805664,
          "generation_latency_ms": 2714.921236038208,
          "total_latency_ms": 3287.7371311187744
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-1",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What specific software versions were observed running on LoadBalancer2 during the latest infrastructure check?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User observed a discrepancy in logs regarding load balancer versioning.",
            "User believes the load balancer is running v2.0.0-beta",
            "Alex is confused about which version of LoadBalancer2 is live."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 371.3560104370117,
          "generation_latency_ms": 4134.484052658081,
          "total_latency_ms": 4505.840063095093
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-0",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the discussion about the Azure budget email occur before or after the user requested a dry cleaning reminder?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Before",
          "retrieved_context": [
            "User thinks it will be a billing nightmare.",
            "Emma is worried about cloud spend, especially on Azure components.",
            "User wants reminder to ping cofounder about quarterly review later."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 600.6531715393066,
          "generation_latency_ms": 3538.0706787109375,
          "total_latency_ms": 4138.723850250244
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-1",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific infrastructure issue caused the user to request a flag be sent to the Backend Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Beta version traffic in production",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is dealing with infrastructure stuff.",
            "James thinks the backend integration might be flaky.",
            "User plans to ping Backend Lead about testing in prod."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 670.2744960784912,
          "generation_latency_ms": 3702.0719051361084,
          "total_latency_ms": 4372.3464012146
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What physical activity does the user imply helps them prepare mentally for the work day?",
          "answer_type": "short_answer",
          "gold_answer": "Running",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "User thinks the design team is having a smoother day than they are.",
            "User needs to grab lunch first.",
            "User needs coffee before tackling a pile of alerts."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 671.9412803649902,
          "generation_latency_ms": 4062.4563694000244,
          "total_latency_ms": 4734.397649765015
        },
        {
          "probe_id": "preference_learning-preference_scope-1",
          "pillar": "preference_learning",
          "subpillar": "preference_scope",
          "question": "Does the user express a preference for managing financial details like Azure bills personally?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Emma is worried about cloud spend, especially on Azure components.",
            "User thinks it will be a billing nightmare.",
            "User is looking at Azure infrastructure."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 674.8461723327637,
          "generation_latency_ms": 3756.3862800598145,
          "total_latency_ms": 4431.232452392578
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the pet belonging to the Product Designer named Will?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Designers are Will and Sophia",
            "User confirms pet is Luna",
            "User is asking how Sophia and Will are doing."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 626.4054775238037,
          "generation_latency_ms": 3562.861442565918,
          "total_latency_ms": 4189.266920089722
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the currently running version of AuthService3?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks how AuthService3 is doing.",
            "User wants to know if AuthService3 is on AWS.",
            "Alex wants to check AuthService3."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 632.6110363006592,
          "generation_latency_ms": 2859.790325164795,
          "total_latency_ms": 3492.401361465454
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-0",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "According to the user's instructions during the beta leak incident, who is the point of contact for resolving backend configuration errors?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "User believes the beta leaked.",
            "User forgot about the beta rollout.",
            "User will bug James about the load balancer issue"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 381.8979263305664,
          "generation_latency_ms": 3074.8350620269775,
          "total_latency_ms": 3456.732988357544
        },
        {
          "probe_id": "procedural_knowledge-task_state_tracking-1",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "What is the current deadline status for the visual language drafts assigned to Sophia and Will?",
          "answer_type": "short_answer",
          "gold_answer": "Due Friday",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Sophia and Will will handle the new visual language.",
            "User is asking how Sophia and Will are doing.",
            "User asks whether Sophia and Will sent new assets."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 829.5996189117432,
          "generation_latency_ms": 3014.7485733032227,
          "total_latency_ms": 3844.348192214966
        }
      ],
      "summary": {
        "overall_accuracy": 0.4166666666666667,
        "total_score": 5,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 3,
            "count": 9,
            "accuracy": 0.3333333333333333
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_041.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 32,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 69.14024019241333,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "What is the job title of the individual the user refers to as 'my cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "CEO",
          "predicted_answer": "Cofounder",
          "retrieved_context": [
            "User is about to jump into a meeting with cofounder.",
            "User's cofounder is stressing about the investor demo.",
            "User wants to know who the frontend lead is."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 553.2543659210205,
          "generation_latency_ms": 2550.053834915161,
          "total_latency_ms": 3103.3082008361816
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What professional role does the owner of the cat named 'Luna' hold?",
          "answer_type": "short_answer",
          "gold_answer": "Frontend Lead",
          "predicted_answer": "Frontend lead",
          "retrieved_context": [
            "User says the cat is basically the mascot.",
            "Luna is demanding.",
            "Frontend lead mentioned her cat distracting her this morning"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 276.3257026672363,
          "generation_latency_ms": 2517.0300006866455,
          "total_latency_ms": 2793.355703353882
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which cloud provider hosts the service currently running the v2.0.0-beta version?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is looking at AWS infrastructure now",
            "User wants to know where the second analytics engine is hosted.",
            "User wants to know if there is an auth service running on Amazon."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 313.48323822021484,
          "generation_latency_ms": 3311.732769012451,
          "total_latency_ms": 3625.216007232666
        },
        {
          "probe_id": "declarative_reasoning-baseline_factual_recall-4",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What type of service is hosted on the Azure platform?",
          "answer_type": "short_answer",
          "gold_answer": "Auth service",
          "predicted_answer": "Auth service",
          "retrieved_context": [
            "There is a straggler auth service on Azure.",
            "User wants to check health of authentication service on Azure and wants to know about the auth instance on Azure.",
            "User will have backend team look into Azure latency."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 600.0916957855225,
          "generation_latency_ms": 2684.523582458496,
          "total_latency_ms": 3284.6152782440186
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What specific event was the CEO anxious about regarding platform stability?",
          "answer_type": "short_answer",
          "gold_answer": "Investor demo",
          "predicted_answer": "Investor demo",
          "retrieved_context": [
            "User's cofounder was stressing about uptime.",
            "User's cofounder is asking for a stability report later today",
            "User doesn't want downtime while cofounder pitches to board."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 367.0494556427002,
          "generation_latency_ms": 4338.579177856445,
          "total_latency_ms": 4705.6286334991455
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-6",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user ask about the location of LoadBalancer9 before or after the discussion about the 'happy Tuesday' log discrepancies?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks where LoadBalancer9 is located",
            "LoadBalancer9 is stable.",
            "User wants to confirm hosting locations of LoadBalancer9 and LoadBalancer5."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 636.0032558441162,
          "generation_latency_ms": 3024.1270065307617,
          "total_latency_ms": 3660.130262374878
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "How does the user characterize their stance on running the split version setup on the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "Risky but necessary",
          "predicted_answer": "Concerned",
          "retrieved_context": [
            "User is concerned about the analytics setup",
            "User has a split version situation running right now.",
            "User is asking if the single stable version is running on the analytics engine"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 290.25745391845703,
          "generation_latency_ms": 2606.229782104492,
          "total_latency_ms": 2896.487236022949
        },
        {
          "probe_id": "preference_learning-explicit_preferences-8",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "Which cloud provider has the user explicitly designated as their preferred choice for all future services?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User thinks there is one auth service on Microsoft's cloud.",
            "User is concerned about cross-cloud traffic.",
            "User is looking at AWS infrastructure now"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 346.62914276123047,
          "generation_latency_ms": 3941.269636154175,
          "total_latency_ms": 4287.898778915405
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What software version is the system 'LoadBalancer9' currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks where LoadBalancer9 is located",
            "LoadBalancer9 is stable.",
            "User wants to confirm hosting locations of LoadBalancer9 and LoadBalancer5."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 695.2557563781738,
          "generation_latency_ms": 3180.7055473327637,
          "total_latency_ms": 3875.9613037109375
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the pet owned by the DevOps Lead?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Charlotte is the DevOps lead",
            "User says the DevOps lead needs to check the latency.",
            "User was unaware that DevOps lead finalized migration to Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 587.2049331665039,
          "generation_latency_ms": 3239.178419113159,
          "total_latency_ms": 3826.383352279663
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-11",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "Who does the user intend to contact to resolve the race condition on the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Charlotte",
          "retrieved_context": [
            "User wants to know where the second analytics engine is hosted.",
            "User is concerned about the analytics setup",
            "Elijah is asking about the Analytics Engine."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 705.9106826782227,
          "generation_latency_ms": 4300.72808265686,
          "total_latency_ms": 5006.638765335083
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-12",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What method does the assistant use to verify the current status and version of the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "Checking telemetry",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to pull up current state of analytics engine",
            "User is asking if the single stable version is running on the analytics engine",
            "User wants to check the versioning on the second analytics engine in the Google environment."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 534.8906517028809,
          "generation_latency_ms": 3578.873634338379,
          "total_latency_ms": 4113.76428604126
        }
      ],
      "summary": {
        "overall_accuracy": 0.5,
        "total_score": 6,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 3,
            "count": 9,
            "accuracy": 0.3333333333333333
          },
          "abstain": {
            "total": 3,
            "count": 3,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_042.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 27,
      "num_probes": 9,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 54.087132930755615,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the individual referred to as the 'cofounder' that was reviewing the billing dashboard?",
          "answer_type": "short_answer",
          "gold_answer": "Will",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder was confused about invoices from three different cloud providers.",
            "User needs to ask Lucas about the new dashboard mockups later.",
            "User has a cofounder"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 811.9678497314453,
          "generation_latency_ms": 3086.5957736968994,
          "total_latency_ms": 3898.5636234283447
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the name of the pet belonging to the person who leads the sales department?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "User's pet is Luna",
            "User got distracted because Sales Lead brought her pet to video call.",
            "User wants to know if Emma sent sales projections."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 640.1181221008301,
          "generation_latency_ms": 2433.3770275115967,
          "total_latency_ms": 3073.4951496124268
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the core data storage system managed by the Backend Lead hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "User told cofounder that core data storage and traffic distribution are on Microsoft stack.",
            "User wants to check where the main database is currently hosted.",
            "User wants status of PrimaryDB2, which is hosted on Azure"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 391.1464214324951,
          "generation_latency_ms": 2997.516632080078,
          "total_latency_ms": 3388.6630535125732
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Despite the logs suggesting a beta version, what version number does the user assert is the stable release for the primary database?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Oliver insists the main database instance is on v1.2.0, but logs suggest v2.0.0-beta.",
            "User is asking about the primary DB version; Will thinks it has been upgraded.",
            "User believes the beta version of PrimaryDB2 was intended for sandbox, not production"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 677.1013736724854,
          "generation_latency_ms": 4822.53623008728,
          "total_latency_ms": 5499.637603759766
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-4",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "What personal task did the user request a reminder for immediately before asking about the Sales Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Call mom",
          "predicted_answer": "pick up dry cleaning at 5 PM",
          "retrieved_context": [
            "User wants a reminder to grab a double espresso before sync with cofounder later.",
            "User wants a reminder to pick up coffee before sync with Will.",
            "User wants reminder to bring up lag at standup."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 630.6211948394775,
          "generation_latency_ms": 3702.0511627197266,
          "total_latency_ms": 4332.672357559204
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-5",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why did the user suggest the Azure portal might be lagging during the conversation about infrastructure confusion?",
          "answer_type": "short_answer",
          "gold_answer": "Conflicting version info",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Alex wants a quick status check on Azure infrastructure",
            "User wants confirmation that the load balancer is not jumping around and is routing traffic correctly to the Azure instance",
            "User is trying to figure out why the Azure bill is high this month for the main database instance."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 556.2868118286133,
          "generation_latency_ms": 3686.3582134246826,
          "total_latency_ms": 4242.645025253296
        },
        {
          "probe_id": "preference_learning-preference_induction-6",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on previous interactions, how does the user view the presence of Emma's pet during video calls?",
          "answer_type": "short_answer",
          "gold_answer": "Hilarious",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User hopes Emma's cat is okay.",
            "User wants to make sure Emma is doing alright personally.",
            "User asks if Emma is bringing her cat to the office."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 604.6481132507324,
          "generation_latency_ms": 2786.4561080932617,
          "total_latency_ms": 3391.104221343994
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-7",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific software version is the LoadBalancer8 currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks to verify if LoadBalancer8 is handling current traffic load.",
            "User wants confirmation that the load balancer is not jumping around and is routing traffic correctly to the Azure instance",
            "Load balancer is fine."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 380.0199031829834,
          "generation_latency_ms": 2896.5842723846436,
          "total_latency_ms": 3276.604175567627
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-8",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "What protocol did the assistant agree to follow regarding the conflicting database versions in the production environment?",
          "answer_type": "generation",
          "gold_answer": "Treat v1.2.0 as active",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Oliver insists the main database instance is on v1.2.0, but logs suggest v2.0.0-beta.",
            "Lucas is asking about the database version for the new prototype.",
            "User plans to ping Oliver about database version because Backend Lead may not know."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 347.01085090637207,
          "generation_latency_ms": 3819.082498550415,
          "total_latency_ms": 4166.093349456787
        }
      ],
      "summary": {
        "overall_accuracy": 0.3333333333333333,
        "total_score": 3,
        "count": 9,
        "by_answer_type": {
          "short_answer": {
            "total": 2,
            "count": 7,
            "accuracy": 0.2857142857142857
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "generation": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_043.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 26,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 68.51058387756348,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "What is the organizational role of the person who owns a cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User refers to cat Luna.",
            "User hopes cat Luna is okay.",
            "User intends to ask Liam about his cat Luna."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 714.5485877990723,
          "generation_latency_ms": 3257.4782371520996,
          "total_latency_ms": 3972.026824951172
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which other service is hosted on the same cloud provider as AuthService6?",
          "answer_type": "short_answer",
          "gold_answer": "CacheLayer4",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is unsure whether CacheLayer4 and AuthService6 are hosted on Amazon.",
            "User wants to check if AuthService6 is handling load okay.",
            "Sophia was asking if the auth service is on the same cluster as the analytics engine."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 701.9944190979004,
          "generation_latency_ms": 3148.0963230133057,
          "total_latency_ms": 3850.090742111206
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service that is currently exhibiting version mismatches hosted?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google",
          "retrieved_context": [
            "User is asking whether the service is running on Amazon infrastructure.",
            "User is unsure whether CacheLayer4 and AuthService6 are hosted on Amazon.",
            "User acknowledges the multi-cloud setup."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 598.36745262146,
          "generation_latency_ms": 2357.8524589538574,
          "total_latency_ms": 2956.2199115753174
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "According to the logs, which two versions are simultaneously reported for the fourth cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User notes logs for CacheLayer4 look erratic and wonders if a beta is running.",
            "Will mentioned a version mismatch on CacheLayer4.",
            "User wants to know where the fourth cache layer is running."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 359.4651222229004,
          "generation_latency_ms": 3091.932535171509,
          "total_latency_ms": 3451.397657394409
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-4",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What weather condition did the user mention while discussing the ambiguous metrics of the fourth cache layer?",
          "answer_type": "short_answer",
          "gold_answer": "Rain",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is referring to CacheLayer4.",
            "User wants to know where the fourth cache layer is running.",
            "User notes logs for CacheLayer4 look erratic and wonders if a beta is running."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 592.1463966369629,
          "generation_latency_ms": 2795.095205307007,
          "total_latency_ms": 3387.2416019439697
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-5",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why did the user specifically request a breakdown of infrastructure by provider before 10 AM?",
          "answer_type": "short_answer",
          "gold_answer": "Meeting with Lucas",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to double-check the infrastructure map for cache services hosting providers.",
            "User has infrastructure headaches.",
            "User needs another coffee before infrastructure audit"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 302.232027053833,
          "generation_latency_ms": 4587.6123905181885,
          "total_latency_ms": 4889.8444175720215
        },
        {
          "probe_id": "preference_learning-explicit_preferences-6",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "When mapping out infrastructure for the cloud spend discussion, did the user prefer a breakdown by service usage or by provider?",
          "answer_type": "short_answer",
          "gold_answer": "By provider",
          "predicted_answer": "By provider",
          "retrieved_context": [
            "Lucas was asking about cloud spend distribution",
            "User is reviewing the cloud footprint.",
            "User is reviewing the cloud bill."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 507.8732967376709,
          "generation_latency_ms": 4255.74803352356,
          "total_latency_ms": 4763.6213302612305
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's morning routine, what specific type of coffee do they appear to favor?",
          "answer_type": "short_answer",
          "gold_answer": "Double espresso",
          "predicted_answer": "Double espresso",
          "retrieved_context": [
            "User is going to grab coffee",
            "User and cofounder are debating which coffee machine to buy for the break room.",
            "User will grab another coffee before diving in."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 679.3911457061768,
          "generation_latency_ms": 2642.2219276428223,
          "total_latency_ms": 3321.613073348999
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-8",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What version of software is currently running on AnalyticsEngine5?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "AnalyticsEngine5 has not been migrated yet.",
            "User wants to know how analytics engine is performing.",
            "User is asking where analytics engine lives."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 552.3817539215088,
          "generation_latency_ms": 2701.1513710021973,
          "total_latency_ms": 3253.533124923706
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who holds the role of Frontend Lead in the organization?",
          "answer_type": "short_answer",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks who is assigned to lead backend team",
            "Will manages the backend team.",
            "Will shares backend lead role with Sophia, and Sophia manages the backend team with Will."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 304.32915687561035,
          "generation_latency_ms": 2828.6654949188232,
          "total_latency_ms": 3132.9946517944336
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-10",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What technical metric was the team testing by splitting the cache layers across different providers?",
          "answer_type": "short_answer",
          "gold_answer": "Latency",
          "predicted_answer": "latency",
          "retrieved_context": [
            "Alex knows the cache layers are split to test latency",
            "User is checking whether the analytics engine is running on the same cluster as CacheLayer4 and is on the same cloud as cache layer.",
            "User feels caching services are split across providers"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 357.7685356140137,
          "generation_latency_ms": 2295.302629470825,
          "total_latency_ms": 2653.071165084839
        },
        {
          "probe_id": "procedural_knowledge-procedure_storage-11",
          "pillar": "procedural_knowledge",
          "subpillar": "procedure_storage",
          "question": "What future task did the assistant schedule regarding the user's mother?",
          "answer_type": "short_answer",
          "gold_answer": "Call in one hour",
          "predicted_answer": "Call mom",
          "retrieved_context": [
            "User thinks Will might be handling deployment today.",
            "User wants a reminder to call mom in one hour.",
            "Alex wants a reminder to pick up dry cleaning later"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 353.1079292297363,
          "generation_latency_ms": 3903.597354888916,
          "total_latency_ms": 4256.705284118652
        }
      ],
      "summary": {
        "overall_accuracy": 0.4166666666666667,
        "total_score": 5,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 12,
            "accuracy": 0.4166666666666667
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_044.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 31,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 68.10545253753662,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which individual is the user referring to when mentioning their 'cofounder' who is worried about login stability?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "User's cofounder is panicking about login stability for the board meeting.",
            "User's cofounder reported latency issues that users are experiencing.",
            "User's cofounder was up late"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 548.9168167114258,
          "generation_latency_ms": 3026.2207984924316,
          "total_latency_ms": 3575.1376152038574
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "What is the name of the pet belonging to the person who holds the Frontend Lead role?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User says Emma can't do frontend work",
            "User's gift card is for Emma, who has been pulling all-nighters with the UI crew to get the dashboard ready and has adopted a cat named Luna.",
            "Emma might be testing the beta against the frontend and mentioned needing to get home to feed Luna."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 762.690544128418,
          "generation_latency_ms": 2906.921863555908,
          "total_latency_ms": 3669.612407684326
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service that is currently running a beta version hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Azure",
          "retrieved_context": [
            "User wants to know if service still in same region on Azure.",
            "The service is hosted on Microsoft's cloud and User is asking if the instance is fully upgraded.",
            "User needs to verify what is running on Azure before talking to cofounder."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 355.0264835357666,
          "generation_latency_ms": 3521.1899280548096,
          "total_latency_ms": 3876.216411590576
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-1",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "Which specific service did the user identify as causing infrastructure fragmentation due to its hosting location on Google Cloud?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer2",
          "predicted_answer": "LoadBalancer2",
          "retrieved_context": [
            "User forgot about the Google instance and says cofounder loves complicating architecture with multi-cloud",
            "User asks if second load balancer is on Google's infrastructure",
            "User doesn't know why LoadBalancer2 is on Google's cloud while other services are scattered."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 538.8498306274414,
          "generation_latency_ms": 2624.859094619751,
          "total_latency_ms": 3163.7089252471924
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-0",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "What specific event caused the Frontend Lead to get distracted while debugging the login UI?",
          "answer_type": "short_answer",
          "gold_answer": "Luna jumped on keyboard",
          "predicted_answer": "Luna jumping on her keyboard",
          "retrieved_context": [
            "Emma was trying to debug the login UI earlier but was distracted by Luna jumping on her keyboard.",
            "User's cofounder is panicking about login stability for the board meeting.",
            "User was too busy debugging."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 441.85376167297363,
          "generation_latency_ms": 2405.203342437744,
          "total_latency_ms": 2847.057104110718
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-1",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user ask to check the Azure deployment slots before or after inquiring about the status of the analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to check the analytics engine status.",
            "User needs to verify what is running on Azure before talking to cofounder.",
            "User wants to know if service still in same region on Azure."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 352.2953987121582,
          "generation_latency_ms": 3679.262638092041,
          "total_latency_ms": 4031.558036804199
        },
        {
          "probe_id": "preference_learning-explicit_preferences-0",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What specific beverage did the user state they required before the standup meeting?",
          "answer_type": "short_answer",
          "gold_answer": "Double espresso",
          "predicted_answer": "double espresso",
          "retrieved_context": [
            "User needs a double espresso before the standup.",
            "User will grab coffee before next meeting",
            "User needs to grab a coffee before the next call."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 555.6983947753906,
          "generation_latency_ms": 2207.7527046203613,
          "total_latency_ms": 2763.451099395752
        },
        {
          "probe_id": "preference_learning-preference_induction-1",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's complaints about fragmentation, which cloud provider is implied to be the non-preferred or 'odd' location for the load balancer?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google Cloud",
          "retrieved_context": [
            "User thinks LoadBalancer2 is odd one out on Google's cloud.",
            "User asks about load balancing situation across different providers",
            "User doesn't know why LoadBalancer2 is on Google's cloud while other services are scattered."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 396.2891101837158,
          "generation_latency_ms": 3493.6041831970215,
          "total_latency_ms": 3889.8932933807373
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What software version is the Analytics Engine currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to check the analytics engine status.",
            "User wants to confirm that AnalyticsEngine6 is still isolated for audit.",
            "User says maintenance is a nightmare and asks if Sophia looked at backend logs for AnalyticsEngine6"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 548.2094287872314,
          "generation_latency_ms": 3430.8340549468994,
          "total_latency_ms": 3979.043483734131
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-1",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the tools used by the Sales Lead?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Analytics Engine is hosted on AWS.",
            "Analytics engine is hosted on Amazon and LoadBalancer2 is hosted on Google Cloud.",
            "User needs to verify what is running on Azure before talking to cofounder."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 591.033935546875,
          "generation_latency_ms": 3645.3354358673096,
          "total_latency_ms": 4236.369371414185
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "Which monitoring service does the assistant use to check the status of the AWS-hosted analytics engine?",
          "answer_type": "short_answer",
          "gold_answer": "CloudWatch",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to check the analytics engine status.",
            "Analytics Engine is hosted on AWS.",
            "Analytics engine on AWS is fine."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 765.5642032623291,
          "generation_latency_ms": 3219.4042205810547,
          "total_latency_ms": 3984.968423843384
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-1",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What does the assistant identify as a 'classic hazard' for the Frontend Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Her cat",
          "predicted_answer": "API contract changes",
          "retrieved_context": [
            "Frontend lead needs to know if API contract changed",
            "User needs to check in with the frontend team.",
            "User says Emma can't do frontend work"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 533.2903861999512,
          "generation_latency_ms": 2751.288890838623,
          "total_latency_ms": 3284.579277038574
        }
      ],
      "summary": {
        "overall_accuracy": 0.6666666666666666,
        "total_score": 8,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 10,
            "accuracy": 0.6
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_045.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 31,
      "num_probes": 10,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 58.58711004257202,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which team member is referred to as the 'DevOps specialist' responsible for patching the database?",
          "answer_type": "short_answer",
          "gold_answer": "Will",
          "predicted_answer": "Will",
          "retrieved_context": [
            "Will is the DevOps guy.",
            "User wants DevOps guy to investigate issue immediately.",
            "Will mentioned he was doing some maintenance on the main database this morning."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 435.31322479248047,
          "generation_latency_ms": 2631.5667629241943,
          "total_latency_ms": 3066.879987716675
        },
        {
          "probe_id": "world_modeling-relationship_mapping-0",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "On which cloud provider is the service hosted that the CEO is specifically concerned about regarding budget fragmentation?",
          "answer_type": "short_answer",
          "gold_answer": "AWS",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "James is stressing about the cloud budget",
            "User feels splitting cache layer across clouds was a bold move.",
            "User is worried about the infrastructure, especially the main database on Azure."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 395.47252655029297,
          "generation_latency_ms": 5047.6696491241455,
          "total_latency_ms": 5443.1421756744385
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-0",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person who owns a cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Sales Lead",
          "predicted_answer": "Sales",
          "retrieved_context": [
            "Ava will probably bring her cat Luna to the video call.",
            "Ava sent a Slack message with a photo of her cat Luna walking across her keyboard, followed by \"Pls fix so I can sell.\"",
            "Ava sent a picture of her cat Luna destroying a couch"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 667.919397354126,
          "generation_latency_ms": 2511.115312576294,
          "total_latency_ms": 3179.03470993042
        },
        {
          "probe_id": "declarative_reasoning-constraint_propagation-0",
          "pillar": "declarative_reasoning",
          "subpillar": "constraint_propagation",
          "question": "The analytics engine is causing latency because it is hosted on a different provider than the primary database. Where is the primary database hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is asking whether analytics engine is on the same stack.",
            "User knows the connection to AnalyticsEngine1 is solid.",
            "Analytics engine is isolated on Amazon."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 359.4622611999512,
          "generation_latency_ms": 3770.6384658813477,
          "total_latency_ms": 4130.100727081299
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-0",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "During the conversation where the user decided to hold off on emailing James, what personal reminder was set?",
          "answer_type": "short_answer",
          "gold_answer": "Dentist appointment",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants reminder to slack Emma later.",
            "User wants reminder to get a gift for Ava",
            "User wants reminders to yell at Will later and pick up dry cleaning at 5."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 661.7844104766846,
          "generation_latency_ms": 4514.145374298096,
          "total_latency_ms": 5175.92978477478
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-0",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why did the DevOps specialist describe his work as a 'nightmare' in recent discussions?",
          "answer_type": "short_answer",
          "gold_answer": "Latency",
          "predicted_answer": "Latency",
          "retrieved_context": [
            "Will complains about latency that makes his DevOps work a nightmare.",
            "User's cofounder is panicked about the quarterly review.",
            "Will is the DevOps guy."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 688.0378723144531,
          "generation_latency_ms": 2057.9886436462402,
          "total_latency_ms": 2746.0265159606934
        },
        {
          "probe_id": "preference_learning-preference_induction-0",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's morning routine comments, what specific beverage do they require to function?",
          "answer_type": "short_answer",
          "gold_answer": "Espresso",
          "predicted_answer": "Double shot of espresso",
          "retrieved_context": [
            "User's coffee hasn't kicked in yet.",
            "User needs a double shot of espresso before looking at logs.",
            "User needs to take a break"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 299.2830276489258,
          "generation_latency_ms": 2689.075231552124,
          "total_latency_ms": 2988.35825920105
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Which cloud provider hosts the service managed by the Frontend Lead?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is asking if Will is still managing the production instance on Microsoft's cloud.",
            "Caching service is split across clouds",
            "User wants to know if main database is still on Microsoft infrastructure."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 582.8485488891602,
          "generation_latency_ms": 3469.0093994140625,
          "total_latency_ms": 4051.8579483032227
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-0",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "Is the PrimaryDB9 system currently running exclusively on version v2.0.0-beta?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Emma thinks PrimaryDB9 was upgraded without telling her; uncertainty about version v1.2.0 or v2.0.0-beta",
            "User is concerned about system stability and was looking at PrimaryDB9, which Will was supposed to patch.",
            "User wants to start with main database PrimaryDB9."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 747.0064163208008,
          "generation_latency_ms": 2469.9950218200684,
          "total_latency_ms": 3217.001438140869
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-0",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "How does the assistant determine the version status of the PrimaryDB9 when asked?",
          "answer_type": "short_answer",
          "gold_answer": "Checks headers",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Emma thinks PrimaryDB9 was upgraded without telling her; uncertainty about version v1.2.0 or v2.0.0-beta",
            "User wants to check current status of main database.",
            "User wants to start with main database PrimaryDB9."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 373.110294342041,
          "generation_latency_ms": 3281.7277908325195,
          "total_latency_ms": 3654.8380851745605
        }
      ],
      "summary": {
        "overall_accuracy": 0.4,
        "total_score": 4,
        "count": 10,
        "by_answer_type": {
          "short_answer": {
            "total": 3,
            "count": 8,
            "accuracy": 0.375
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "preference_learning": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_046.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 65.16195273399353,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the cofounder the user plans to have lunch with?",
          "answer_type": "short_answer",
          "gold_answer": "Oliver",
          "predicted_answer": "Oliver",
          "retrieved_context": [
            "User's lunch with cofounder is a casual catch-up.",
            "User had coffee with cofounder",
            "User plans to talk after lunch."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 610.5034351348877,
          "generation_latency_ms": 3903.993844985962,
          "total_latency_ms": 4514.49728012085
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which infrastructure provider hosts the database that Sophia is concerned about regarding latency?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Google",
          "retrieved_context": [
            "Sophia is worried about latency to main database on Google's infrastructure.",
            "User will have Olivia and Sophia look into latency between clouds.",
            "User is experiencing high latency between the primary database and Amazon authentication service, and sees latency on the main database."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 506.439208984375,
          "generation_latency_ms": 2581.979751586914,
          "total_latency_ms": 3088.418960571289
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which two specific version numbers are simultaneously active on the authentication service hosted on AWS?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "User refers to AuthService7 hosted on AWS and sees weird logs regarding its version number.",
            "User identifies authentication service as instance number 7 on Amazon's cloud",
            "User wants to check status of auth service on AWS."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 311.15007400512695,
          "generation_latency_ms": 2672.14298248291,
          "total_latency_ms": 2983.293056488037
        },
        {
          "probe_id": "declarative_reasoning-baseline_factual_recall-4",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "What is the name of the pet belonging to the Backend Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Luna",
          "predicted_answer": "Luna",
          "retrieved_context": [
            "User wants to know who is covering backend lead role.",
            "Sophia leads backend team",
            "Olivia leads the backend crew."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 343.17731857299805,
          "generation_latency_ms": 2781.9693088531494,
          "total_latency_ms": 3125.1466274261475
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user ask to set a reminder for their mom's birthday before or after the reminder for dry cleaning?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "After",
          "retrieved_context": [
            "User wants reminder to pick up dry cleaning later",
            "User wants a reminder about dry cleaning again in an hour.",
            "User wants a reminder to pick up dry cleaning at 6."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 301.70249938964844,
          "generation_latency_ms": 3055.6507110595703,
          "total_latency_ms": 3357.3532104492188
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-6",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What specific complaint did the user make about the coffee in session 23?",
          "answer_type": "short_answer",
          "gold_answer": "Tastes like battery acid",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's coffee is terrible and getting cold",
            "User says coffee tastes like battery acid.",
            "User had coffee with cofounder"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 669.4462299346924,
          "generation_latency_ms": 2899.0819454193115,
          "total_latency_ms": 3568.528175354004
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the morning sessions, what beverage does the user consistently require before working?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee",
          "predicted_answer": "Coffee",
          "retrieved_context": [
            "User needs to grab a coffee before next meeting.",
            "User is feeling dragging today and needs more coffee.",
            "User wants a quick sanity check on infrastructure before caffeine kicks in"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 306.1509132385254,
          "generation_latency_ms": 3015.395164489746,
          "total_latency_ms": 3321.5460777282715
        },
        {
          "probe_id": "preference_learning-explicit_preferences-8",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "At what time did the user specifically request to be reminded to call their mom?",
          "answer_type": "short_answer",
          "gold_answer": "6 PM",
          "predicted_answer": "6 PM",
          "retrieved_context": [
            "User wants a reminder to call mom for her birthday at 6 PM.",
            "User wants reminder to ping cofounder later.",
            "User wants a reminder to grab lunch with cofounder later."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 367.39039421081543,
          "generation_latency_ms": 2287.5282764434814,
          "total_latency_ms": 2654.918670654297
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific version number is running on the LoadBalancer4 service?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User identifies load balancer number 4 and wants to check its status on Azure stack.",
            "User wants to check status of load balancer in Microsoft cloud.",
            "User wants to include LoadBalancer4."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 315.4163360595703,
          "generation_latency_ms": 2677.239418029785,
          "total_latency_ms": 2992.6557540893555
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who is the specific team lead for the DevOps engineers Emma and Mia?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Emma and Mia handle the pipes.",
            "Sophia leads backend team",
            "Olivia leads the backend crew."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 314.2862319946289,
          "generation_latency_ms": 3821.1331367492676,
          "total_latency_ms": 4135.4193687438965
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-11",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "When the user references the 'Microsoft cloud', which specific load balancer identifier is relevant?",
          "answer_type": "short_answer",
          "gold_answer": "LoadBalancer4",
          "predicted_answer": "LoadBalancer4",
          "retrieved_context": [
            "User knows there is a load balancer on Microsoft's cloud.",
            "User wants to check status of load balancer in Microsoft cloud.",
            "User identifies load balancer number 4 and wants to check its status on Azure stack."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 598.3731746673584,
          "generation_latency_ms": 3041.4679050445557,
          "total_latency_ms": 3639.841079711914
        },
        {
          "probe_id": "procedural_knowledge-task_state_tracking-12",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "How did the user categorize the state of the deployment on the AWS auth service in the final session?",
          "answer_type": "short_answer",
          "gold_answer": "Stuck deployment",
          "predicted_answer": "Weird logs regarding its version number",
          "retrieved_context": [
            "User wants to check status of auth service on AWS.",
            "User wants to shift focus to AWS deployment and check other auth node",
            "User suspects authentication layer and wants to inspect the instance running on AWS."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 571.0153579711914,
          "generation_latency_ms": 3245.0613975524902,
          "total_latency_ms": 3816.0767555236816
        }
      ],
      "summary": {
        "overall_accuracy": 0.6666666666666666,
        "total_score": 8,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 6,
            "count": 10,
            "accuracy": 0.6
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_047.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 30,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 67.22401666641235,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which individual is the user referring to when mentioning the 'cofounder' who texted late at night about bills?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Elijah",
          "retrieved_context": [
            "User's cofounder texted them late last night about infrastructure bills",
            "User thinks the cofounder is a handful.",
            "User wants to know if cofounder is coming in late."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 747.802734375,
          "generation_latency_ms": 2601.942300796509,
          "total_latency_ms": 3349.745035171509
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which specific infrastructure services are currently hosted on the Amazon platform?",
          "answer_type": "short_answer",
          "gold_answer": "PrimaryDB4 and CacheLayer7",
          "predicted_answer": "Main database, PrimaryDB4, CacheLayer7, beta version of PrimaryDB instance",
          "retrieved_context": [
            "User wants to know if main database is on Amazon's infrastructure.",
            "Main database is hosted on AWS",
            "User wants to know if auth service is on AWS."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 290.96126556396484,
          "generation_latency_ms": 2571.507215499878,
          "total_latency_ms": 2862.468481063843
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "What is the job title of the person who owns the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Product Designer",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User has a pet named Luna.",
            "Luna is practically an employee.",
            "Noah has a cat named Luna who was tearing up furniture during standup."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 355.1304340362549,
          "generation_latency_ms": 3314.211845397949,
          "total_latency_ms": 3669.342279434204
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-4",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "Despite the dashboard displaying v1.2.0, what version do the logs suggest PrimaryDB4 is actually running?",
          "answer_type": "short_answer",
          "gold_answer": "v2.0.0-beta",
          "predicted_answer": "v1.2.0 traces",
          "retrieved_context": [
            "User is concerned about versioning issue on PrimaryDB4",
            "User wants version check on primary database.",
            "PrimaryDB4 config version is v1.2.0."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 584.5956802368164,
          "generation_latency_ms": 2971.031665802002,
          "total_latency_ms": 3555.6273460388184
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the user complain about the two-hour 'quick sync' before or after asking to clear their schedule to review hosting costs?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to review hosting costs.",
            "User's cofounder pulled them into a quick sync that lasted two hours",
            "User feels behind schedule today."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 443.310022354126,
          "generation_latency_ms": 4248.962879180908,
          "total_latency_ms": 4692.272901535034
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-6",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why is the CEO specifically concerned about the cost of the authentication service compared to the rest of the stack?",
          "answer_type": "short_answer",
          "gold_answer": "It is isolated on Azure",
          "predicted_answer": "Overpaying for authentication system",
          "retrieved_context": [
            "User's cofounder thinks overpaying for authentication system",
            "User's cofounder wants to know why authentication system not on same provider as rest of stack",
            "User suspects Auth service hosted on Azure might be causing latency spiking."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 656.5806865692139,
          "generation_latency_ms": 3684.7076416015625,
          "total_latency_ms": 4341.288328170776
        },
        {
          "probe_id": "preference_learning-explicit_preferences-7",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "How does the user's cofounder feel about ambiguity in status reports?",
          "answer_type": "short_answer",
          "gold_answer": "He hates it",
          "predicted_answer": "Hates ambiguity",
          "retrieved_context": [
            "User does not want to stress cofounder unless necessary",
            "User wants to know if cofounder is coming in late.",
            "User's cofounder hates ambiguity."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 806.3132762908936,
          "generation_latency_ms": 2207.285165786743,
          "total_latency_ms": 3013.5984420776367
        },
        {
          "probe_id": "preference_learning-preference_scope-8",
          "pillar": "preference_learning",
          "subpillar": "preference_scope",
          "question": "Does the CEO's concern about overpaying apply to the AWS services or the Azure service?",
          "answer_type": "short_answer",
          "gold_answer": "Azure service",
          "predicted_answer": "Azure service",
          "retrieved_context": [
            "Elijah was asking about the AWS bill earlier and is worried about extra overhead.",
            "User's cofounder thinks overpaying for authentication system",
            "User wants to review hosting costs."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 291.581392288208,
          "generation_latency_ms": 2916.445255279541,
          "total_latency_ms": 3208.026647567749
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of Oliver's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Only Noah has a cat; Oliver does not",
            "User will walk over to Oliver's desk",
            "User will ping Oliver instead of Noah"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 566.124439239502,
          "generation_latency_ms": 2974.5893478393555,
          "total_latency_ms": 3540.7137870788574
        },
        {
          "probe_id": "knowledge_boundaries-confidence_calibration-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "confidence_calibration",
          "question": "Does the assistant have visual confirmation of how big Noah's cat has grown?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks if Noah is bringing his pet today",
            "User wants to add buy cat food to shopping list for Noah's pet.",
            "User wants to know if Oliver or Noah uploaded new SVGs."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 287.49680519104004,
          "generation_latency_ms": 3230.7660579681396,
          "total_latency_ms": 3518.2628631591797
        },
        {
          "probe_id": "procedural_knowledge-task_state_tracking-11",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "Who is currently responsible for handling the backend logic of the infrastructure migration?",
          "answer_type": "short_answer",
          "gold_answer": "Sophia",
          "predicted_answer": "Sophia",
          "retrieved_context": [
            "The backend lead is the only one who really gets the migration path.",
            "User intends to involve Sophia, who leads backend efforts, to assess migration feasibility.",
            "Elijah wants the infrastructure migration done."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 626.2068748474121,
          "generation_latency_ms": 3325.8395195007324,
          "total_latency_ms": 3952.0463943481445
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-12",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "Based on the user's interactions, what specific database issue creates a risk of confusing the CEO?",
          "answer_type": "short_answer",
          "gold_answer": "Version ambiguity",
          "predicted_answer": "running unstable beta software in production",
          "retrieved_context": [
            "User suspects main database is issue",
            "User wants the CEO to be informed about running unstable beta software in production.",
            "User wants a note drafted to Backend Lead regarding database version discrepancy."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 588.5350704193115,
          "generation_latency_ms": 2725.083827972412,
          "total_latency_ms": 3313.6188983917236
        }
      ],
      "summary": {
        "overall_accuracy": 0.4166666666666667,
        "total_score": 5,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 4,
            "count": 10,
            "accuracy": 0.4
          },
          "abstain": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          },
          "boolean": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "declarative_reasoning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "knowledge_boundaries": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_048.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 28,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 69.64392685890198,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-1",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user referring to when they mention their 'cofounder' who is stressing about platform stability?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "Alex's cofounder",
          "retrieved_context": [
            "Cofounder is stressing about platform stability for upcoming launch",
            "User's cofounder was asking about beta rollout stability.",
            "User's cofounder is seeing variance."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 434.1006278991699,
          "generation_latency_ms": 2272.954225540161,
          "total_latency_ms": 2707.054853439331
        },
        {
          "probe_id": "world_modeling-relationship_mapping-2",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Which employee is the owner of the cat named Luna?",
          "answer_type": "short_answer",
          "gold_answer": "Emma",
          "predicted_answer": "Emma",
          "retrieved_context": [
            "Emma's cat Luna is adorable",
            "Luna is Emma's cat.",
            "Emma just adopted a cat named Luna"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 357.0866584777832,
          "generation_latency_ms": 2221.5964794158936,
          "total_latency_ms": 2578.6831378936768
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-3",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "On which cloud provider is the service running the 'v2.0.0-beta' hosted?",
          "answer_type": "short_answer",
          "gold_answer": "Azure",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User notes that services are spread across clouds.",
            "User heard there might be a version mismatch for the Azure service.",
            "The blue-green deployment for AuthService2 went sideways"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 417.7846908569336,
          "generation_latency_ms": 4042.6957607269287,
          "total_latency_ms": 4460.480451583862
        },
        {
          "probe_id": "declarative_reasoning-baseline_factual_recall-4",
          "pillar": "declarative_reasoning",
          "subpillar": "baseline_factual_recall",
          "question": "Which two individuals currently hold the role of Backend Lead?",
          "answer_type": "short_answer",
          "gold_answer": "Oliver and Charlotte",
          "predicted_answer": "Oliver and Charlotte",
          "retrieved_context": [
            "User knows Oliver and Charlotte are both backend leads, causing overlap, and they are splitting backend leadership duties and coordinating a plan together, and the role was split recently.",
            "User wants current leadership structure for the backend team.",
            "User needs to contact the backend lead"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 929.4610023498535,
          "generation_latency_ms": 2733.269453048706,
          "total_latency_ms": 3662.7304553985596
        },
        {
          "probe_id": "temporal_episodic-episode_reconstruction-5",
          "pillar": "temporal_episodic",
          "subpillar": "episode_reconstruction",
          "question": "What personal task did the user ask to be reminded of during the conversation about Oliver and Charlotte's argument?",
          "answer_type": "short_answer",
          "gold_answer": "Pick up dry cleaning",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Oliver and Charlotte mentioned some lag.",
            "Oliver and Charlotte are arguing about whether to kill the beta.",
            "Alex needs to ping Oliver and Charlotte"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 304.93831634521484,
          "generation_latency_ms": 3802.809000015259,
          "total_latency_ms": 4107.747316360474
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-6",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "According to the session history, why did the user describe the game match as 'intense'?",
          "answer_type": "short_answer",
          "gold_answer": "It went into overtime",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "The game was pretty intense",
            "The game went into overtime",
            "User reports seeing weird inconsistencies"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 622.8728294372559,
          "generation_latency_ms": 2833.354711532593,
          "total_latency_ms": 3456.2275409698486
        },
        {
          "probe_id": "preference_learning-preference_induction-7",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "What is the CEO's primary motivation for pushing infrastructure consolidation?",
          "answer_type": "short_answer",
          "gold_answer": "Bottom line",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to consolidate infrastructure someday and is concerned about the multi-cloud mess and Liam is pressuring them about consolidation.",
            "Alex's cofounder is asking for a status report on the infrastructure migration",
            "Alex wants to get a handle on the infrastructure map today"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 301.45955085754395,
          "generation_latency_ms": 4394.9878215789795,
          "total_latency_ms": 4696.447372436523
        },
        {
          "probe_id": "preference_learning-preference_scope-8",
          "pillar": "preference_learning",
          "subpillar": "preference_scope",
          "question": "Which specific individual is concerned about the 'Azure spend'?",
          "answer_type": "short_answer",
          "gold_answer": "Liam",
          "predicted_answer": "User",
          "retrieved_context": [
            "User is concerned about Azure spend.",
            "Alex is worried about the service running on Azure",
            "CacheLayer5 on Azure is not preventing sluggishness today"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 617.767333984375,
          "generation_latency_ms": 2049.208641052246,
          "total_latency_ms": 2666.975975036621
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-9",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What version of software is the system 'primarydb_3' currently running?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wants to know status of connection to primary database",
            "PrimaryDB3 is not part of the rest of the stack",
            "User is checking whether PrimaryDB3 is on AWS like AuthService8."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 295.6058979034424,
          "generation_latency_ms": 2600.2516746520996,
          "total_latency_ms": 2895.857572555542
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the Data Scientist's pet?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User forgot the name of the pet.",
            "Alex wants to send logs over to the Data Scientist",
            "Mia is trying to train models."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 339.45345878601074,
          "generation_latency_ms": 3451.1630535125732,
          "total_latency_ms": 3790.616512298584
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-11",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What technical configuration issue was identified as the cause of the version flapping on the Azure auth service?",
          "answer_type": "short_answer",
          "gold_answer": "Configuration drift",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User heard there might be a version mismatch for the Azure service.",
            "Cache layer is in same environment as the buggy Azure authentication service",
            "Other backend lead is dealing with Azure authentication service"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 714.9553298950195,
          "generation_latency_ms": 4531.517267227173,
          "total_latency_ms": 5246.472597122192
        },
        {
          "probe_id": "procedural_knowledge-lesson_application-12",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_application",
          "question": "Based on the identified configuration drift, was the traffic split on AuthService2 considered intentional?",
          "answer_type": "boolean",
          "gold_answer": "No",
          "predicted_answer": "No",
          "retrieved_context": [
            "The situation is a configuration drift.",
            "User suspects configuration drift",
            "The blue-green deployment for AuthService2 went sideways"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 570.5585479736328,
          "generation_latency_ms": 3913.1126403808594,
          "total_latency_ms": 4483.671188354492
        }
      ],
      "summary": {
        "overall_accuracy": 0.4166666666666667,
        "total_score": 5,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 2,
            "count": 9,
            "accuracy": 0.2222222222222222
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "boolean": {
            "total": 1,
            "count": 1,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_049.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 12,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 65.82032227516174,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Which specific system is the user's cofounder concerned about regarding version ambiguity?",
          "answer_type": "short_answer",
          "gold_answer": "PrimaryDB7",
          "predicted_answer": "the main database on Google's cloud",
          "retrieved_context": [
            "User suggests ops guy look into the version conflict",
            "User notes that versioning looks weird",
            "The cofounder thinks the versioning of the main database on Google's cloud is off"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 610.0208759307861,
          "generation_latency_ms": 2420.304536819458,
          "total_latency_ms": 3030.325412750244
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Who is the DevOps lead responsible for the recent beta deployment on the Google Cloud database?",
          "answer_type": "short_answer",
          "gold_answer": "Elijah",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "The main database on Google's cloud was being asked about by the user's cofounder",
            "DevOps guy is working on the issue.",
            "The cofounder thinks the versioning of the main database on Google's cloud is off"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 409.00111198425293,
          "generation_latency_ms": 3503.5245418548584,
          "total_latency_ms": 3912.5256538391113
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "The database hosted on AWS runs alongside which other system on the same cloud provider?",
          "answer_type": "short_answer",
          "gold_answer": "AnalyticsEngine6",
          "predicted_answer": "AnalyticsEngine6",
          "retrieved_context": [
            "PrimaryDB3 is hosted on AWS.",
            "User is looking at databases and often mixes up which one is on Google Cloud versus Amazon.",
            "AnalyticsEngine6 is on AWS and is located close to PrimaryDB3."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 684.0763092041016,
          "generation_latency_ms": 2515.4614448547363,
          "total_latency_ms": 3199.537754058838
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What versions are currently active on PrimaryDB7 according to the latest system checks?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "User examined deployment logs for PrimaryDB7 this morning and found that the system logs report main database version v1.2.0 and the admin dashboard reports main database version v2.0.0-beta.",
            "User is unsure which cloud provider PrimaryDB7 uses.",
            "User believes PrimaryDB7 and CacheLayer5 are on the same provider."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 628.2837390899658,
          "generation_latency_ms": 2371.0012435913086,
          "total_latency_ms": 2999.2849826812744
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why was the DevOps lead unavailable to immediately fix the database conflict in the morning?",
          "answer_type": "short_answer",
          "gold_answer": "Taking cat to vet",
          "predicted_answer": "Taking cat to vet",
          "retrieved_context": [
            "DevOps lead might be late due to taking cat to vet",
            "DevOps guy is working on the issue.",
            "User vaguely remembers DevOps guy might have updated it last night."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 338.6051654815674,
          "generation_latency_ms": 2352.445363998413,
          "total_latency_ms": 2691.0505294799805
        },
        {
          "probe_id": "temporal_episodic-temporal_sequencing-5",
          "pillar": "temporal_episodic",
          "subpillar": "temporal_sequencing",
          "question": "Did the discussion about the AWS bill happen before or after the strategy sync meeting was mentioned?",
          "answer_type": "short_answer",
          "gold_answer": "Before",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "CEO is complaining about Amazon bill for other database.",
            "User needs to review the infrastructure map before a strategy meeting with User's cofounder later.",
            "User intends to sync with DevOps lead about the cloud provider later."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 453.72557640075684,
          "generation_latency_ms": 4755.877494812012,
          "total_latency_ms": 5209.603071212769
        },
        {
          "probe_id": "procedural_knowledge-task_state_tracking-6",
          "pillar": "procedural_knowledge",
          "subpillar": "task_state_tracking",
          "question": "What item is currently on the user's shopping list based on recent requests?",
          "answer_type": "short_answer",
          "gold_answer": "Coffee beans",
          "predicted_answer": "coffee beans, hiking boots, milk, tickets for concert",
          "retrieved_context": [
            "User wants to pull up their schedule for the day",
            "User wants reminder to buy coffee beans later",
            "User asks who owns new UI mockups"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 541.0921573638916,
          "generation_latency_ms": 2673.89178276062,
          "total_latency_ms": 3214.9839401245117
        },
        {
          "probe_id": "procedural_knowledge-tool_method_memory-7",
          "pillar": "procedural_knowledge",
          "subpillar": "tool_method_memory",
          "question": "Which two frontend leads did the user decide to involve to verify feasibility?",
          "answer_type": "short_answer",
          "gold_answer": "Charlotte and Sophia",
          "predicted_answer": "Charlotte and Sophia",
          "retrieved_context": [
            "User wants both frontend leads on UI review invite",
            "User needs Charlotte and Sophia to verify feasibility",
            "User believes there is a co-lead situation for the frontend team."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 303.1349182128906,
          "generation_latency_ms": 2827.3353576660156,
          "total_latency_ms": 3130.4702758789062
        },
        {
          "probe_id": "preference_learning-preference_induction-8",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "Based on the user's repeated checks, which infrastructure component requires the most monitoring attention?",
          "answer_type": "short_answer",
          "gold_answer": "PrimaryDB7",
          "predicted_answer": "main database on GCP",
          "retrieved_context": [
            "User needs to check infrastructure status",
            "User wants to double-check infrastructure details before sync with Oliver",
            "User is concerned about multi-cloud sprawl, which is a headache."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 338.1786346435547,
          "generation_latency_ms": 4447.848081588745,
          "total_latency_ms": 4786.0267162323
        },
        {
          "probe_id": "preference_learning-explicit_preferences-9",
          "pillar": "preference_learning",
          "subpillar": "explicit_preferences",
          "question": "What specific aspect of the company does Oliver usually focus on?",
          "answer_type": "short_answer",
          "gold_answer": "Financial overview",
          "predicted_answer": "Infrastructure and cloud costs",
          "retrieved_context": [
            "Oliver wants to review the quarterly targets",
            "User asks Oliver about board meeting time",
            "User's cofounder Oliver is asking for a quick infra summary for Nebula Corp."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 665.4503345489502,
          "generation_latency_ms": 4062.366485595703,
          "total_latency_ms": 4727.816820144653
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-10",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What is the name of the user's gym?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User forgot about gym membership renewal.",
            "User thinks ops guy is out walking his cat right now",
            "User is going to hunt for caffeine"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 585.1662158966064,
          "generation_latency_ms": 2385.446310043335,
          "total_latency_ms": 2970.6125259399414
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-11",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "Who holds the role of Backend Lead at the company?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User asks who is leading frontend team.",
            "User believes there is a co-lead situation for the frontend team.",
            "User thinks Charlotte is leading the frontend team."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 300.6143569946289,
          "generation_latency_ms": 2535.9654426574707,
          "total_latency_ms": 2836.5797996520996
        }
      ],
      "summary": {
        "overall_accuracy": 0.5833333333333334,
        "total_score": 7,
        "count": 12,
        "by_answer_type": {
          "short_answer": {
            "total": 5,
            "count": 10,
            "accuracy": 0.5
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "declarative_reasoning": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "temporal_episodic": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "procedural_knowledge": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "preference_learning": {
            "total": 0,
            "count": 2,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        }
      },
      "stored_memories": []
    },
    {
      "benchmark_file": "C:\\Users\\k_nai\\nebulaMemBenchmark\\complex_test_set\\benchmark_complex_050.json",
      "adapter_type": "Mem0Adapter",
      "num_sessions": 25,
      "num_probes": 9,
      "ingestion_time_s": 0.0,
      "total_evaluation_time_s": 53.09941554069519,
      "probe_results": [
        {
          "probe_id": "world_modeling-entity_resolution-0",
          "pillar": "world_modeling",
          "subpillar": "entity_resolution",
          "question": "Who is the user referring to when they mention their 'cofounder'?",
          "answer_type": "short_answer",
          "gold_answer": "Noah",
          "predicted_answer": "Liam",
          "retrieved_context": [
            "User's cofounder is usually faster than this.",
            "User's cofounder was asking about resource allocation",
            "User's cofounder has a board meeting tomorrow."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 362.18929290771484,
          "generation_latency_ms": 4191.860914230347,
          "total_latency_ms": 4554.0502071380615
        },
        {
          "probe_id": "world_modeling-relationship_mapping-1",
          "pillar": "world_modeling",
          "subpillar": "relationship_mapping",
          "question": "Who is the Frontend Lead responsible for the React migration?",
          "answer_type": "short_answer",
          "gold_answer": "James",
          "predicted_answer": "James",
          "retrieved_context": [
            "User will hand over the project to James to lead frontend implementation",
            "User wants James looped in for the Frontend Lead perspective.",
            "James leads the frontend team and is complaining about latency on the frontend."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 518.2137489318848,
          "generation_latency_ms": 2317.8951740264893,
          "total_latency_ms": 2836.108922958374
        },
        {
          "probe_id": "declarative_reasoning-fact_composition-2",
          "pillar": "declarative_reasoning",
          "subpillar": "fact_composition",
          "question": "Which cloud provider hosts the authentication service that is currently experiencing a stuck blue-green deployment?",
          "answer_type": "short_answer",
          "gold_answer": "GCP",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "The main authentication service deployed on Google Cloud is behaving erratically.",
            "User wants confirmation of which auth service is currently in the Google cloud environment.",
            "User confirms backup auth service and load balancer 3 are on Microsoft Cloud."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 291.57328605651855,
          "generation_latency_ms": 3122.9286193847656,
          "total_latency_ms": 3414.501905441284
        },
        {
          "probe_id": "declarative_reasoning-belief_revision-3",
          "pillar": "declarative_reasoning",
          "subpillar": "belief_revision",
          "question": "What versions of the software are currently detected running on AuthService8?",
          "answer_type": "short_answer",
          "gold_answer": "v1.2.0 and v2.0.0-beta",
          "predicted_answer": "v1.2.0 and v2.0.0-beta",
          "retrieved_context": [
            "Alex wants to know if AuthService8 is running the stable version.",
            "Alex wants to check the status of AuthService8.",
            "User wants to know where AuthService8 is parked"
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 519.2911624908447,
          "generation_latency_ms": 2649.930715560913,
          "total_latency_ms": 3169.221878051758
        },
        {
          "probe_id": "temporal_episodic-causal_explanation-4",
          "pillar": "temporal_episodic",
          "subpillar": "causal_explanation",
          "question": "Why is the user concerned about egress fees regarding the load balancer hosted on AWS?",
          "answer_type": "short_answer",
          "gold_answer": "It routes traffic to GCP",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is concerned about LoadBalancer2 on AWS.",
            "User wants to verify that the Amazon load balancer is not blackholed, including checking for misdirecting traffic.",
            "User notes that load balancer on Amazon is separate from Azure load balancer"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 301.2678623199463,
          "generation_latency_ms": 3491.748809814453,
          "total_latency_ms": 3793.0166721343994
        },
        {
          "probe_id": "preference_learning-preference_induction-5",
          "pillar": "preference_learning",
          "subpillar": "preference_induction",
          "question": "How does the CEO prefer infrastructure cost reports to be formatted?",
          "answer_type": "short_answer",
          "gold_answer": "Detailed",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User's cofounder wants a full rundown of infrastructure costs before the board meeting and is worried about them.",
            "User expects Noah to ask about infrastructure costs during exec meeting",
            "User's main concern is infrastructure costs"
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 975.8772850036621,
          "generation_latency_ms": 4038.91658782959,
          "total_latency_ms": 5014.793872833252
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-6",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What kind of pet does Will own?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "Will is focused",
            "User is with Will and Liam.",
            "Will is handling the design specs."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 659.2965126037598,
          "generation_latency_ms": 2917.0188903808594,
          "total_latency_ms": 3576.315402984619
        },
        {
          "probe_id": "knowledge_boundaries-negative_knowledge-7",
          "pillar": "knowledge_boundaries",
          "subpillar": "negative_knowledge",
          "question": "What specific roast of coffee beans did the user ask to be added to the shopping list?",
          "answer_type": "abstain",
          "gold_answer": "Unknown",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User is out of coffee beans.",
            "User is having their second coffee of the day.",
            "User prefers the usual dark roast."
          ],
          "score": 1,
          "match_type": "llm_judge",
          "search_latency_ms": 423.60711097717285,
          "generation_latency_ms": 4054.687976837158,
          "total_latency_ms": 4478.295087814331
        },
        {
          "probe_id": "procedural_knowledge-lesson_extraction-8",
          "pillar": "procedural_knowledge",
          "subpillar": "lesson_extraction",
          "question": "What does the user identify as the number one priority when dealing with the executive team?",
          "answer_type": "short_answer",
          "gold_answer": "Keeping them happy",
          "predicted_answer": "Unknown",
          "retrieved_context": [
            "User wonders if design team pushed something early.",
            "User's cofounder was asking about resource allocation",
            "User finds being the CTO involves more people management than expected."
          ],
          "score": 0,
          "match_type": "llm_judge",
          "search_latency_ms": 594.9945449829102,
          "generation_latency_ms": 4033.8973999023438,
          "total_latency_ms": 4628.891944885254
        }
      ],
      "summary": {
        "overall_accuracy": 0.4444444444444444,
        "total_score": 4,
        "count": 9,
        "by_answer_type": {
          "short_answer": {
            "total": 2,
            "count": 7,
            "accuracy": 0.2857142857142857
          },
          "abstain": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          }
        },
        "by_pillar": {
          "world_modeling": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "declarative_reasoning": {
            "total": 1,
            "count": 2,
            "accuracy": 0.5
          },
          "temporal_episodic": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "preference_learning": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          },
          "knowledge_boundaries": {
            "total": 2,
            "count": 2,
            "accuracy": 1.0
          },
          "procedural_knowledge": {
            "total": 0,
            "count": 1,
            "accuracy": 0.0
          }
        }
      },
      "stored_memories": []
    }
  ]
}